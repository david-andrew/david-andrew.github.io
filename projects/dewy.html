<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" as="font" href="/_next/static/media/c9a5bc6a7c948fb0-s.p.woff2" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/e8d89bf12f3e5f17.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/85fa6dafca566008.css" data-precedence="next"/><link rel="preload" href="/_next/static/chunks/webpack-cd5d5aa64ec07774.js" as="script" fetchPriority="low"/><script src="/_next/static/chunks/fd9d1056-bc91c3b3fa0b78fd.js" async=""></script><script src="/_next/static/chunks/596-fc24fa4abd14b1c2.js" async=""></script><script src="/_next/static/chunks/main-app-de654e813a62aea4.js" async=""></script><script src="/pyodideCommsService.js" async=""></script><title>David Samson</title><meta name="description" content="Generated by create next app"/><link rel="icon" href="/favicon.ico" type="image/x-icon" sizes="16x16"/><meta name="next-size-adjust"/><script src="/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js" noModule=""></script></head><body class="__className_e66fe9"><div class="w-screen h-screen"><div class="fixed w-screen bg-black z-50"><div><div class="flex flex-row md:justify-center justify-left px-4 py-2"><div class="md:hidden"><button><span class="text-white text-4xl align-middle">☰</span></button></div><div class="hidden md:flex"><a draggable="false" class="select-none" href="/"><div class="relative cursor-pointer text-center font-quadon
                m-2 text-white border-solid sm:border-white md:border-transparent hover:border-white 
                text-xl border-2
                md:text-2xl md:border-3
                lg:text-4xl lg:border-4
                "><div class="
                    py-3 px-4 
                    md:py-3 md:px-4 
                    lg:py-6 lg:px-9">Home</div></div></a><a draggable="false" class="select-none" href="/projects"><div class="relative cursor-pointer text-center font-quadon
                m-2 text-white border-solid sm:border-white md:border-transparent hover:border-white 
                text-xl border-2
                md:text-2xl md:border-3
                lg:text-4xl lg:border-4
                bg-accent"><div class="
                    py-3 px-4 
                    md:py-3 md:px-4 
                    lg:py-6 lg:px-9">Projects</div></div></a><a draggable="false" class="select-none" href="/about"><div class="relative cursor-pointer text-center font-quadon
                m-2 text-white border-solid sm:border-white md:border-transparent hover:border-white 
                text-xl border-2
                md:text-2xl md:border-3
                lg:text-4xl lg:border-4
                "><div class="
                    py-3 px-4 
                    md:py-3 md:px-4 
                    lg:py-6 lg:px-9">About</div></div></a><a draggable="false" class="select-none" href="/clovers"><div class="relative cursor-pointer text-center font-quadon
                m-2 text-white border-solid sm:border-white md:border-transparent hover:border-white 
                text-xl border-2
                md:text-2xl md:border-3
                lg:text-4xl lg:border-4
                "><div class="
                    py-3 px-4 
                    md:py-3 md:px-4 
                    lg:py-6 lg:px-9">Clovers</div></div></a><a draggable="false" class="select-none" href="/contact"><div class="relative cursor-pointer text-center font-quadon
                m-2 text-white border-solid sm:border-white md:border-transparent hover:border-white 
                text-xl border-2
                md:text-2xl md:border-3
                lg:text-4xl lg:border-4
                "><div class="
                    py-3 px-4 
                    md:py-3 md:px-4 
                    lg:py-6 lg:px-9">Contact</div></div></a></div></div></div></div><div class="pointer-events-none select-none" style="height:var(--navbar-height)"> </div><div style="height:calc(100vh - var(--navbar-height))" class="overflow-x-hidden"><!--$--><div class="mx-auto px-4 sm:px-6 lg:px-8 max-w-[1190px]"><h1 class="text-4xl my-6 font-quadon mb-0">Dewy Programming Language</h1><p class="mb-6 text-xl font-gentona text-justify">Unknown</p><!--$!--><template data-dgst="NEXT_DYNAMIC_NO_SSR_CODE"></template><!--/$--><h3 class="text-2xl mt-6 mb-2 font-quadon">About</h3><p class="mb-6 text-xl font-gentona text-justify">Dewy is a programming language I have been developing off and on since 2016. The Dewy Programming Language is a general purpose language designed with engineering applications in mind. Think the functionality and ease of use of matlab or python combined with the speed of a compiled language like C or Rust, but with its own unique flare.</p><p class="text-xl font-gentona text-justify mb-2">Some key planned features include:</p><ul class="list-disc mb-6 pl-10 text-xl font-gentona"><li><strong>Functional and Imperative</strong> - Dewy is an imperitive language with strong support for functional programming. This allows for a very flexible programming style, where you can use the best tool for the job.</li><li><strong>Expression based syntax</strong> - Dewy uses an expression based syntax, meaning that everything is an expression. This allows for a very simple yet powerful syntax, where common language features often are just a free consequence of the syntax</li><li><strong>Garbage-collector-free memory management</strong> - Dewy uses a unique memory management system, allowing for fast and efficient memory management without the need for a garbage collector.</li><li><strong>Strong type system</strong> - Dewy has a powerful static type system with inference, reminiscent of those in Typescript and Julia.</li><li><strong>Built in unit system</strong> - Dewy has a built in unit system, allowing you to easily work with units and convert between them. This is especially useful for engineering applications.</li><li><strong>Strong math support</strong> - Dewy has strong support many math features, including complex numbers, quaternions, vectors, matrices, and more. This is especially useful for engineering applications.</li></ul><p class="mb-6 text-xl font-gentona text-justify">An example of the common FizzBuzz program implemented in Dewy might look like this:</p><div class="rounded-md overflow-hidden mb-6"><pre style="display:block;overflow-x:auto;padding:0.5em;background:#232323;color:#e6e1dc"><code style="white-space:pre"><span>multiples = [</span><span style="color:#e8bf6a">3</span><span> -&gt; </span><span style="color:#6d9cbe">&#x27;Fizz</span><span>&#x27; </span><span style="color:#a5c261">5</span><span> -&gt; </span><span style="color:#6d9cbe">&#x27;Buzz</span><span>&#x27; /{</span><span style="color:#a5c261">7</span><span> -&gt; </span><span style="color:#6d9cbe">&#x27;Bazz</span><span>&#x27; </span><span style="color:#a5c261">11</span><span> -&gt; </span><span style="color:#6d9cbe">&#x27;Bar</span><span>&#x27;}/]
</span><span>loop i in [</span><span style="color:#e8bf6a">0..100</span><span>)
</span>{
<!-- -->    printed_words = false
<span>    loop [</span><span style="color:#e8bf6a">multiple</span><span> word] in multiples 
</span>    {
<span>        if i % multiple =? </span><span style="color:#a5c261">0</span><span> 
</span>        { 
<span>            print(</span><span style="color:#e8bf6a">multiple</span><span>)
</span>            printed_words = true
<!-- -->        }
<!-- -->    }
<span>    if not? printed_words print(</span><span style="color:#e8bf6a">i</span><span>)
</span>    printl()
<!-- -->}</code></pre></div><p class="mb-6 text-xl font-gentona text-justify">Or a more functional style implementation might look like this:</p><div class="rounded-md overflow-hidden mb-6"><pre style="display:block;overflow-x:auto;padding:0.5em;background:#232323;color:#e6e1dc"><code style="white-space:pre"><span>multiples = [</span><span style="color:#e8bf6a">3</span><span> -&gt; </span><span style="color:#6d9cbe">&#x27;Fizz</span><span>&#x27; </span><span style="color:#a5c261">5</span><span> -&gt; </span><span style="color:#6d9cbe">&#x27;Buzz</span><span>&#x27; /{</span><span style="color:#a5c261">7</span><span> -&gt; </span><span style="color:#6d9cbe">&#x27;Bazz</span><span>&#x27; </span><span style="color:#a5c261">11</span><span> -&gt; </span><span style="color:#6d9cbe">&#x27;Bar</span><span>&#x27;}/]
</span><span>range = [</span><span style="color:#e8bf6a">0..100</span><span>)
</span>
<span>//indexing at [, ..] and [</span><span style="color:#e8bf6a">..</span><span>,] adds singleton dimensions
</span><span>word_bools = range[, ..] .% multiples.keys[</span><span style="color:#e8bf6a">..</span><span>,] .=? </span><span style="color:#a5c261">0</span><span>
</span>
<span>// #` means transpose, which behaves like python</span><span style="color:#6d9cbe">&#x27;s</span><span> zip()
</span><span>word_grid = [</span><span style="color:#e8bf6a">multiples.values</span><span> word_bools]`.map(
</span><span>[</span><span style="color:#e8bf6a">word</span><span> bools] =&gt; bools.map(</span><span style="color:#e8bf6a">b</span><span> =&gt; if b word else &#x27;&#x27;)
</span>)
<!-- -->
<span>raw_lines = word_grid`.map(</span><span style="color:#e8bf6a">line_words</span><span> =&gt; line_words.join(&#x27;&#x27;))
</span>
<span>lines = [</span><span style="color:#e8bf6a">raw_lines</span><span> range]`.map(
</span><span>    (</span><span style="color:#e8bf6a">raw_line</span><span>, i) =&gt; if raw_line.length =? </span><span style="color:#a5c261">0</span><span> &#x27;{i}&#x27; else raw_line
</span>)
<!-- -->
<!-- -->lines.join(&#x27;\n&#x27;) |&gt; printl
</code></pre></div><p class="mb-6 text-xl font-gentona text-justify">For clarity, the variables at each step look like so:</p><div class="rounded-md overflow-hidden mb-6"><pre style="display:block;overflow-x:auto;padding:0.5em;background:#232323;color:#e6e1dc"><code style="white-space:pre"><span>word_bools = [[</span><span style="color:#e8bf6a">true</span><span> false false true false false true false ...]
</span><span>             [</span><span style="color:#e8bf6a">true</span><span> false false false false true false false ...]]
</span>
<span>word_grid = [[</span><span style="color:#6d9cbe">&#x27;Fizz</span><span>&#x27; &#x27;&#x27; &#x27;&#x27; </span><span style="color:#6d9cbe">&#x27;Fizz</span><span>&#x27; &#x27;&#x27; &#x27;&#x27; </span><span style="color:#6d9cbe">&#x27;Fizz</span><span>&#x27; &#x27;&#x27; &#x27;&#x27; </span><span style="color:#6d9cbe">&#x27;Fizz</span><span>&#x27; &#x27;&#x27; &#x27;&#x27; ...]
</span><span>            [</span><span style="color:#6d9cbe">&#x27;Buzz</span><span>&#x27; &#x27;&#x27; &#x27;&#x27; &#x27;&#x27; &#x27;&#x27; </span><span style="color:#6d9cbe">&#x27;Buzz</span><span>&#x27; &#x27;&#x27; &#x27;&#x27; &#x27;&#x27; &#x27;&#x27; </span><span style="color:#6d9cbe">&#x27;Buzz</span><span>&#x27; &#x27;&#x27; &#x27;&#x27; ...]]
</span>
<span>raw_lines = [</span><span style="color:#6d9cbe">&#x27;FizzBuzz</span><span>&#x27; &#x27;&#x27; &#x27;&#x27; </span><span style="color:#6d9cbe">&#x27;Fizz</span><span>&#x27; &#x27;&#x27; </span><span style="color:#6d9cbe">&#x27;Buzz</span><span>&#x27; </span><span style="color:#6d9cbe">&#x27;Fizz</span><span>&#x27; &#x27;&#x27; &#x27;&#x27; </span><span style="color:#6d9cbe">&#x27;Fizz</span><span>&#x27; </span><span style="color:#6d9cbe">&#x27;Buzz</span><span>&#x27; &#x27;&#x27; ...]
</span>
<span>lines = [</span><span style="color:#6d9cbe">&#x27;FizzBuzz</span><span>&#x27; </span><span style="color:#6d9cbe">&#x27;1</span><span>&#x27; </span><span style="color:#6d9cbe">&#x27;2</span><span>&#x27; </span><span style="color:#6d9cbe">&#x27;Fizz</span><span>&#x27; </span><span style="color:#6d9cbe">&#x27;4</span><span>&#x27; </span><span style="color:#6d9cbe">&#x27;Buzz</span><span>&#x27; </span><span style="color:#6d9cbe">&#x27;Fizz</span><span>&#x27; </span><span style="color:#6d9cbe">&#x27;7</span><span>&#x27; </span><span style="color:#6d9cbe">&#x27;8</span><span>&#x27; </span><span style="color:#6d9cbe">&#x27;Fizz</span><span>&#x27; </span><span style="color:#6d9cbe">&#x27;Buzz</span><span>&#x27; </span><span style="color:#6d9cbe">&#x27;11</span><span>&#x27; ...]
</span></code></pre></div><h3 class="text-2xl mt-6 mb-2 font-quadon">Current Status</h3><p class="mb-6 text-xl font-gentona text-justify">Currently I&#x27;m working through a simple interpreter for the language (powering the demo above). Previously I had been doing a lot of development on bleeding edge<!-- --> <a class="text-blue-400 hover:text-blue-500 font-gentona text-xl" href="/projects/dewy_old">parser generators</a>, but that ended up being too big of a time sink for not much visible progress. Instead, for the time being, I ended up just hand rolling a parser in python, which has led to actually runnable code! I&#x27;ll definitely revisit parser generators in the future when the language is further along.</p><p class="mb-6 text-xl font-gentona text-justify">After the parser is complete, the next steps will be working on compiling to<!-- --> <a class="text-blue-400 hover:text-blue-500 font-gentona text-xl" href="https://en.wikipedia.org/wiki/LLVM#Intermediate_representation">LLVM IR</a> (read LLVM assembly), as well as starting to build out the standard library, and then bootstrapping the compiler to be able to compile itself.</p><h3 class="text-2xl mt-6 mb-2 font-quadon">About the Demo</h3><p class="mb-6 text-xl font-gentona text-justify">The demo above was actually pretty complex to put together. The current interpreter is written in python, and this website is statically hosted, which meant the demo required some way to statically run python code without a server. For this, I used <a class="text-blue-400 hover:text-blue-500 font-gentona text-xl" href="https://pyodide.org/">Pyodide</a>, which is basically <a class="text-blue-400 hover:text-blue-500 font-gentona text-xl" href="https://github.com/python/cpython">CPython</a> compiled to<!-- --> <a class="text-blue-400 hover:text-blue-500 font-gentona text-xl" href="https://webassembly.org/">WebAssembly</a> via<!-- --> <a class="text-blue-400 hover:text-blue-500 font-gentona text-xl" href="https://emscripten.org/">Emscripten.</a></p><p class="mb-6 text-xl font-gentona text-justify">Pyodide itself isn&#x27;t too difficult to use, except for the fact that it doesn&#x27;t have good support for asynchronous standard input—it really wants to halt the entire UI while you type input into a stock browser popup prompt. To get around this, I found a<!-- --> <a class="text-blue-400 hover:text-blue-500 font-gentona text-xl" href="https://www.npmjs.com/package/sync-message">handy library</a> where you run pyodide in a web worker, and then any time it wants to read input, the worker makes a synchronous XHR request to a service worker, blocking the pyodide web worker until the service worker receives a response from the main thread with the input, which the service worker can then pass back to the pyodide worker. Suffice it to say, I don&#x27;t think I ever want to deal with service workers again.</p><p class="mb-6 text-xl font-gentona text-justify">Now that python is handled, the next aspect is getting the Dewy interpreter itself to run. For this, I fetch (at website build time) the source code directly from<!-- --> <a class="text-blue-400 hover:text-blue-500 font-gentona text-xl" href="https://github.com/david-andrew/dewy-lang/tree/master/src/compiler">github</a>. I then abuse the python import lib to allow loading &quot;modules&quot; directly from strings, and then pass all of the dewy source in as modules. Then I have a little wrapper function for the entry point which receives the source code string, and runs the program. The entry point can then be called from the browser via a javascript wrapper function.</p><p class="mb-6 text-xl font-gentona text-justify">The final piece of the puzzle is the text entry, and terminal emulator. For text input, I&#x27;m using the <a class="text-blue-400 hover:text-blue-500 font-gentona text-xl" href="https://codemirror.net/">Code Mirror Library</a>with a custom syntax highlighter (actually the current syntax highlighter was for the<!-- --> <a class="text-blue-400 hover:text-blue-500 font-gentona text-xl" href="/projects/dewy_old">Dewy meta language</a>, but it works well enough in the meantime). For the terminal, I use the <a class="text-blue-400 hover:text-blue-500 font-gentona text-xl" href="https://xtermjs.org/">xterm.js</a> library. I then hooked up stdin and stdout from pyodide to interact with the terminal, and voila! A Dewy interpreter running in the browser.</p><p class="mb-6 text-xl font-gentona text-justify">There are definitely some rough edges, and the parser only supports a small handful of features, but it runs! It&#x27;s probably the easiest way to try out the language, and I&#x27;m looking forward to getting all of the broken example programs working!</p><h3 class="text-2xl mt-6 mb-2 font-quadon">Links</h3><div class="flex flex-col space-y-3"><div class="flex flex-row text-sm items-center"><img alt="github icon" draggable="false" loading="lazy" width="496" height="484" decoding="async" data-nimg="1" class="inline-block w-8 h-8 mr-2  pointer-events-none select-none" style="color:transparent" src="/_next/static/media/github.8d24eda3.svg"/><span class="align-middle"><a class="text-blue-400 hover:text-blue-500 font-gentona text-xl" href="https://github.com/david-andrew/dewy-lang">Github Repo</a></span></div><div class="flex flex-row text-sm items-center"><img alt="docs icon" draggable="false" loading="lazy" width="384" height="512" decoding="async" data-nimg="1" class="inline-block w-8 h-8 mr-2  pointer-events-none select-none" style="color:transparent" src="/_next/static/media/docs.71257e0f.svg"/><span class="align-middle"><a class="text-blue-400 hover:text-blue-500 font-gentona text-xl" href="https://david-andrew.github.io/dewy-lang/">Language Docs</a></span></div></div><div class="pointer-events-none select-none" style="height:var(--navbar-height)"> </div></div><!--/$--></div><div class="fixed bottom-0 right-0 w-full flex flex-row-reverse pointer-events-none" style="height:var(--navbar-height)"><div class="flex flex-row justify-center" style="width:var(--navbar-height);height:var(--navbar-height)"><div class="flex flex-col justify-center"><div class="hidden md:block hover:cursor-pointer pointer-events-auto"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" class=" lg:h-16 lg:w-16 md:h-12 md:w-12 sm:h-8 sm:w-8 h-8 w-8 "><title>Select Accent Color. Color is saved in a cookie.</title><path stroke-linecap="round" stroke-linejoin="round" d="M4.098 19.902a3.75 3.75 0 005.304 0l6.401-6.402M6.75 21A3.75 3.75 0 013 17.25V4.125C3 3.504 3.504 3 4.125 3h5.25c.621 0 1.125.504 1.125 1.125v4.072M6.75 21a3.75 3.75 0 003.75-3.75V8.197M6.75 21h13.125c.621 0 1.125-.504 1.125-1.125v-5.25c0-.621-.504-1.125-1.125-1.125h-4.072M10.5 8.197l2.88-2.88c.438-.439 1.15-.439 1.59 0l3.712 3.713c.44.44.44 1.152 0 1.59l-2.879 2.88M6.75 17.25h.008v.008H6.75v-.008z"></path></svg></div><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" class=" pointer-events-auto lg:h-16 lg:w-16 md:h-12 md:w-12 sm:h-8 sm:w-8 h-8 w-8 md:hidden "><title>Select Accent Color. Color is saved in a cookie.</title><path stroke-linecap="round" stroke-linejoin="round" d="M4.098 19.902a3.75 3.75 0 005.304 0l6.401-6.402M6.75 21A3.75 3.75 0 013 17.25V4.125C3 3.504 3.504 3 4.125 3h5.25c.621 0 1.125.504 1.125 1.125v4.072M6.75 21a3.75 3.75 0 003.75-3.75V8.197M6.75 21h13.125c.621 0 1.125-.504 1.125-1.125v-5.25c0-.621-.504-1.125-1.125-1.125h-4.072M10.5 8.197l2.88-2.88c.438-.439 1.15-.439 1.59 0l3.712 3.713c.44.44.44 1.152 0 1.59l-2.879 2.88M6.75 17.25h.008v.008H6.75v-.008z"></path></svg></div></div></div></div><script src="/_next/static/chunks/webpack-cd5d5aa64ec07774.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/media/c9a5bc6a7c948fb0-s.p.woff2\",{\"as\":\"font\",\"type\":\"font/woff2\"}]\n2:HL[\"/_next/static/css/e8d89bf12f3e5f17.css\",{\"as\":\"style\"}]\n0:\"$L3\"\n"])</script><script>self.__next_f.push([1,"4:HL[\"/_next/static/css/85fa6dafca566008.css\",{\"as\":\"style\"}]\n"])</script><script>self.__next_f.push([1,"5:I{\"id\":57948,\"chunks\":[\"2272:static/chunks/webpack-cd5d5aa64ec07774.js\",\"2971:static/chunks/fd9d1056-bc91c3b3fa0b78fd.js\",\"596:static/chunks/596-fc24fa4abd14b1c2.js\"],\"name\":\"default\",\"async\":false}\n7:I{\"id\":56628,\"chunks\":[\"2272:static/chunks/webpack-cd5d5aa64ec07774.js\",\"2971:static/chunks/fd9d1056-bc91c3b3fa0b78fd.js\",\"596:static/chunks/596-fc24fa4abd14b1c2.js\"],\"name\":\"\",\"async\":false}\n3:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/e8d89bf12f3e5f17.css\",\"precedence\":\"next\"}]],[\"$\",\""])</script><script>self.__next_f.push([1,"$L5\",null,{\"buildId\":\"Z383ZlWf6tQmuxltlzj6s\",\"assetPrefix\":\"\",\"initialCanonicalUrl\":\"/projects/dewy\",\"initialTree\":[\"\",{\"children\":[\"projects\",{\"children\":[\"dewy\",{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],\"initialHead\":[false,\"$L6\"],\"globalErrorComponent\":\"$7\",\"children\":[null,\"$L8\",null]}]]\n"])</script><script>self.__next_f.push([1,"9:I{\"id\":27250,\"chunks\":[\"6685:static/chunks/6685-d55f1e0fd750c950.js\",\"8213:static/chunks/8213-ef98b168d3fb6523.js\",\"3337:static/chunks/3337-92bca57b67600e26.js\",\"5570:static/chunks/app/projects/layout-94b7229fd8c860b6.js\"],\"name\":\"Navbar\",\"async\":false}\na:I{\"id\":15274,\"chunks\":[\"6685:static/chunks/6685-d55f1e0fd750c950.js\",\"8213:static/chunks/8213-ef98b168d3fb6523.js\",\"3905:static/chunks/3905-01dc2d4b158832d0.js\",\"3337:static/chunks/3337-92bca57b67600e26.js\",\"3185:static/chunks/app/layout-4c642a84e29f5574"])</script><script>self.__next_f.push([1,".js\"],\"name\":\"GithubTimestampsProvider\",\"async\":false}\nb:I{\"id\":15274,\"chunks\":[\"6685:static/chunks/6685-d55f1e0fd750c950.js\",\"8213:static/chunks/8213-ef98b168d3fb6523.js\",\"3905:static/chunks/3905-01dc2d4b158832d0.js\",\"3337:static/chunks/3337-92bca57b67600e26.js\",\"3185:static/chunks/app/layout-4c642a84e29f5574.js\"],\"name\":\"GithubTimestampsFetcher\",\"async\":false}\nc:I{\"id\":15274,\"chunks\":[\"6685:static/chunks/6685-d55f1e0fd750c950.js\",\"8213:static/chunks/8213-ef98b168d3fb6523.js\",\"3905:static/chunks/3905-01dc2"])</script><script>self.__next_f.push([1,"d4b158832d0.js\",\"3337:static/chunks/3337-92bca57b67600e26.js\",\"3185:static/chunks/app/layout-4c642a84e29f5574.js\"],\"name\":\"ProjectsContextProvider\",\"async\":false}\nd:I{\"id\":47767,\"chunks\":[\"2272:static/chunks/webpack-cd5d5aa64ec07774.js\",\"2971:static/chunks/fd9d1056-bc91c3b3fa0b78fd.js\",\"596:static/chunks/596-fc24fa4abd14b1c2.js\"],\"name\":\"default\",\"async\":false}\ne:I{\"id\":57920,\"chunks\":[\"2272:static/chunks/webpack-cd5d5aa64ec07774.js\",\"2971:static/chunks/fd9d1056-bc91c3b3fa0b78fd.js\",\"596:static/chunks/596-f"])</script><script>self.__next_f.push([1,"c24fa4abd14b1c2.js\"],\"name\":\"default\",\"async\":false}\n10:I{\"id\":49488,\"chunks\":[\"6685:static/chunks/6685-d55f1e0fd750c950.js\",\"8213:static/chunks/8213-ef98b168d3fb6523.js\",\"3905:static/chunks/3905-01dc2d4b158832d0.js\",\"3337:static/chunks/3337-92bca57b67600e26.js\",\"3185:static/chunks/app/layout-4c642a84e29f5574.js\"],\"name\":\"ColorPicker\",\"async\":false}\n"])</script><script>self.__next_f.push([1,"8:[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[[\"$\",\"head\",null,{\"children\":[\"$\",\"script\",null,{\"src\":\"/pyodideCommsService.js\",\"async\":true}]}],[\"$\",\"body\",null,{\"className\":\"__className_e66fe9\",\"children\":[\"$\",\"div\",null,{\"className\":\"w-screen h-screen\",\"children\":[[\"$\",\"$L9\",null,{}],[\"$\",\"div\",null,{\"style\":{\"height\":\"calc(100vh - var(--navbar-height))\"},\"className\":\"overflow-x-hidden\",\"children\":[\"$\",\"$La\",null,{\"children\":[[\"$\",\"$Lb\",null,{\"projects\":[{\"title\":\"Blob Opera Performances\",\"imgSrc\":{\"src\":\"/_next/static/media/blob_opera_nox.e6f3aa2a.png\",\"height\":414,\"width\":512,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAGCAMAAADJ2y/JAAAAJ1BMVEU4EgowEQlEIRV0Vzx9ZEo+JhlXOyBCT1RTMx0+LyVEUlxuTS5AS1HBZ0aTAAAACXBIWXMAAAsTAAALEwEAmpwYAAAALklEQVR4nC3IuREAIAwDMMcOeYD95+XgKNQIhpahHYwUawuGoQuM6az0OwvPnwMUSwDO9qMceAAAAABJRU5ErkJggg==\",\"blurWidth\":8,\"blurHeight\":6},\"summary\":\"Virtual choir performances leveraging the blob opera as a front end for voice synthesis\",\"lastUpdated\":\"February 2021\",\"tags\":[\"Python\",\"Blob Opera\",\"choir\",\"music\",\"synthesis\"],\"route\":\"blob_opera\"},{\"title\":\"Boat Simulator\",\"imgSrc\":{\"src\":\"/_next/static/media/boat_simulator.7cc391fd.jpg\",\"height\":1280,\"width\":2048,\"blurDataURL\":\"data:image/jpeg;base64,/9j/2wBDAAoHBwgHBgoICAgLCgoLDhgQDg0NDh0VFhEYIx8lJCIfIiEmKzcvJik0KSEiMEExNDk7Pj4+JS5ESUM8SDc9Pjv/2wBDAQoLCw4NDhwQEBw7KCIoOzs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozv/wAARCAAFAAgDASIAAhEBAxEB/8QAFQABAQAAAAAAAAAAAAAAAAAAAAb/xAAdEAABAgcAAAAAAAAAAAAAAAAAAQQCAxESFSFT/8QAFAEBAAAAAAAAAAAAAAAAAAAABf/EABYRAAMAAAAAAAAAAAAAAAAAAAABEf/aAAwDAQACEQMRAD8AkFks7K49tuLmABWIOrP/2Q==\",\"blurWidth\":8,\"blurHeight\":5},\"summary\":\"Spring 2017 HopHacks submission\",\"lastUpdated\":\"March 2017\",\"tags\":[\"Unity\",\"C#\",\"3D game\"],\"route\":\"boat_simulator\"},{\"title\":\"Bueller Board\",\"imgSrc\":{\"src\":\"/_next/static/media/logo.43586adb.png\",\"height\":960,\"width\":960,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAMAAADz0U65AAAAG1BMVEUHBwcwMDAAAABMaXEAAAAAAAAgICAFBQUmJiYApgMbAAAACHRSTlP9/C8AtOqwLojbm7gAAAAJcEhZcwAACxMAAAsTAQCanBgAAAAxSURBVHicPYtbCgAwCMNSH9P7n3joYNCPQFK8AsIcS4A0DkhwkHq30AOjetSP3738AhZmAKbLVdBfAAAAAElFTkSuQmCC\",\"blurWidth\":8,\"blurHeight\":8},\"summary\":\"Fall 2015 HopHacks submission: Midi keyboard that used user provided audio samples, a.k.a. the 'goat keyboard'\",\"lastUpdated\":\"September 2015\",\"tags\":[\"midi\",\"music\"],\"route\":\"bueller_board\"},{\"title\":\"Composer\",\"imgSrc\":{\"src\":\"/_next/static/media/YeArlingtonMusickeLabLogo.cf893b61.png\",\"height\":960,\"width\":960,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAMAAADz0U65AAAAFVBMVEUEBARFRUVQUFA3NzckJCQXFxdfX192C4FUAAAACXBIWXMAAAsTAAALEwEAmpwYAAAALElEQVR4nE2LtxEAMAyE+CDtP7JPnakoAH60CgwNFQr2ibdytUhjT3xt8q8PDVwAX2ljebUAAAAASUVORK5CYII=\",\"blurWidth\":8,\"blurHeight\":8},\"summary\":\"React based composing software that acts as a front-end for LilyPond\",\"lastUpdated\":\"January 2021\",\"tags\":[\"React\",\"TypeScript\",\"SMuFL\",\"LilyPond\",\"music\",\"composition\"],\"route\":\"composer\"},{\"title\":\"Choir Compositions\",\"imgSrc\":{\"src\":\"/_next/static/media/music_staff.3145785a.png\",\"height\":1616,\"width\":2745,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAFCAMAAABPT11nAAAAHlBMVEUGBgZISEhSUlIeHh5paWk+Pj4vLy9cXFx7e3ufn5/bdycMAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAJ0lEQVR4nCXBtwEAIAwDMLe0/x9mQIKFjwN3jZBwxGowpFZGm7cpPAkxAH3f0FE4AAAAAElFTkSuQmCC\",\"blurWidth\":8,\"blurHeight\":5},\"summary\":\"\",\"lastUpdated\":\"May 2015\",\"tags\":[\"music\",\"choral\",\"composition\"],\"route\":\"compositions\"},{\"title\":\"Dewy Programming Language\",\"github\":\"dewy\",\"imgSrc\":{\"src\":\"/_next/static/media/dewy_dandelion.e2efa7ee.jpg\",\"height\":1600,\"width\":1600,\"blurDataURL\":\"data:image/jpeg;base64,/9j/2wBDAAoHBwgHBgoICAgLCgoLDhgQDg0NDh0VFhEYIx8lJCIfIiEmKzcvJik0KSEiMEExNDk7Pj4+JS5ESUM8SDc9Pjv/2wBDAQoLCw4NDhwQEBw7KCIoOzs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozv/wAARCAAIAAgDASIAAhEBAxEB/8QAFQABAQAAAAAAAAAAAAAAAAAAAAX/xAAgEAABAgUFAAAAAAAAAAAAAAABAAIDBQYSMREiMkFR/8QAFQEBAQAAAAAAAAAAAAAAAAAAAwX/xAAXEQADAQAAAAAAAAAAAAAAAAAAAREx/9oADAMBAAIRAxEAPwCAyFJ3U08ExHTO/e5wIPLHltuO9UREukVun//Z\",\"blurWidth\":8,\"blurHeight\":8},\"summary\":\"An engineering focused programming language I am developing\",\"tags\":[\"Python\",\"compilers\",\"parsers\",\"LLVM\",\"Programming Languages\"],\"route\":\"dewy\"},{\"title\":\"Generalized Parsing\",\"lastUpdated\":\"2022-02-06\",\"imgSrc\":{\"src\":\"/_next/static/media/dewy_dandelion.e2efa7ee.jpg\",\"height\":1600,\"width\":1600,\"blurDataURL\":\"data:image/jpeg;base64,/9j/2wBDAAoHBwgHBgoICAgLCgoLDhgQDg0NDh0VFhEYIx8lJCIfIiEmKzcvJik0KSEiMEExNDk7Pj4+JS5ESUM8SDc9Pjv/2wBDAQoLCw4NDhwQEBw7KCIoOzs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozv/wAARCAAIAAgDASIAAhEBAxEB/8QAFQABAQAAAAAAAAAAAAAAAAAAAAX/xAAgEAABAgUFAAAAAAAAAAAAAAABAAIDBQYSMREiMkFR/8QAFQEBAQAAAAAAAAAAAAAAAAAAAwX/xAAXEQADAQAAAAAAAAAAAAAAAAAAAREx/9oADAMBAAIRAxEAPwCAyFJ3U08ExHTO/e5wIPLHltuO9UREukVun//Z\",\"blurWidth\":8,\"blurHeight\":8},\"summary\":\"Previous work on the Dewy Programming Language, namely a custom SRNGLR parser written entirely in C\",\"tags\":[\"C\",\"compilers\",\"parsers\",\"SRNGLR\",\"LLVM\"],\"route\":\"dewy_old\"},{\"title\":\"UR5 Draw Robot\",\"imgSrc\":{\"src\":\"/_next/static/media/mona_lisa_contour.9bc5cbc9.jpg\",\"height\":1016,\"width\":1600,\"blurDataURL\":\"data:image/jpeg;base64,/9j/2wBDAAoHBwgHBgoICAgLCgoLDhgQDg0NDh0VFhEYIx8lJCIfIiEmKzcvJik0KSEiMEExNDk7Pj4+JS5ESUM8SDc9Pjv/2wBDAQoLCw4NDhwQEBw7KCIoOzs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozv/wAARCAAFAAgDASIAAhEBAxEB/8QAFQABAQAAAAAAAAAAAAAAAAAAAAX/xAAeEAACAgEFAQAAAAAAAAAAAAABAgAEAwUHEiFRsf/EABUBAQEAAAAAAAAAAAAAAAAAAAEC/8QAFxEAAwEAAAAAAAAAAAAAAAAAAAExAv/aAAwDAQACEQMRAD8AtbT3HvV9WGZVPB8RHXqsT8iIgoVqn//Z\",\"blurWidth\":8,\"blurHeight\":5},\"summary\":\"UR5 robot arm project\",\"lastUpdated\":\"December 2017\",\"tags\":[\"Matlab\",\"UR5 robot\",\"ROS\"],\"route\":\"drawbot\"},{\"title\":\"Hacking Harmony or The Demon Chipmunk Choir\",\"imgSrc\":{\"src\":\"/_next/static/media/logo.43586adb.png\",\"height\":960,\"width\":960,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAMAAADz0U65AAAAG1BMVEUHBwcwMDAAAABMaXEAAAAAAAAgICAFBQUmJiYApgMbAAAACHRSTlP9/C8AtOqwLojbm7gAAAAJcEhZcwAACxMAAAsTAQCanBgAAAAxSURBVHicPYtbCgAwCMNSH9P7n3joYNCPQFK8AsIcS4A0DkhwkHq30AOjetSP3738AhZmAKbLVdBfAAAAAElFTkSuQmCC\",\"blurWidth\":8,\"blurHeight\":8},\"github\":\"Ensemble\",\"summary\":\"2019 Peabody Hackathon Submission. Choral music synthesis via autotuned google text-to-speech, AKA the demon chipmunk choir\",\"tags\":[\"Google text-to-speech API\",\"matlab\",\"python\"],\"route\":\"ensemble_peabody\"},{\"title\":\"Escort Mission 2020\",\"imgSrc\":{\"src\":\"/_next/static/media/escort_mission_lamb.4c525bc4.png\",\"height\":128,\"width\":128,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAMAAADz0U65AAAAHlBMVEUA/gAAugD/+//h9+EAdAAirCKG/YZf2l9ri2uA/4BNpwkIAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAK0lEQVR4nE2KuREAMAyDbPnff+HcSU1ooMDsI1P2XWdURDEOOMYAo6dbj3gNJgBhtLya0gAAAABJRU5ErkJggg==\",\"blurWidth\":8,\"blurHeight\":8},\"github\":\"escort_mission_2020\",\"summary\":\"Submission for the 2020 GMTK Game Jam\",\"tags\":[\"Godot\",\"GDScript\",\"2D game\"],\"route\":\"escort_mission\"},{\"title\":\"Foxing Animatronic\",\"imgSrc\":{\"src\":\"/_next/static/media/foxing_animatronic.91d20002.png\",\"height\":1252,\"width\":1540,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAHCAMAAAACh/xsAAAAJ1BMVEUGFwsJIxEILhUiJQkdSRwWIQoUORYULA8RRSArMAYZEwYyVzM6OglI+AgfAAAACXBIWXMAAAsTAAALEwEAmpwYAAAANElEQVR4nBXKuREAIAwEsT2/GOi/XgbFoqs9I6DvdY8CW7O9DBSzvQ3OKFOCE5Vp+mdJBg8iegD5GB/ChgAAAABJRU5ErkJggg==\",\"blurWidth\":8,\"blurHeight\":7},\"summary\":\"Manually actuated animatronic robot featured in the Foxing music video 'Slapstick'\",\"lastUpdated\":\"June 2018\",\"tags\":[\"Solidworks\",\"mechanical design\",\"animatronic\",\"Foxing\",\"music\"],\"route\":\"foxing_animatronic\"},{\"title\":\"Mechatronics Robots\",\"imgSrc\":{\"src\":\"/_next/static/media/logo.43586adb.png\",\"height\":960,\"width\":960,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAMAAADz0U65AAAAG1BMVEUHBwcwMDAAAABMaXEAAAAAAAAgICAFBQUmJiYApgMbAAAACHRSTlP9/C8AtOqwLojbm7gAAAAJcEhZcwAACxMAAAsTAQCanBgAAAAxSURBVHicPYtbCgAwCMNSH9P7n3joYNCPQFK8AsIcS4A0DkhwkHq30AOjetSP3738AhZmAKbLVdBfAAAAAElFTkSuQmCC\",\"blurWidth\":8,\"blurHeight\":8},\"summary\":\"Robots from mechatronics\",\"lastUpdated\":\"May 2019\",\"tags\":[\"Arduino\",\"C++\",\"SolidWorks\",\"mechanical design\"],\"route\":\"mechatronics\"},{\"title\":\"Mehve (Working Title)\",\"imgSrc\":{\"src\":\"/_next/static/media/logo.43586adb.png\",\"height\":960,\"width\":960,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAMAAADz0U65AAAAG1BMVEUHBwcwMDAAAABMaXEAAAAAAAAgICAFBQUmJiYApgMbAAAACHRSTlP9/C8AtOqwLojbm7gAAAAJcEhZcwAACxMAAAsTAQCanBgAAAAxSURBVHicPYtbCgAwCMNSH9P7n3joYNCPQFK8AsIcS4A0DkhwkHq30AOjetSP3738AhZmAKbLVdBfAAAAAElFTkSuQmCC\",\"blurWidth\":8,\"blurHeight\":8},\"github\":\"mehve\",\"summary\":\"3D adventure game inspire by \\\"Nausicaa of the Valley of the Wind\\\"\",\"tags\":[\"Godot\",\"GDScript\",\"3D game\"],\"route\":\"mehve\"},{\"title\":\"Musical DL\",\"imgSrc\":{\"src\":\"/_next/static/media/logo.43586adb.png\",\"height\":960,\"width\":960,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAMAAADz0U65AAAAG1BMVEUHBwcwMDAAAABMaXEAAAAAAAAgICAFBQUmJiYApgMbAAAACHRSTlP9/C8AtOqwLojbm7gAAAAJcEhZcwAACxMAAAsTAQCanBgAAAAxSURBVHicPYtbCgAwCMNSH9P7n3joYNCPQFK8AsIcS4A0DkhwkHq30AOjetSP3738AhZmAKbLVdBfAAAAAElFTkSuQmCC\",\"blurWidth\":8,\"blurHeight\":8},\"github\":\"MusicalDL\",\"summary\":\"Using deep learning to generate choral music in the style of JS Bach\",\"tags\":[\"Python\",\"Pytorch\",\"AI/ML\",\"choral\",\"music\",\"generation\"],\"route\":\"musical_dl\"},{\"title\":\"pOngBot\",\"imgSrc\":{\"src\":\"/_next/static/media/logo.43586adb.png\",\"height\":960,\"width\":960,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAMAAADz0U65AAAAG1BMVEUHBwcwMDAAAABMaXEAAAAAAAAgICAFBQUmJiYApgMbAAAACHRSTlP9/C8AtOqwLojbm7gAAAAJcEhZcwAACxMAAAsTAQCanBgAAAAxSURBVHicPYtbCgAwCMNSH9P7n3joYNCPQFK8AsIcS4A0DkhwkHq30AOjetSP3738AhZmAKbLVdBfAAAAAElFTkSuQmCC\",\"blurWidth\":8,\"blurHeight\":8},\"summary\":\"Autonomous beer pong playing robot\",\"lastUpdated\":\"June 2020\",\"tags\":[\"Arduino\",\"C++\",\"computer vision\",\"Viola-Jones\",\"mechanical design\"],\"route\":\"pongbot\"},{\"title\":\"PRS19: Fret Press Robot\",\"imgSrc\":{\"src\":\"/_next/static/media/prs2019_preview.aed05a2a.png\",\"height\":2093,\"width\":3061,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAFCAMAAABPT11nAAAAPFBMVEVJPTmhmIiCa1SBfXdBQD1IOzB3bGA6My5dUkyXlpNPRTyio6ChpadSTUm0q5e+taCun2xwYl2qrq5mXU/I9hK/AAAACXBIWXMAAAsTAAALEwEAmpwYAAAAL0lEQVR4nAXBhwEAIAjAsKoo4B7//2rCXFZLjoGwh4poIj5TJRfOsAok3G/v3toHGpkBOY6KaOIAAAAASUVORK5CYII=\",\"blurWidth\":8,\"blurHeight\":5},\"github\":\"PRS_robot\",\"summary\":\"Automatic guitar fret press robot. Mechanical Engineering Master's Design captsone project\",\"tags\":[\"C++\",\"Arduino\",\"mechanical design\"],\"route\":\"prs19\"},{\"title\":\"Rewind\",\"imgSrc\":{\"src\":\"/_next/static/media/rewind_title.a1e43a09.png\",\"height\":540,\"width\":960,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAFCAMAAABPT11nAAAAElBMVEUqHjguITs4J0JmWW1PRFo/MUqO6aYhAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAH0lEQVR4nGNggAMmJkYmRhCDhZmFmZUBxGRkgIhAAQADKgAhbD4/MgAAAABJRU5ErkJggg==\",\"blurWidth\":8,\"blurHeight\":5},\"summary\":\"2018 Video Game Desgn (EN.601.355) capstone project\",\"lastUpdated\":\"May 2018\",\"tags\":[\"Unity\",\"C#\",\"2D game\"],\"route\":\"rewind\"},{\"title\":\"RoboJay\",\"imgSrc\":{\"src\":\"/_next/static/media/logo.43586adb.png\",\"height\":960,\"width\":960,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAMAAADz0U65AAAAG1BMVEUHBwcwMDAAAABMaXEAAAAAAAAgICAFBQUmJiYApgMbAAAACHRSTlP9/C8AtOqwLojbm7gAAAAJcEhZcwAACxMAAAsTAQCanBgAAAAxSURBVHicPYtbCgAwCMNSH9P7n3joYNCPQFK8AsIcS4A0DkhwkHq30AOjetSP3738AhZmAKbLVdBfAAAAAElFTkSuQmCC\",\"blurWidth\":8,\"blurHeight\":8},\"lastUpdated\":\"May 2018\",\"summary\":\"A balancing robot designed to give campus tours to incoming JHU freshmen\",\"tags\":[\"robotics\",\"feedback control\",\"navigation\",\"BeagleBone\",\"ROS\"],\"route\":\"robojay\"},{\"title\":\"High Power Rocketry\",\"imgSrc\":{\"src\":\"/_next/static/media/rebel_scum.34e7823c.jpg\",\"height\":1365,\"width\":2048,\"blurDataURL\":\"data:image/jpeg;base64,/9j/2wBDAAoHBwgHBgoICAgLCgoLDhgQDg0NDh0VFhEYIx8lJCIfIiEmKzcvJik0KSEiMEExNDk7Pj4+JS5ESUM8SDc9Pjv/2wBDAQoLCw4NDhwQEBw7KCIoOzs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozv/wAARCAAFAAgDASIAAhEBAxEB/8QAFQABAQAAAAAAAAAAAAAAAAAAAAP/xAAaEAACAgMAAAAAAAAAAAAAAAAAARESIjFB/8QAFQEBAQAAAAAAAAAAAAAAAAAAAgP/xAAXEQADAQAAAAAAAAAAAAAAAAAAAhNR/9oADAMBAAIRAxEAPwC6o4w5OwATo+immH//2Q==\",\"blurWidth\":8,\"blurHeight\":5},\"summary\":\"Level 1 \u0026 2 High Powered Rocket built with the Johns Hopkins Rocketry Club, and Spaceport America Cup 2018\",\"lastUpdated\":\"January 2018\",\"tags\":[\"High Power Rocketry\",\"Arduino\",\"C++\",\"mechanical design\",\"Tripoli\"],\"route\":\"rocketry\"},{\"title\":\"so voice!\",\"imgSrc\":{\"src\":\"/_next/static/media/YeArlingtonMusickeLabLogo.cf893b61.png\",\"height\":960,\"width\":960,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAMAAADz0U65AAAAFVBMVEUEBARFRUVQUFA3NzckJCQXFxdfX192C4FUAAAACXBIWXMAAAsTAAALEwEAmpwYAAAALElEQVR4nE2LtxEAMAyE+CDtP7JPnakoAH60CgwNFQr2ibdytUhjT3xt8q8PDVwAX2ljebUAAAAASUVORK5CYII=\",\"blurWidth\":8,\"blurHeight\":8},\"lastUpdated\":\"December 2022\",\"summary\":\"Choral music synthesis with deep learning (Continuation of Musical DL)\",\"tags\":[\"Python\",\"Pytorch\",\"AI/ML\",\"choral\",\"music\",\"synthesis\"],\"route\":\"so_voice\"},{\"title\":\"Terminal Ray Tracer\",\"imgSrc\":{\"src\":\"/_next/static/media/terminal_ray_tracer.00db7e4a.png\",\"height\":2043,\"width\":2881,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAGCAMAAADJ2y/JAAAAbFBMVEWSamvNrLWWP0yUKVeYinmmnKTsEheTcnnmh4+Xfo6pV2GMMDasvsa5aXiPRVFVs2uOWF9WnGxXtVObh4ypREzbYmnsPkXIba/y/P10bHmfbcouPtDAMDdJbZOtmERQbkXfwcqTb3g+yNdOcdnEQLLCAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAOklEQVR4nAXBBQKAIAAAsSMl7MZG//9HN/Igu6YtYDT+7qnhSK++tI+IcH5BViXZqn0Tk8M8Ti3rbH9KhwLIHy1s0QAAAABJRU5ErkJggg==\",\"blurWidth\":8,\"blurHeight\":6},\"github\":\"TerminalRayTracer\",\"summary\":\"A dependency-free ray tracer written in C that runs directly in a linux terminal\",\"route\":\"terminal_ray_tracer\"},{\"title\":\"Cloud Timelapse\",\"imgSrc\":{\"src\":\"/_next/static/media/timelapse.b57dd258.jpg\",\"height\":3468,\"width\":4624,\"blurDataURL\":\"data:image/jpeg;base64,/9j/2wBDAAoHBwgHBgoICAgLCgoLDhgQDg0NDh0VFhEYIx8lJCIfIiEmKzcvJik0KSEiMEExNDk7Pj4+JS5ESUM8SDc9Pjv/2wBDAQoLCw4NDhwQEBw7KCIoOzs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozv/wAARCAAGAAgDASIAAhEBAxEB/8QAFQABAQAAAAAAAAAAAAAAAAAAAAP/xAAcEAACAgIDAAAAAAAAAAAAAAAAAQIFAxETYdH/xAAVAQEBAAAAAAAAAAAAAAAAAAADBP/EABYRAQEBAAAAAAAAAAAAAAAAAAEAEf/aAAwDAQACEQMRAD8AlG4r56fBlT6ivQAUqwYX/9k=\",\"blurWidth\":8,\"blurHeight\":6},\"github\":\"timelapse\",\"summary\":\"A simple python project for taking timelapses of clouds from a webcam\",\"tags\":[\"Python\",\"OpenCV\",\"Raspberry Pi\",\"timelapse\",\"clouds\"],\"route\":\"timelapse\"},{\"title\":\"uSkipSpoilers\",\"imgSrc\":{\"src\":\"/_next/static/media/logo.43586adb.png\",\"height\":960,\"width\":960,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAMAAADz0U65AAAAG1BMVEUHBwcwMDAAAABMaXEAAAAAAAAgICAFBQUmJiYApgMbAAAACHRSTlP9/C8AtOqwLojbm7gAAAAJcEhZcwAACxMAAAsTAQCanBgAAAAxSURBVHicPYtbCgAwCMNSH9P7n3joYNCPQFK8AsIcS4A0DkhwkHq30AOjetSP3738AhZmAKbLVdBfAAAAAElFTkSuQmCC\",\"blurWidth\":8,\"blurHeight\":8},\"github\":\"uSkipSpoilers\",\"summary\":\"A small chrome extension for blocking spoilers in YouTube videos\",\"tags\":[\"React\",\"TypeScript\",\"Chrome\",\"Extension\"],\"route\":\"uskipspoilers\"},{\"title\":\"This Website\",\"github\":\"david-andrew.github.io\",\"imgSrc\":{\"src\":\"/_next/static/media/logo.43586adb.png\",\"height\":960,\"width\":960,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAMAAADz0U65AAAAG1BMVEUHBwcwMDAAAABMaXEAAAAAAAAgICAFBQUmJiYApgMbAAAACHRSTlP9/C8AtOqwLojbm7gAAAAJcEhZcwAACxMAAAsTAQCanBgAAAAxSURBVHicPYtbCgAwCMNSH9P7n3joYNCPQFK8AsIcS4A0DkhwkHq30AOjetSP3738AhZmAKbLVdBfAAAAAElFTkSuQmCC\",\"blurWidth\":8,\"blurHeight\":8},\"externalLink\":\"https://github.com/david-andrew/david-andrew.github.io\",\"summary\":\"This website, written in react/typescript\",\"tags\":[\"Next.js\",\"React\",\"TypeScript\",\"Tailwind CSS\",\"WebAssembly\"],\"route\":\"website\"},{\"title\":\"WSE18: Machine Shop Biometric Interlock\",\"imgSrc\":{\"src\":\"/_next/static/media/wse18.7405315e.png\",\"height\":2054,\"width\":2456,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAHCAMAAAACh/xsAAAAUVBMVEU8OTSVjYNlX1nIwbpLQjaqnpBOSUOJgHU8MCsyKSXo4dUfHh1iU0R8aWMUDAdoYlull4ialI2BZkzBuKyNdleyrKaQosO9iGCNY0PTj19hbYD9ZLzaAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAO0lEQVR4nAXBhQHAMAwDMBdCZRj/f+gkiLgdPDJcpJS6MbxKOJEBa1pH5whYpXl9DfEoc2A90MJC671/OekCOef5C1cAAAAASUVORK5CYII=\",\"blurWidth\":8,\"blurHeight\":7},\"summary\":\"Biometric security interlock system. Mechanical Engineering Senior Design capstone project\",\"lastUpdated\":\"May 2018\",\"tags\":[\"Raspberry Pi\",\"Python\",\"C++\",\"Qt\",\"interlock\",\"fingerprint\",\"biometric\"],\"route\":\"wse18\"},{\"title\":\"Ziggy V (Working Title)\",\"imgSrc\":{\"src\":\"/_next/static/media/logo.43586adb.png\",\"height\":960,\"width\":960,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAMAAADz0U65AAAAG1BMVEUHBwcwMDAAAABMaXEAAAAAAAAgICAFBQUmJiYApgMbAAAACHRSTlP9/C8AtOqwLojbm7gAAAAJcEhZcwAACxMAAAsTAQCanBgAAAAxSURBVHicPYtbCgAwCMNSH9P7n3joYNCPQFK8AsIcS4A0DkhwkHq30AOjetSP3738AhZmAKbLVdBfAAAAAElFTkSuQmCC\",\"blurWidth\":8,\"blurHeight\":8},\"summary\":\"Concept for a Real-Time-Strategy crossed with First-Person-Shooter\",\"lastUpdated\":\"January 2021\",\"tags\":[\"Godot\",\"GDScript\",\"FPS x RTS\",\"3D game\"],\"route\":\"ziggy_v\"}]}],[\"$\",\"$Lc\",null,{\"children\":[\"$\",\"$Ld\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"loading\":[\"$\",\"div\",null,{\"className\":\"fixed w-screen h-screen bg-black flex justify-center items-center\",\"children\":[\"$\",\"div\",null,{\"role\":\"status\",\"children\":[[\"$\",\"svg\",null,{\"aria-hidden\":\"true\",\"className\":\"w-32 h-32 mr-2 text-gray-200 animate-spin dark:text-gray-600 fill-accent\",\"viewBox\":\"0 0 100 101\",\"fill\":\"none\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"children\":[[\"$\",\"path\",null,{\"d\":\"M100 50.5908C100 78.2051 77.6142 100.591 50 100.591C22.3858 100.591 0 78.2051 0 50.5908C0 22.9766 22.3858 0.59082 50 0.59082C77.6142 0.59082 100 22.9766 100 50.5908ZM9.08144 50.5908C9.08144 73.1895 27.4013 91.5094 50 91.5094C72.5987 91.5094 90.9186 73.1895 90.9186 50.5908C90.9186 27.9921 72.5987 9.67226 50 9.67226C27.4013 9.67226 9.08144 27.9921 9.08144 50.5908Z\",\"fill\":\"currentColor\"}],[\"$\",\"path\",null,{\"d\":\"M93.9676 39.0409C96.393 38.4038 97.8624 35.9116 97.0079 33.5539C95.2932 28.8227 92.871 24.3692 89.8167 20.348C85.8452 15.1192 80.8826 10.7238 75.2124 7.41289C69.5422 4.10194 63.2754 1.94025 56.7698 1.05124C51.7666 0.367541 46.6976 0.446843 41.7345 1.27873C39.2613 1.69328 37.813 4.19778 38.4501 6.62326C39.0873 9.04874 41.5694 10.4717 44.0505 10.1071C47.8511 9.54855 51.7191 9.52689 55.5402 10.0491C60.8642 10.7766 65.9928 12.5457 70.6331 15.2552C75.2735 17.9648 79.3347 21.5619 82.5849 25.841C84.9175 28.9121 86.7997 32.2913 88.1811 35.8758C89.083 38.2158 91.5421 39.6781 93.9676 39.0409Z\",\"fill\":\"currentFill\"}]]}],[\"$\",\"span\",null,{\"className\":\"sr-only\",\"children\":\"Loading...\"}]]}]}],\"loadingStyles\":[],\"hasLoading\":true,\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"template\":[\"$\",\"$Le\",null,{}],\"templateStyles\":\"$undefined\",\"notFound\":[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":\"404\"}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],\"notFoundStyles\":[],\"childProp\":{\"current\":[null,\"$Lf\",null],\"segment\":\"projects\"},\"styles\":[]}]}]]}]}],[\"$\",\"$L10\",null,{}]]}]}]]}]\n"])</script><script>self.__next_f.push([1,"6:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"1\",{\"children\":\"David Samson\"}],[\"$\",\"meta\",\"2\",{\"name\":\"description\",\"content\":\"Generated by create next app\"}],[\"$\",\"meta\",\"3\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"link\",\"4\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}],[\"$\",\"meta\",\"5\",{\"name\":\"next-size-adjust\"}]]\n"])</script><script>self.__next_f.push([1,"11:I{\"id\":52160,\"chunks\":[\"6685:static/chunks/6685-d55f1e0fd750c950.js\",\"8213:static/chunks/8213-ef98b168d3fb6523.js\",\"3337:static/chunks/3337-92bca57b67600e26.js\",\"5570:static/chunks/app/projects/layout-94b7229fd8c860b6.js\"],\"name\":\"Heading\",\"async\":false}\n14:I{\"id\":27250,\"chunks\":[\"6685:static/chunks/6685-d55f1e0fd750c950.js\",\"8213:static/chunks/8213-ef98b168d3fb6523.js\",\"3337:static/chunks/3337-92bca57b67600e26.js\",\"5570:static/chunks/app/projects/layout-94b7229fd8c860b6.js\"],\"name\":\"NavbarDummy\",\"async\""])</script><script>self.__next_f.push([1,":false}\n"])</script><script>self.__next_f.push([1,"f:[\"$\",\"div\",null,{\"className\":\"mx-auto px-4 sm:px-6 lg:px-8 max-w-[1190px]\",\"children\":[[\"$\",\"$L11\",null,{\"projects\":[{\"title\":\"Blob Opera Performances\",\"imgSrc\":{\"src\":\"/_next/static/media/blob_opera_nox.e6f3aa2a.png\",\"height\":414,\"width\":512,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAGCAMAAADJ2y/JAAAAJ1BMVEU4EgowEQlEIRV0Vzx9ZEo+JhlXOyBCT1RTMx0+LyVEUlxuTS5AS1HBZ0aTAAAACXBIWXMAAAsTAAALEwEAmpwYAAAALklEQVR4nC3IuREAIAwDMMcOeYD95+XgKNQIhpahHYwUawuGoQuM6az0OwvPnwMUSwDO9qMceAAAAABJRU5ErkJggg==\",\"blurWidth\":8,\"blurHeight\":6},\"summary\":\"Virtual choir performances leveraging the blob opera as a front end for voice synthesis\",\"lastUpdated\":\"February 2021\",\"tags\":[\"Python\",\"Blob Opera\",\"choir\",\"music\",\"synthesis\"],\"route\":\"blob_opera\"},{\"title\":\"Boat Simulator\",\"imgSrc\":{\"src\":\"/_next/static/media/boat_simulator.7cc391fd.jpg\",\"height\":1280,\"width\":2048,\"blurDataURL\":\"data:image/jpeg;base64,/9j/2wBDAAoHBwgHBgoICAgLCgoLDhgQDg0NDh0VFhEYIx8lJCIfIiEmKzcvJik0KSEiMEExNDk7Pj4+JS5ESUM8SDc9Pjv/2wBDAQoLCw4NDhwQEBw7KCIoOzs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozv/wAARCAAFAAgDASIAAhEBAxEB/8QAFQABAQAAAAAAAAAAAAAAAAAAAAb/xAAdEAABAgcAAAAAAAAAAAAAAAAAAQQCAxESFSFT/8QAFAEBAAAAAAAAAAAAAAAAAAAABf/EABYRAAMAAAAAAAAAAAAAAAAAAAABEf/aAAwDAQACEQMRAD8AkFks7K49tuLmABWIOrP/2Q==\",\"blurWidth\":8,\"blurHeight\":5},\"summary\":\"Spring 2017 HopHacks submission\",\"lastUpdated\":\"March 2017\",\"tags\":[\"Unity\",\"C#\",\"3D game\"],\"route\":\"boat_simulator\"},{\"title\":\"Bueller Board\",\"imgSrc\":{\"src\":\"/_next/static/media/logo.43586adb.png\",\"height\":960,\"width\":960,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAMAAADz0U65AAAAG1BMVEUHBwcwMDAAAABMaXEAAAAAAAAgICAFBQUmJiYApgMbAAAACHRSTlP9/C8AtOqwLojbm7gAAAAJcEhZcwAACxMAAAsTAQCanBgAAAAxSURBVHicPYtbCgAwCMNSH9P7n3joYNCPQFK8AsIcS4A0DkhwkHq30AOjetSP3738AhZmAKbLVdBfAAAAAElFTkSuQmCC\",\"blurWidth\":8,\"blurHeight\":8},\"summary\":\"Fall 2015 HopHacks submission: Midi keyboard that used user provided audio samples, a.k.a. the 'goat keyboard'\",\"lastUpdated\":\"September 2015\",\"tags\":[\"midi\",\"music\"],\"route\":\"bueller_board\"},{\"title\":\"Composer\",\"imgSrc\":{\"src\":\"/_next/static/media/YeArlingtonMusickeLabLogo.cf893b61.png\",\"height\":960,\"width\":960,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAMAAADz0U65AAAAFVBMVEUEBARFRUVQUFA3NzckJCQXFxdfX192C4FUAAAACXBIWXMAAAsTAAALEwEAmpwYAAAALElEQVR4nE2LtxEAMAyE+CDtP7JPnakoAH60CgwNFQr2ibdytUhjT3xt8q8PDVwAX2ljebUAAAAASUVORK5CYII=\",\"blurWidth\":8,\"blurHeight\":8},\"summary\":\"React based composing software that acts as a front-end for LilyPond\",\"lastUpdated\":\"January 2021\",\"tags\":[\"React\",\"TypeScript\",\"SMuFL\",\"LilyPond\",\"music\",\"composition\"],\"route\":\"composer\"},{\"title\":\"Choir Compositions\",\"imgSrc\":{\"src\":\"/_next/static/media/music_staff.3145785a.png\",\"height\":1616,\"width\":2745,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAFCAMAAABPT11nAAAAHlBMVEUGBgZISEhSUlIeHh5paWk+Pj4vLy9cXFx7e3ufn5/bdycMAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAJ0lEQVR4nCXBtwEAIAwDMLe0/x9mQIKFjwN3jZBwxGowpFZGm7cpPAkxAH3f0FE4AAAAAElFTkSuQmCC\",\"blurWidth\":8,\"blurHeight\":5},\"summary\":\"\",\"lastUpdated\":\"May 2015\",\"tags\":[\"music\",\"choral\",\"composition\"],\"route\":\"compositions\"},{\"title\":\"Dewy Programming Language\",\"github\":\"dewy\",\"imgSrc\":{\"src\":\"/_next/static/media/dewy_dandelion.e2efa7ee.jpg\",\"height\":1600,\"width\":1600,\"blurDataURL\":\"data:image/jpeg;base64,/9j/2wBDAAoHBwgHBgoICAgLCgoLDhgQDg0NDh0VFhEYIx8lJCIfIiEmKzcvJik0KSEiMEExNDk7Pj4+JS5ESUM8SDc9Pjv/2wBDAQoLCw4NDhwQEBw7KCIoOzs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozv/wAARCAAIAAgDASIAAhEBAxEB/8QAFQABAQAAAAAAAAAAAAAAAAAAAAX/xAAgEAABAgUFAAAAAAAAAAAAAAABAAIDBQYSMREiMkFR/8QAFQEBAQAAAAAAAAAAAAAAAAAAAwX/xAAXEQADAQAAAAAAAAAAAAAAAAAAAREx/9oADAMBAAIRAxEAPwCAyFJ3U08ExHTO/e5wIPLHltuO9UREukVun//Z\",\"blurWidth\":8,\"blurHeight\":8},\"summary\":\"An engineering focused programming language I am developing\",\"tags\":[\"Python\",\"compilers\",\"parsers\",\"LLVM\",\"Programming Languages\"],\"route\":\"dewy\"},{\"title\":\"Generalized Parsing\",\"lastUpdated\":\"2022-02-06\",\"imgSrc\":{\"src\":\"/_next/static/media/dewy_dandelion.e2efa7ee.jpg\",\"height\":1600,\"width\":1600,\"blurDataURL\":\"data:image/jpeg;base64,/9j/2wBDAAoHBwgHBgoICAgLCgoLDhgQDg0NDh0VFhEYIx8lJCIfIiEmKzcvJik0KSEiMEExNDk7Pj4+JS5ESUM8SDc9Pjv/2wBDAQoLCw4NDhwQEBw7KCIoOzs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozv/wAARCAAIAAgDASIAAhEBAxEB/8QAFQABAQAAAAAAAAAAAAAAAAAAAAX/xAAgEAABAgUFAAAAAAAAAAAAAAABAAIDBQYSMREiMkFR/8QAFQEBAQAAAAAAAAAAAAAAAAAAAwX/xAAXEQADAQAAAAAAAAAAAAAAAAAAAREx/9oADAMBAAIRAxEAPwCAyFJ3U08ExHTO/e5wIPLHltuO9UREukVun//Z\",\"blurWidth\":8,\"blurHeight\":8},\"summary\":\"Previous work on the Dewy Programming Language, namely a custom SRNGLR parser written entirely in C\",\"tags\":[\"C\",\"compilers\",\"parsers\",\"SRNGLR\",\"LLVM\"],\"route\":\"dewy_old\"},{\"title\":\"UR5 Draw Robot\",\"imgSrc\":{\"src\":\"/_next/static/media/mona_lisa_contour.9bc5cbc9.jpg\",\"height\":1016,\"width\":1600,\"blurDataURL\":\"data:image/jpeg;base64,/9j/2wBDAAoHBwgHBgoICAgLCgoLDhgQDg0NDh0VFhEYIx8lJCIfIiEmKzcvJik0KSEiMEExNDk7Pj4+JS5ESUM8SDc9Pjv/2wBDAQoLCw4NDhwQEBw7KCIoOzs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozv/wAARCAAFAAgDASIAAhEBAxEB/8QAFQABAQAAAAAAAAAAAAAAAAAAAAX/xAAeEAACAgEFAQAAAAAAAAAAAAABAgAEAwUHEiFRsf/EABUBAQEAAAAAAAAAAAAAAAAAAAEC/8QAFxEAAwEAAAAAAAAAAAAAAAAAAAExAv/aAAwDAQACEQMRAD8AtbT3HvV9WGZVPB8RHXqsT8iIgoVqn//Z\",\"blurWidth\":8,\"blurHeight\":5},\"summary\":\"UR5 robot arm project\",\"lastUpdated\":\"December 2017\",\"tags\":[\"Matlab\",\"UR5 robot\",\"ROS\"],\"route\":\"drawbot\"},{\"title\":\"Hacking Harmony or The Demon Chipmunk Choir\",\"imgSrc\":{\"src\":\"/_next/static/media/logo.43586adb.png\",\"height\":960,\"width\":960,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAMAAADz0U65AAAAG1BMVEUHBwcwMDAAAABMaXEAAAAAAAAgICAFBQUmJiYApgMbAAAACHRSTlP9/C8AtOqwLojbm7gAAAAJcEhZcwAACxMAAAsTAQCanBgAAAAxSURBVHicPYtbCgAwCMNSH9P7n3joYNCPQFK8AsIcS4A0DkhwkHq30AOjetSP3738AhZmAKbLVdBfAAAAAElFTkSuQmCC\",\"blurWidth\":8,\"blurHeight\":8},\"github\":\"Ensemble\",\"summary\":\"2019 Peabody Hackathon Submission. Choral music synthesis via autotuned google text-to-speech, AKA the demon chipmunk choir\",\"tags\":[\"Google text-to-speech API\",\"matlab\",\"python\"],\"route\":\"ensemble_peabody\"},{\"title\":\"Escort Mission 2020\",\"imgSrc\":{\"src\":\"/_next/static/media/escort_mission_lamb.4c525bc4.png\",\"height\":128,\"width\":128,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAMAAADz0U65AAAAHlBMVEUA/gAAugD/+//h9+EAdAAirCKG/YZf2l9ri2uA/4BNpwkIAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAK0lEQVR4nE2KuREAMAyDbPnff+HcSU1ooMDsI1P2XWdURDEOOMYAo6dbj3gNJgBhtLya0gAAAABJRU5ErkJggg==\",\"blurWidth\":8,\"blurHeight\":8},\"github\":\"escort_mission_2020\",\"summary\":\"Submission for the 2020 GMTK Game Jam\",\"tags\":[\"Godot\",\"GDScript\",\"2D game\"],\"route\":\"escort_mission\"},{\"title\":\"Foxing Animatronic\",\"imgSrc\":{\"src\":\"/_next/static/media/foxing_animatronic.91d20002.png\",\"height\":1252,\"width\":1540,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAHCAMAAAACh/xsAAAAJ1BMVEUGFwsJIxEILhUiJQkdSRwWIQoUORYULA8RRSArMAYZEwYyVzM6OglI+AgfAAAACXBIWXMAAAsTAAALEwEAmpwYAAAANElEQVR4nBXKuREAIAwEsT2/GOi/XgbFoqs9I6DvdY8CW7O9DBSzvQ3OKFOCE5Vp+mdJBg8iegD5GB/ChgAAAABJRU5ErkJggg==\",\"blurWidth\":8,\"blurHeight\":7},\"summary\":\"Manually actuated animatronic robot featured in the Foxing music video 'Slapstick'\",\"lastUpdated\":\"June 2018\",\"tags\":[\"Solidworks\",\"mechanical design\",\"animatronic\",\"Foxing\",\"music\"],\"route\":\"foxing_animatronic\"},{\"title\":\"Mechatronics Robots\",\"imgSrc\":{\"src\":\"/_next/static/media/logo.43586adb.png\",\"height\":960,\"width\":960,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAMAAADz0U65AAAAG1BMVEUHBwcwMDAAAABMaXEAAAAAAAAgICAFBQUmJiYApgMbAAAACHRSTlP9/C8AtOqwLojbm7gAAAAJcEhZcwAACxMAAAsTAQCanBgAAAAxSURBVHicPYtbCgAwCMNSH9P7n3joYNCPQFK8AsIcS4A0DkhwkHq30AOjetSP3738AhZmAKbLVdBfAAAAAElFTkSuQmCC\",\"blurWidth\":8,\"blurHeight\":8},\"summary\":\"Robots from mechatronics\",\"lastUpdated\":\"May 2019\",\"tags\":[\"Arduino\",\"C++\",\"SolidWorks\",\"mechanical design\"],\"route\":\"mechatronics\"},{\"title\":\"Mehve (Working Title)\",\"imgSrc\":{\"src\":\"/_next/static/media/logo.43586adb.png\",\"height\":960,\"width\":960,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAMAAADz0U65AAAAG1BMVEUHBwcwMDAAAABMaXEAAAAAAAAgICAFBQUmJiYApgMbAAAACHRSTlP9/C8AtOqwLojbm7gAAAAJcEhZcwAACxMAAAsTAQCanBgAAAAxSURBVHicPYtbCgAwCMNSH9P7n3joYNCPQFK8AsIcS4A0DkhwkHq30AOjetSP3738AhZmAKbLVdBfAAAAAElFTkSuQmCC\",\"blurWidth\":8,\"blurHeight\":8},\"github\":\"mehve\",\"summary\":\"3D adventure game inspire by \\\"Nausicaa of the Valley of the Wind\\\"\",\"tags\":[\"Godot\",\"GDScript\",\"3D game\"],\"route\":\"mehve\"},{\"title\":\"Musical DL\",\"imgSrc\":{\"src\":\"/_next/static/media/logo.43586adb.png\",\"height\":960,\"width\":960,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAMAAADz0U65AAAAG1BMVEUHBwcwMDAAAABMaXEAAAAAAAAgICAFBQUmJiYApgMbAAAACHRSTlP9/C8AtOqwLojbm7gAAAAJcEhZcwAACxMAAAsTAQCanBgAAAAxSURBVHicPYtbCgAwCMNSH9P7n3joYNCPQFK8AsIcS4A0DkhwkHq30AOjetSP3738AhZmAKbLVdBfAAAAAElFTkSuQmCC\",\"blurWidth\":8,\"blurHeight\":8},\"github\":\"MusicalDL\",\"summary\":\"Using deep learning to generate choral music in the style of JS Bach\",\"tags\":[\"Python\",\"Pytorch\",\"AI/ML\",\"choral\",\"music\",\"generation\"],\"route\":\"musical_dl\"},{\"title\":\"pOngBot\",\"imgSrc\":{\"src\":\"/_next/static/media/logo.43586adb.png\",\"height\":960,\"width\":960,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAMAAADz0U65AAAAG1BMVEUHBwcwMDAAAABMaXEAAAAAAAAgICAFBQUmJiYApgMbAAAACHRSTlP9/C8AtOqwLojbm7gAAAAJcEhZcwAACxMAAAsTAQCanBgAAAAxSURBVHicPYtbCgAwCMNSH9P7n3joYNCPQFK8AsIcS4A0DkhwkHq30AOjetSP3738AhZmAKbLVdBfAAAAAElFTkSuQmCC\",\"blurWidth\":8,\"blurHeight\":8},\"summary\":\"Autonomous beer pong playing robot\",\"lastUpdated\":\"June 2020\",\"tags\":[\"Arduino\",\"C++\",\"computer vision\",\"Viola-Jones\",\"mechanical design\"],\"route\":\"pongbot\"},{\"title\":\"PRS19: Fret Press Robot\",\"imgSrc\":{\"src\":\"/_next/static/media/prs2019_preview.aed05a2a.png\",\"height\":2093,\"width\":3061,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAFCAMAAABPT11nAAAAPFBMVEVJPTmhmIiCa1SBfXdBQD1IOzB3bGA6My5dUkyXlpNPRTyio6ChpadSTUm0q5e+taCun2xwYl2qrq5mXU/I9hK/AAAACXBIWXMAAAsTAAALEwEAmpwYAAAAL0lEQVR4nAXBhwEAIAjAsKoo4B7//2rCXFZLjoGwh4poIj5TJRfOsAok3G/v3toHGpkBOY6KaOIAAAAASUVORK5CYII=\",\"blurWidth\":8,\"blurHeight\":5},\"github\":\"PRS_robot\",\"summary\":\"Automatic guitar fret press robot. Mechanical Engineering Master's Design captsone project\",\"tags\":[\"C++\",\"Arduino\",\"mechanical design\"],\"route\":\"prs19\"},{\"title\":\"Rewind\",\"imgSrc\":{\"src\":\"/_next/static/media/rewind_title.a1e43a09.png\",\"height\":540,\"width\":960,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAFCAMAAABPT11nAAAAElBMVEUqHjguITs4J0JmWW1PRFo/MUqO6aYhAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAH0lEQVR4nGNggAMmJkYmRhCDhZmFmZUBxGRkgIhAAQADKgAhbD4/MgAAAABJRU5ErkJggg==\",\"blurWidth\":8,\"blurHeight\":5},\"summary\":\"2018 Video Game Desgn (EN.601.355) capstone project\",\"lastUpdated\":\"May 2018\",\"tags\":[\"Unity\",\"C#\",\"2D game\"],\"route\":\"rewind\"},{\"title\":\"RoboJay\",\"imgSrc\":{\"src\":\"/_next/static/media/logo.43586adb.png\",\"height\":960,\"width\":960,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAMAAADz0U65AAAAG1BMVEUHBwcwMDAAAABMaXEAAAAAAAAgICAFBQUmJiYApgMbAAAACHRSTlP9/C8AtOqwLojbm7gAAAAJcEhZcwAACxMAAAsTAQCanBgAAAAxSURBVHicPYtbCgAwCMNSH9P7n3joYNCPQFK8AsIcS4A0DkhwkHq30AOjetSP3738AhZmAKbLVdBfAAAAAElFTkSuQmCC\",\"blurWidth\":8,\"blurHeight\":8},\"lastUpdated\":\"May 2018\",\"summary\":\"A balancing robot designed to give campus tours to incoming JHU freshmen\",\"tags\":[\"robotics\",\"feedback control\",\"navigation\",\"BeagleBone\",\"ROS\"],\"route\":\"robojay\"},{\"title\":\"High Power Rocketry\",\"imgSrc\":{\"src\":\"/_next/static/media/rebel_scum.34e7823c.jpg\",\"height\":1365,\"width\":2048,\"blurDataURL\":\"data:image/jpeg;base64,/9j/2wBDAAoHBwgHBgoICAgLCgoLDhgQDg0NDh0VFhEYIx8lJCIfIiEmKzcvJik0KSEiMEExNDk7Pj4+JS5ESUM8SDc9Pjv/2wBDAQoLCw4NDhwQEBw7KCIoOzs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozv/wAARCAAFAAgDASIAAhEBAxEB/8QAFQABAQAAAAAAAAAAAAAAAAAAAAP/xAAaEAACAgMAAAAAAAAAAAAAAAAAARESIjFB/8QAFQEBAQAAAAAAAAAAAAAAAAAAAgP/xAAXEQADAQAAAAAAAAAAAAAAAAAAAhNR/9oADAMBAAIRAxEAPwC6o4w5OwATo+immH//2Q==\",\"blurWidth\":8,\"blurHeight\":5},\"summary\":\"Level 1 \u0026 2 High Powered Rocket built with the Johns Hopkins Rocketry Club, and Spaceport America Cup 2018\",\"lastUpdated\":\"January 2018\",\"tags\":[\"High Power Rocketry\",\"Arduino\",\"C++\",\"mechanical design\",\"Tripoli\"],\"route\":\"rocketry\"},{\"title\":\"so voice!\",\"imgSrc\":{\"src\":\"/_next/static/media/YeArlingtonMusickeLabLogo.cf893b61.png\",\"height\":960,\"width\":960,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAMAAADz0U65AAAAFVBMVEUEBARFRUVQUFA3NzckJCQXFxdfX192C4FUAAAACXBIWXMAAAsTAAALEwEAmpwYAAAALElEQVR4nE2LtxEAMAyE+CDtP7JPnakoAH60CgwNFQr2ibdytUhjT3xt8q8PDVwAX2ljebUAAAAASUVORK5CYII=\",\"blurWidth\":8,\"blurHeight\":8},\"lastUpdated\":\"December 2022\",\"summary\":\"Choral music synthesis with deep learning (Continuation of Musical DL)\",\"tags\":[\"Python\",\"Pytorch\",\"AI/ML\",\"choral\",\"music\",\"synthesis\"],\"route\":\"so_voice\"},{\"title\":\"Terminal Ray Tracer\",\"imgSrc\":{\"src\":\"/_next/static/media/terminal_ray_tracer.00db7e4a.png\",\"height\":2043,\"width\":2881,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAGCAMAAADJ2y/JAAAAbFBMVEWSamvNrLWWP0yUKVeYinmmnKTsEheTcnnmh4+Xfo6pV2GMMDasvsa5aXiPRVFVs2uOWF9WnGxXtVObh4ypREzbYmnsPkXIba/y/P10bHmfbcouPtDAMDdJbZOtmERQbkXfwcqTb3g+yNdOcdnEQLLCAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAOklEQVR4nAXBBQKAIAAAsSMl7MZG//9HN/Igu6YtYDT+7qnhSK++tI+IcH5BViXZqn0Tk8M8Ti3rbH9KhwLIHy1s0QAAAABJRU5ErkJggg==\",\"blurWidth\":8,\"blurHeight\":6},\"github\":\"TerminalRayTracer\",\"summary\":\"A dependency-free ray tracer written in C that runs directly in a linux terminal\",\"route\":\"terminal_ray_tracer\"},{\"title\":\"Cloud Timelapse\",\"imgSrc\":{\"src\":\"/_next/static/media/timelapse.b57dd258.jpg\",\"height\":3468,\"width\":4624,\"blurDataURL\":\"data:image/jpeg;base64,/9j/2wBDAAoHBwgHBgoICAgLCgoLDhgQDg0NDh0VFhEYIx8lJCIfIiEmKzcvJik0KSEiMEExNDk7Pj4+JS5ESUM8SDc9Pjv/2wBDAQoLCw4NDhwQEBw7KCIoOzs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozv/wAARCAAGAAgDASIAAhEBAxEB/8QAFQABAQAAAAAAAAAAAAAAAAAAAAP/xAAcEAACAgIDAAAAAAAAAAAAAAAAAQIFAxETYdH/xAAVAQEBAAAAAAAAAAAAAAAAAAADBP/EABYRAQEBAAAAAAAAAAAAAAAAAAEAEf/aAAwDAQACEQMRAD8AlG4r56fBlT6ivQAUqwYX/9k=\",\"blurWidth\":8,\"blurHeight\":6},\"github\":\"timelapse\",\"summary\":\"A simple python project for taking timelapses of clouds from a webcam\",\"tags\":[\"Python\",\"OpenCV\",\"Raspberry Pi\",\"timelapse\",\"clouds\"],\"route\":\"timelapse\"},{\"title\":\"uSkipSpoilers\",\"imgSrc\":{\"src\":\"/_next/static/media/logo.43586adb.png\",\"height\":960,\"width\":960,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAMAAADz0U65AAAAG1BMVEUHBwcwMDAAAABMaXEAAAAAAAAgICAFBQUmJiYApgMbAAAACHRSTlP9/C8AtOqwLojbm7gAAAAJcEhZcwAACxMAAAsTAQCanBgAAAAxSURBVHicPYtbCgAwCMNSH9P7n3joYNCPQFK8AsIcS4A0DkhwkHq30AOjetSP3738AhZmAKbLVdBfAAAAAElFTkSuQmCC\",\"blurWidth\":8,\"blurHeight\":8},\"github\":\"uSkipSpoilers\",\"summary\":\"A small chrome extension for blocking spoilers in YouTube videos\",\"tags\":[\"React\",\"TypeScript\",\"Chrome\",\"Extension\"],\"route\":\"uskipspoilers\"},{\"title\":\"This Website\",\"github\":\"david-andrew.github.io\",\"imgSrc\":{\"src\":\"/_next/static/media/logo.43586adb.png\",\"height\":960,\"width\":960,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAMAAADz0U65AAAAG1BMVEUHBwcwMDAAAABMaXEAAAAAAAAgICAFBQUmJiYApgMbAAAACHRSTlP9/C8AtOqwLojbm7gAAAAJcEhZcwAACxMAAAsTAQCanBgAAAAxSURBVHicPYtbCgAwCMNSH9P7n3joYNCPQFK8AsIcS4A0DkhwkHq30AOjetSP3738AhZmAKbLVdBfAAAAAElFTkSuQmCC\",\"blurWidth\":8,\"blurHeight\":8},\"externalLink\":\"https://github.com/david-andrew/david-andrew.github.io\",\"summary\":\"This website, written in react/typescript\",\"tags\":[\"Next.js\",\"React\",\"TypeScript\",\"Tailwind CSS\",\"WebAssembly\"],\"route\":\"website\"},{\"title\":\"WSE18: Machine Shop Biometric Interlock\",\"imgSrc\":{\"src\":\"/_next/static/media/wse18.7405315e.png\",\"height\":2054,\"width\":2456,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAHCAMAAAACh/xsAAAAUVBMVEU8OTSVjYNlX1nIwbpLQjaqnpBOSUOJgHU8MCsyKSXo4dUfHh1iU0R8aWMUDAdoYlull4ialI2BZkzBuKyNdleyrKaQosO9iGCNY0PTj19hbYD9ZLzaAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAO0lEQVR4nAXBhQHAMAwDMBdCZRj/f+gkiLgdPDJcpJS6MbxKOJEBa1pH5whYpXl9DfEoc2A90MJC671/OekCOef5C1cAAAAASUVORK5CYII=\",\"blurWidth\":8,\"blurHeight\":7},\"summary\":\"Biometric security interlock system. Mechanical Engineering Senior Design capstone project\",\"lastUpdated\":\"May 2018\",\"tags\":[\"Raspberry Pi\",\"Python\",\"C++\",\"Qt\",\"interlock\",\"fingerprint\",\"biometric\"],\"route\":\"wse18\"},{\"title\":\"Ziggy V (Working Title)\",\"imgSrc\":{\"src\":\"/_next/static/media/logo.43586adb.png\",\"height\":960,\"width\":960,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAMAAADz0U65AAAAG1BMVEUHBwcwMDAAAABMaXEAAAAAAAAgICAFBQUmJiYApgMbAAAACHRSTlP9/C8AtOqwLojbm7gAAAAJcEhZcwAACxMAAAsTAQCanBgAAAAxSURBVHicPYtbCgAwCMNSH9P7n3joYNCPQFK8AsIcS4A0DkhwkHq30AOjetSP3738AhZmAKbLVdBfAAAAAElFTkSuQmCC\",\"blurWidth\":8,\"blurHeight\":8},\"summary\":\"Concept for a Real-Time-Strategy crossed with First-Person-Shooter\",\"lastUpdated\":\"January 2021\",\"tags\":[\"Godot\",\"GDScript\",\"FPS x RTS\",\"3D game\"],\"route\":\"ziggy_v\"}]}],[\"$\",\"$Ld\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"projects\",\"children\"],\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"hasLoading\":false,\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"template\":[\"$\",\"$Le\",null,{}],\"templateStyles\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"childProp\":{\"current\":[\"$\",\"$Ld\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"projects\",\"children\",\"dewy\",\"children\"],\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"hasLoading\":false,\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"template\":[\"$\",\"$Le\",null,{}],\"templateStyles\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"childProp\":{\"current\":[\"$L12\",\"$L13\",null],\"segment\":\"__PAGE__\"},\"styles\":[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/85fa6dafca566008.css\",\"precedence\":\"next\"}]]}],\"segment\":\"dewy\"},\"styles\":[]}],[\"$\",\"$L14\",null,{}]]}]\n"])</script><script>self.__next_f.push([1,"12:null\n"])</script><script>self.__next_f.push([1,"15:\"$Sreact.suspense\"\n16:I{\"id\":33699,\"chunks\":[\"6401:static/chunks/363642f4-e868532fae175454.js\",\"9838:static/chunks/30d07d85-388c23c5cce2d192.js\",\"6685:static/chunks/6685-d55f1e0fd750c950.js\",\"3222:static/chunks/3222-d51cb51b116d5c1d.js\",\"8213:static/chunks/8213-ef98b168d3fb6523.js\",\"9659:static/chunks/9659-468d9b7f9560cf55.js\",\"5578:static/chunks/5578-20f904870b8e232b.js\",\"1134:static/chunks/app/projects/dewy/page-d240caee60f7bf5e.js\"],\"name\":\"NoSSR\",\"async\":false}\n18:I{\"id\":77705,\"chunks\":[\"6401:static/"])</script><script>self.__next_f.push([1,"chunks/363642f4-e868532fae175454.js\",\"9838:static/chunks/30d07d85-388c23c5cce2d192.js\",\"6685:static/chunks/6685-d55f1e0fd750c950.js\",\"3222:static/chunks/3222-d51cb51b116d5c1d.js\",\"8213:static/chunks/8213-ef98b168d3fb6523.js\",\"9659:static/chunks/9659-468d9b7f9560cf55.js\",\"5578:static/chunks/5578-20f904870b8e232b.js\",\"1134:static/chunks/app/projects/dewy/page-d240caee60f7bf5e.js\"],\"name\":\"CodeBlock\",\"async\":false}\n19:I{\"id\":46685,\"chunks\":[\"6401:static/chunks/363642f4-e868532fae175454.js\",\"9838:static/chunks/"])</script><script>self.__next_f.push([1,"30d07d85-388c23c5cce2d192.js\",\"6685:static/chunks/6685-d55f1e0fd750c950.js\",\"3222:static/chunks/3222-d51cb51b116d5c1d.js\",\"8213:static/chunks/8213-ef98b168d3fb6523.js\",\"9659:static/chunks/9659-468d9b7f9560cf55.js\",\"5578:static/chunks/5578-20f904870b8e232b.js\",\"1134:static/chunks/app/projects/dewy/page-d240caee60f7bf5e.js\"],\"name\":\"\",\"async\":false}\n1a:I{\"id\":63222,\"chunks\":[\"6401:static/chunks/363642f4-e868532fae175454.js\",\"9838:static/chunks/30d07d85-388c23c5cce2d192.js\",\"6685:static/chunks/6685-d55f1e0fd75"])</script><script>self.__next_f.push([1,"0c950.js\",\"3222:static/chunks/3222-d51cb51b116d5c1d.js\",\"8213:static/chunks/8213-ef98b168d3fb6523.js\",\"9659:static/chunks/9659-468d9b7f9560cf55.js\",\"5578:static/chunks/5578-20f904870b8e232b.js\",\"1134:static/chunks/app/projects/dewy/page-d240caee60f7bf5e.js\"],\"name\":\"Image\",\"async\":false}\n"])</script><script>self.__next_f.push([1,"13:[[\"$\",\"$15\",null,{\"fallback\":null,\"children\":[\"$\",\"$L16\",null,{\"children\":\"$L17\"}]}],[\"$\",\"h3\",null,{\"className\":\"text-2xl mt-6 mb-2 font-quadon\",\"children\":\"About\"}],[\"$\",\"p\",null,{\"className\":\"mb-6 text-xl font-gentona text-justify\",\"children\":\"Dewy is a programming language I have been developing off and on since 2016. The Dewy Programming Language is a general purpose language designed with engineering applications in mind. Think the functionality and ease of use of matlab or python combined with the speed of a compiled language like C or Rust, but with its own unique flare.\"}],[\"$\",\"p\",null,{\"className\":\"text-xl font-gentona text-justify mb-2\",\"children\":\"Some key planned features include:\"}],[\"$\",\"ul\",null,{\"className\":\"list-disc mb-6 pl-10 text-xl font-gentona\",\"children\":[[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Functional and Imperative\"}],\" - Dewy is an imperitive language with strong support for functional programming. This allows for a very flexible programming style, where you can use the best tool for the job.\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Expression based syntax\"}],\" - Dewy uses an expression based syntax, meaning that everything is an expression. This allows for a very simple yet powerful syntax, where common language features often are just a free consequence of the syntax\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Garbage-collector-free memory management\"}],\" - Dewy uses a unique memory management system, allowing for fast and efficient memory management without the need for a garbage collector.\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Strong type system\"}],\" - Dewy has a powerful static type system with inference, reminiscent of those in Typescript and Julia.\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Built in unit system\"}],\" - Dewy has a built in unit system, allowing you to easily work with units and convert between them. This is especially useful for engineering applications.\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Strong math support\"}],\" - Dewy has strong support many math features, including complex numbers, quaternions, vectors, matrices, and more. This is especially useful for engineering applications.\"]}]]}],[\"$\",\"p\",null,{\"className\":\"mb-6 text-xl font-gentona text-justify\",\"children\":\"An example of the common FizzBuzz program implemented in Dewy might look like this:\"}],[\"$\",\"$L18\",null,{\"code\":\"multiples = [3 -\u003e 'Fizz' 5 -\u003e 'Buzz' /{7 -\u003e 'Bazz' 11 -\u003e 'Bar'}/]\\nloop i in [0..100)\\n{\\n    printed_words = false\\n    loop [multiple word] in multiples \\n    {\\n        if i % multiple =? 0 \\n        { \\n            print(multiple)\\n            printed_words = true\\n        }\\n    }\\n    if not? printed_words print(i)\\n    printl()\\n}\"}],[\"$\",\"p\",null,{\"className\":\"mb-6 text-xl font-gentona text-justify\",\"children\":\"Or a more functional style implementation might look like this:\"}],[\"$\",\"$L18\",null,{\"code\":\"multiples = [3 -\u003e 'Fizz' 5 -\u003e 'Buzz' /{7 -\u003e 'Bazz' 11 -\u003e 'Bar'}/]\\nrange = [0..100)\\n\\n//indexing at [, ..] and [..,] adds singleton dimensions\\nword_bools = range[, ..] .% multiples.keys[..,] .=? 0\\n\\n// #` means transpose, which behaves like python's zip()\\nword_grid = [multiples.values word_bools]`.map(\\n[word bools] =\u003e bools.map(b =\u003e if b word else '')\\n)\\n\\nraw_lines = word_grid`.map(line_words =\u003e line_words.join(''))\\n\\nlines = [raw_lines range]`.map(\\n    (raw_line, i) =\u003e if raw_line.length =? 0 '{i}' else raw_line\\n)\\n\\nlines.join('\\\\n') |\u003e printl\\n\"}],[\"$\",\"p\",null,{\"className\":\"mb-6 text-xl font-gentona text-justify\",\"children\":\"For clarity, the variables at each step look like so:\"}],[\"$\",\"$L18\",null,{\"code\":\"word_bools = [[true false false true false false true false ...]\\n             [true false false false false true false false ...]]\\n\\nword_grid = [['Fizz' '' '' 'Fizz' '' '' 'Fizz' '' '' 'Fizz' '' '' ...]\\n            ['Buzz' '' '' '' '' 'Buzz' '' '' '' '' 'Buzz' '' '' ...]]\\n\\nraw_lines = ['FizzBuzz' '' '' 'Fizz' '' 'Buzz' 'Fizz' '' '' 'Fizz' 'Buzz' '' ...]\\n\\nlines = ['FizzBuzz' '1' '2' 'Fizz' '4' 'Buzz' 'Fizz' '7' '8' 'Fizz' 'Buzz' '11' ...]\\n\"}],[\"$\",\"h3\",null,{\"className\":\"text-2xl mt-6 mb-2 font-quadon\",\"children\":\"Current Status\"}],[\"$\",\"p\",null,{\"className\":\"mb-6 text-xl font-gentona text-justify\",\"children\":[\"Currently I'm working through a simple interpreter for the language (powering the demo above). Previously I had been doing a lot of development on bleeding edge\",\" \",[\"$\",\"$L19\",null,{\"href\":\"/projects/dewy_old\",\"className\":\"text-blue-400 hover:text-blue-500 font-gentona text-xl\",\"children\":\"parser generators\"}],\", but that ended up being too big of a time sink for not much visible progress. Instead, for the time being, I ended up just hand rolling a parser in python, which has led to actually runnable code! I'll definitely revisit parser generators in the future when the language is further along.\"]}],[\"$\",\"p\",null,{\"className\":\"mb-6 text-xl font-gentona text-justify\",\"children\":[\"After the parser is complete, the next steps will be working on compiling to\",\" \",[\"$\",\"$L19\",null,{\"href\":\"https://en.wikipedia.org/wiki/LLVM#Intermediate_representation\",\"className\":\"text-blue-400 hover:text-blue-500 font-gentona text-xl\",\"children\":\"LLVM IR\"}],\" (read LLVM assembly), as well as starting to build out the standard library, and then bootstrapping the compiler to be able to compile itself.\"]}],[\"$\",\"h3\",null,{\"className\":\"text-2xl mt-6 mb-2 font-quadon\",\"children\":\"About the Demo\"}],[\"$\",\"p\",null,{\"className\":\"mb-6 text-xl font-gentona text-justify\",\"children\":[\"The demo above was actually pretty complex to put together. The current interpreter is written in python, and this website is statically hosted, which meant the demo required some way to statically run python code without a server. For this, I used \",[\"$\",\"$L19\",null,{\"href\":\"https://pyodide.org/\",\"className\":\"text-blue-400 hover:text-blue-500 font-gentona text-xl\",\"children\":\"Pyodide\"}],\", which is basically \",[\"$\",\"$L19\",null,{\"href\":\"https://github.com/python/cpython\",\"className\":\"text-blue-400 hover:text-blue-500 font-gentona text-xl\",\"children\":\"CPython\"}],\" compiled to\",\" \",[\"$\",\"$L19\",null,{\"href\":\"https://webassembly.org/\",\"className\":\"text-blue-400 hover:text-blue-500 font-gentona text-xl\",\"children\":\"WebAssembly\"}],\" via\",\" \",[\"$\",\"$L19\",null,{\"href\":\"https://emscripten.org/\",\"className\":\"text-blue-400 hover:text-blue-500 font-gentona text-xl\",\"children\":\"Emscripten.\"}]]}],[\"$\",\"p\",null,{\"className\":\"mb-6 text-xl font-gentona text-justify\",\"children\":[\"Pyodide itself isn't too difficult to use, except for the fact that it doesn't have good support for asynchronous standard input—it really wants to halt the entire UI while you type input into a stock browser popup prompt. To get around this, I found a\",\" \",[\"$\",\"$L19\",null,{\"href\":\"https://www.npmjs.com/package/sync-message\",\"className\":\"text-blue-400 hover:text-blue-500 font-gentona text-xl\",\"children\":\"handy library\"}],\" where you run pyodide in a web worker, and then any time it wants to read input, the worker makes a synchronous XHR request to a service worker, blocking the pyodide web worker until the service worker receives a response from the main thread with the input, which the service worker can then pass back to the pyodide worker. Suffice it to say, I don't think I ever want to deal with service workers again.\"]}],[\"$\",\"p\",null,{\"className\":\"mb-6 text-xl font-gentona text-justify\",\"children\":[\"Now that python is handled, the next aspect is getting the Dewy interpreter itself to run. For this, I fetch (at website build time) the source code directly from\",\" \",[\"$\",\"$L19\",null,{\"href\":\"https://github.com/david-andrew/dewy-lang/tree/master/src/compiler\",\"className\":\"text-blue-400 hover:text-blue-500 font-gentona text-xl\",\"children\":\"github\"}],\". I then abuse the python import lib to allow loading \\\"modules\\\" directly from strings, and then pass all of the dewy source in as modules. Then I have a little wrapper function for the entry point which receives the source code string, and runs the program. The entry point can then be called from the browser via a javascript wrapper function.\"]}],[\"$\",\"p\",null,{\"className\":\"mb-6 text-xl font-gentona text-justify\",\"children\":[\"The final piece of the puzzle is the text entry, and terminal emulator. For text input, I'm using the \",[\"$\",\"$L19\",null,{\"href\":\"https://codemirror.net/\",\"className\":\"text-blue-400 hover:text-blue-500 font-gentona text-xl\",\"children\":\"Code Mirror Library\"}],\"with a custom syntax highlighter (actually the current syntax highlighter was for the\",\" \",[\"$\",\"$L19\",null,{\"href\":\"/projects/dewy_old\",\"className\":\"text-blue-400 hover:text-blue-500 font-gentona text-xl\",\"children\":\"Dewy meta language\"}],\", but it works well enough in the meantime). For the terminal, I use the \",[\"$\",\"$L19\",null,{\"href\":\"https://xtermjs.org/\",\"className\":\"text-blue-400 hover:text-blue-500 font-gentona text-xl\",\"children\":\"xterm.js\"}],\" library. I then hooked up stdin and stdout from pyodide to interact with the terminal, and voila! A Dewy interpreter running in the browser.\"]}],[\"$\",\"p\",null,{\"className\":\"mb-6 text-xl font-gentona text-justify\",\"children\":\"There are definitely some rough edges, and the parser only supports a small handful of features, but it runs! It's probably the easiest way to try out the language, and I'm looking forward to getting all of the broken example programs working!\"}],[\"$\",\"h3\",null,{\"className\":\"text-2xl mt-6 mb-2 font-quadon\",\"children\":\"Links\"}],[\"$\",\"div\",null,{\"className\":\"flex flex-col space-y-3\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex flex-row text-sm items-center\",\"children\":[[\"$\",\"$L1a\",null,{\"src\":{\"src\":\"/_next/static/media/github.8d24eda3.svg\",\"height\":484,\"width\":496,\"blurWidth\":0,\"blurHeight\":0},\"alt\":\"github icon\",\"className\":\"inline-block w-8 h-8 mr-2  pointer-events-none select-none\",\"draggable\":false}],[\"$\",\"span\",null,{\"className\":\"align-middle\",\"children\":[\"$\",\"$L19\",null,{\"href\":\"https://github.com/david-andrew/dewy-lang\",\"className\":\"text-blue-400 hover:text-blue-500 font-gentona text-xl\",\"children\":\"Github Repo\"}]}]]}],[\"$\",\"div\",null,{\"className\":\"flex flex-row text-sm items-center\",\"children\":[[\"$\",\"$L1a\",null,{\"src\":{\"src\":\"/_next/static/media/docs.71257e0f.svg\",\"height\":512,\"width\":384,\"blurWidth\":0,\"blurHeight\":0},\"alt\":\"docs icon\",\"className\":\"inline-block w-8 h-8 mr-2  pointer-events-none select-none\",\"draggable\":false}],[\"$\",\"span\",null,{\"className\":\"align-middle\",\"children\":[\"$\",\"$L19\",null,{\"href\":\"https://david-andrew.github.io/dewy-lang/\",\"className\":\"text-blue-400 hover:text-blue-500 font-gentona text-xl\",\"children\":\"Language Docs\"}]}]]}]]}]]\n"])</script><script>self.__next_f.push([1,"1b:I{\"id\":38469,\"chunks\":[\"6401:static/chunks/363642f4-e868532fae175454.js\",\"9838:static/chunks/30d07d85-388c23c5cce2d192.js\",\"6685:static/chunks/6685-d55f1e0fd750c950.js\",\"3222:static/chunks/3222-d51cb51b116d5c1d.js\",\"8213:static/chunks/8213-ef98b168d3fb6523.js\",\"9659:static/chunks/9659-468d9b7f9560cf55.js\",\"5578:static/chunks/5578-20f904870b8e232b.js\",\"1134:static/chunks/app/projects/dewy/page-d240caee60f7bf5e.js\"],\"name\":\"\",\"async\":false}\n1c:T68d,"])</script><script>self.__next_f.push([1,"from typing import Callable\n\n\ndef python_interpreter(path:str, args:list[str]):\n    from tokenizer import tokenize\n    from postok import post_process\n    from parser import top_level_parse # type: ignore[reportShadowedImports]\n    from dewy import Scope\n\n    with open(path) as f:\n        src = f.read()\n    \n    tokens = tokenize(src)\n    post_process(tokens)\n\n    root = Scope.default()\n    ast = top_level_parse(tokens, root)\n    res = ast.eval(root)\n    if res: print(res)\n\n\ndef llvm_compiler(path:str, args:list[str]):\n    raise NotImplementedError('LLVM backend is not yet supported')\n\ndef c_compiler(path:str, args:list[str]):\n    raise NotImplementedError('C backend is not yet supported')\n\ndef x86_64_compiler(path:str, args:list[str]):\n    raise NotImplementedError('x86_64 backend is not yet supported')\n\ndef shell(path:str, args:list[str]):\n    \"\"\"this would target sh/powershell/etc. all simultaneously\"\"\"\n    raise NotImplementedError('Shell backend is not yet supported')\n\nbackend_map = {\n    'python': python_interpreter,\n    'llvm': llvm_compiler,\n    'c': c_compiler,\n    'x86_64': x86_64_compiler,\n    # 'arm': arm,\n    # 'riscv': riscv,\n    'sh': shell,\n    # 'posix': posix_shell,\n    # 'powershell': powershell_shell,\n}\nbackends = [*backend_map.keys()]\n\ndef get_backend(name:str) -\u003e Callable[[str, list[str]], None]:\n    try:\n        return backend_map[name.lower()]\n    except:\n        raise ValueError(f'Unknown backend \"{name}\"') from None\n\n\ndef get_version() -\u003e str:\n    \"\"\"Return the semantic version of the language\"\"\"\n    from pathlib import Path\n    with open(Path(__file__).parent.parent.parent / 'VERSION') as f:\n        return f.read().strip()"])</script><script>self.__next_f.push([1,"1d:Tfa4b,"])</script><script>self.__next_f.push([1,"from abc import ABC\nfrom dataclasses import dataclass\nfrom types import EllipsisType\nfrom typing import Any, Callable as PyCallable, Type as PyType, Union, Optional\nfrom functools import partial\nimport operator\n\nimport pdb\n\n#Written in python3.10\n\n#dumb look at interpreting/compiling dewy\n#for now, construct the AST directly, skipping the parsing step\n\n\n# [Tasks]\n# - instead of If with a block of multiple conditional checks: ConditionalChain, which can have any conditonals, e.g. if, loop, etc, and the first one that gets entered stops the chain\n# - write function for crawling AST, and replacing \n# loop \u003cvar\u003e in \u003cexpr\u003e \n#   \u003cbody\u003e \n# with \n# \u003c_itr\u003e = \u003cexpr\u003e.iter()\n# \u003cvar\u003e = \u003citr\u003e.next()\n# loop \u003cvar\u003e\n#   \u003cbody\u003e\n#   \u003cvar\u003e = \u003citr\u003e.next()\n#\n# - make all type checking happen at compile time, and be based on calls to expr.type\n#   -\u003e need to be able to handle type graph with child types matching where parent types are expected, etc. e.g. int is a number, etc.\n# also make the current functionality not worker (where it checks if the variable exists). should throw an error about how it's syntax sugar\n\n#convenient for inside lambdas\ndef notimplemented():\n    raise NotImplementedError()\n\ntab = '    ' #for printing ASTs\nnewline = '\\n' # or ' ' to make it all one line\n# tabin = '|\u003e\u003e\u003e\u003e|'\n# tabout = '|\u003c\u003c\u003c\u003c|'\n\n\ndef insert_tabs_inner(s):\n    \"\"\"given the output of __str__ from an AST, insert tabs at \\n based on how many {} were encountered so far\"\"\"\n    #TODO: this runs into problems b/c {} is also used in string interpolation syntax...\n    level = 0\n    out = []\n    for c in s:\n        if c == '{':\n            level += 1\n        elif c == '}':\n            level -= 1\n            if out[-1].isspace():\n                out[-1] = out[-1][:-4] #remove 1 tab\n        out.append(c)\n\n        if c == '\\n':\n            out.append(tab*level)\n            continue\n\n    return ''.join(out)\n\ninserting_tabs = False #so that only the top level inserts the tabs\ndef insert_tabs(func):\n    def wrapper(*args, **kwargs):\n        global inserting_tabs\n        if inserting_tabs:\n            out = func(*args, **kwargs)\n        else:\n            inserting_tabs = True\n            out = insert_tabs_inner(func(*args, **kwargs))\n            inserting_tabs = False\n        return out\n\n    return wrapper\n\n\nclass AST(ABC):\n    \n    #TODO: make accessing this raise better error if not overwritten by child class\n    #      for now, just rely on exception for missing property\n    # type:'Type' = None\n\n    def eval(self, scope:'Scope'=None) -\u003e 'AST':\n        \"\"\"Evaluate the AST in the given scope, and return the result (as a dewy obj) if any\"\"\"\n        raise NotImplementedError(f'{self.__class__.__name__}.eval')\n    def topy(self, scope:'Scope'=None) -\u003e Any:\n        \"\"\"Convert the AST to a python equivalent object (usually unboxing the dewy object)\"\"\"\n        raise NotImplementedError(f'{self.__class__.__name__}.topy')\n    def comp(self, scope:'Scope'=None) -\u003e str:\n        \"\"\"TODO: future handle compiling an AST to LLVM IR\"\"\"\n        raise NotImplementedError(f'{self.__class__.__name__}.comp')\n    # @abstractclassmethod\n    # def type(cls, scope:'Scope'=None) -\u003e 'Type':\n    #     \"\"\"Return the type of the object that would be returned by eval\"\"\"\n    #     raise NotImplementedError(f'{cls.__name__}.type')\n    #TODO: other methods, e.g. semantic analysis\n    def treestr(self, indent=0) -\u003e str:\n        \"\"\"Return a string representation of the AST tree\"\"\"\n        raise NotImplementedError(f'{self.__class__.__name__}.treestr')\n    def __str__(self) -\u003e str:\n        \"\"\"Return a string representation of the AST as dewy code\"\"\"\n        raise NotImplementedError(f'{self.__class__.__name__}.__str__')\n    def __repr__(self) -\u003e str:\n        \"\"\"Return a string representation of the python objects making up the AST\"\"\"\n        raise NotImplementedError(f'{self.__class__.__name__}.__repr__')\n\nclass PrototypeAST(AST):\n    def eval(self, scope:'Scope'=None) -\u003e AST:\n        raise ValueError(f'Prototype ASTs may not define eval. Attempted to call eval on prototype {self}, of type ({type(self)})')\n\nclass Undefined(AST):\n    \"\"\"undefined singleton\"\"\"\n\n    #type value is set in __new__, since class Type isn't declared yet\n    type:'Type'\n\n    def __new__(cls):\n        if not hasattr(cls, 'instance'):\n            cls.instance = super(Undefined, cls).__new__(cls)\n        return cls.instance\n    def eval(self, scope:'Scope'=None):\n        return self\n    def topy(self, scope:'Scope'=None):\n        return None\n    def typeof(self, scope:'Scope'=None):\n        return Type('undefined')\n    def treesr(self, indent=0):\n        return tab * indent + 'Undefined'\n    def __str__(self):\n        return 'undefined'\n    def __repr__(self):\n        return 'Undefined()'\n\n#undefined shorthand, for convenience\nundefined = Undefined()\n\n\n\n\nclass Scope():\n    \n    @dataclass\n    class _var():\n        # name:str #name is stored in the dict key\n        type:AST\n        value:AST\n        const:bool\n    \n    def __init__(self, parent:Optional['Scope']=None):\n        self.parent = parent\n        self.vars:dict[str, Scope._var] = {}\n        \n        #used for function calls\n        self.args:Array|None = None\n\n    @property\n    def root(self) -\u003e 'Scope':\n        \"\"\"Return the root scope\"\"\"\n        return [*self][-1]\n\n    def let(self, name:str, type:Union['Type',Undefined]=undefined, value:AST=undefined, const=False):\n        #overwrite anything that might have previously been there\n        self.vars[name] = Scope._var(type, value, const)\n\n    def get(self, name:str, default:AST=None) -\u003e AST:\n        #get a variable from this scope or any of its parents\n        for s in self:\n            if name in s.vars:\n                return s.vars[name].value\n        if default is not None:\n            return default\n        raise NameError(f'{name} not found in scope {self}')\n\n    def bind(self, name:str, value:AST):\n\n        #update an existing variable in this scope or  any of the parent scopes\n        for s in self:\n            if name in s.vars:\n                var = s.vars[name]\n                assert not var.const, f'cannot assign to const {name}'\n                assert Type.is_instance(value.typeof(), var.type), f'cannot assign {value}:{value.typeof()} to {name}:{var.type}'\n                var.value = value\n                return\n\n        #otherwise just create a new instance of the variable\n        self.vars[name] = Scope._var(undefined, value, False)\n\n    def __iter__(self):\n        \"\"\"return an iterator that walks up each successive parent scope. Starts with self\"\"\"\n        s = self\n        while s is not None:\n            yield s\n            s = s.parent\n\n    def __repr__(self):\n        if self.parent is not None:\n            return f'Scope({self.vars}, {repr(self.parent)})'\n        return f'Scope({self.vars})'\n\n    def copy(self):\n        s = Scope(self.parent)\n        s.vars = self.vars.copy()\n        return s\n\n    def attach_args(self, args:Union['Array', None]):\n        self.args = args\n\n    @staticmethod\n    def default():\n        \"\"\"return a scope with the standard library (of builtins) included\"\"\"\n        root = Scope()\n        root.bind('print', Builtin('print', [Arg('text')], None, Type('callable', [Array([String.type]), Undefined.type])))\n        root.bind('printl', Builtin('printl', [Arg('text')], None, Type('callable', [Array([String.type]), Undefined.type])))\n        root.bind('readl', Builtin('readl', [], String, Type('callable', [Array([]), String.type])))\n        #TODO: eventually add more builtins\n\n        return root\n\n\n#probably won't use this, except possibly for when calling functions and providing enums from the function's scope\n# def merge_scopes(*scopes:list[Scope], onto:Scope=None):\n#     #TODO... this probably could actually be a scope union class that inherits from Scope\n#     #            that way we don't have to copy the scopes\n#     pdb.set_trace()\n\n\nclass Type(AST):\n\n    type:'Type'\n\n    #map by name from simple types to their parent type in the type graph\n    graph: dict[str, str|None] = {\n        'callable': None,\n        'function': 'callable',\n        'builtin': 'callable'\n    }\n\n    def __init__(self, name:str|AST, params:list[AST]=None, parent:str=None):\n        self.name = name\n        self.params = params or []\n        \n        # register type in the type graph\n        if isinstance(name, str) and name not in Type.graph:\n            Type.graph[name] = parent\n        \n    def eval(self, scope:Scope=None):\n        return self\n\n    def typeof(self, scope:Scope=None):\n        return Type('type')\n    \n\n    def treestr(self, indent=0):\n        s = tab * indent + f'Type: {self.name}\\n'\n        for p in self.params:\n            s += p.treestr(indent + 1) + '\\n'\n        return s\n\n    @insert_tabs\n    def __str__(self):\n        if self.params is not None and len(self.params) \u003e 0:\n            return f'{self.name}\u003c{\", \".join(map(str, self.params))}\u003e'\n        return self.name\n\n    def __repr__(self):\n        return f'Type({self.name}, {self.params})'\n\n    def __eq__(self, other):\n        if isinstance(other, Type):\n            return self.name == other.name and self.params == other.params\n        return False\n    \n    def __and__(self, other:AST):\n        return And(self, other, Type)\n    \n    def __rand__(self, other:AST):\n        return And(other, self, Type)\n    \n    def __or__(self, other:AST):\n        return Or(self, other, Type)\n    \n    def __ror__(self, other:AST):\n        return Or(other, self, Type)\n\n    def __eq__(self, other):\n        raise NotImplementedError('Type comparisons should be performed with `Type.is_instance()`')\n    \n    #TODO: come up with better names for the method arguments\n    @staticmethod\n    def is_instance(obj_t:Union['Type',Undefined], target_t:Union['Type',Undefined]) -\u003e bool:\n        \"\"\"\n        Check if the object is an instance (or descendent) of the specified type\n\n        if target_t is undefined, short circuit results to True.\n        Parameters are only checked based on those present in target_t, \n            e.g. if obj_t=array\u003cint\u003e and target_t=array, then no params would be checked (and is_instance would be true)\n\n        Args:\n            obj_t (Type|Undefined): The type of the object to be checked (i.e. for some dewy obj, obj_t = obj.typeof())\n            target_t: (Type|Undefined): The target type for determining if obj_t is an instance or not\n\n        Returns:\n            (bool): whether or not obj_t is an instance (or descendent) of target_t\n        \"\"\"\n        assert isinstance(target_t, (Type, Undefined)), f't must be a Type or undefined, not {target_t}'\n        assert isinstance(obj_t, (Type, Undefined)), f'obj_t must be a Type or undefined, not {obj_t}'\n        \n        # undefined target always returns true\n        if isinstance(target_t, Undefined):\n            return True\n        \n        # since target is not undefined, undefined obj_t necessarily doesn't match\n        if isinstance(obj_t, Undefined):\n            return False\n        \n        \n        #DEBUG/TODO\n        if isinstance(target_t.name, AST) and isinstance(obj_t.name, AST):\n            #TODO: need to make AST equality work properly (namely for binops and/or)\n            #      will remove this if check, and let target.name == obj_t.name handle it\n            pdb.set_trace()\n        \n        # check the type by name, and params\n        if target_t.name == obj_t.name:\n            if len(obj_t.params) \u003c len(target_t.params):\n                return False\n            \n            # check if any object parameters don't match the present target parameters\n            # note: obj_t may have more params than target_t\n            if any(obj_param != target_param for obj_param, target_param in zip(target_t.params, obj_t.params)):\n                return False\n                \n            # names match, and obj_t has all params target_t has\n            return True\n        \n\n        # for non-matching name, if atomic type, recursively check parent type in graph for compatibility\n        if isinstance(obj_t.name, str):\n            parent = Type.graph[obj_t.name]\n            if parent is not None:\n                #TODO: this is a poor way to check for parent types. Assumes parent parameters are same shape as child type...\n                return Type.is_instance(Type(parent, obj_t.params), target_t)\n\n        return False\n\n# set the type class property for Type, and Undefined since class Type() exists now\nType.type = Type('type')\nUndefined.type = Type('undefined')\n\nclass Identifier(PrototypeAST):\n    # intermediate node, expected to be replaced with call or etc. during AST construction\n\n    def __init__(self, name:str) -\u003e None:\n        self.name = name\n    \n    def __str__(self) -\u003e str:\n        return f'{self.name}'\n    \n    def __repr__(self) -\u003e str:\n        return f'Identifier({self.name})'\n\n\nclass Callable(AST):\n\n    type:Type = Type('callable')\n\n    def call(self, scope:'Scope'=None):\n        \"\"\"Call the callable in the given scope\"\"\"\n        raise NotImplementedError(f'{self.__class__.__name__}.call')\n\nclass Orderable(AST):\n    \"\"\"An object that can be sorted relative to other objects of the same type\"\"\"\n    def compare(self, other:'Orderable', scope:'Scope'=None) -\u003e 'Number':\n        \"\"\"Return a value indicating the relationship between this value and another value\"\"\"\n        raise NotImplementedError(f'{self.__class__.__name__}.compare')\n    @staticmethod\n    def max(self) -\u003e 'Rangeable':\n        \"\"\"Return the maximum element from the set of all elements of this type\"\"\"\n        raise NotImplementedError(f'{self.__class__.__name__}.max')\n    @staticmethod\n    def min(self) -\u003e 'Rangeable':\n        \"\"\"Return the minimum element from the set of all elements of this type\"\"\"\n        raise NotImplementedError(f'{self.__class__.__name__}.min')\n    \n#TODO: come up with a better name for this class... successor and predecessor are only used for range iterators, not ranges themselves\n#        e.g. Incrementable, Decrementable, etc.\nclass Rangeable(Orderable):\n    \"\"\"An object that can be used to specify bounds of a range\"\"\"\n    def successor(self, step=undefined, scope:'Scope'=None) -\u003e 'Rangeable':\n        \"\"\"Return the next value in the range\"\"\"\n        raise NotImplementedError(f'{self.__class__.__name__}.successor')\n    def predecessor(self, step=undefined, scope:'Scope'=None) -\u003e 'Rangeable':\n        \"\"\"Return the previous value in the range\"\"\"\n        raise NotImplementedError(f'{self.__class__.__name__}.predecessor')\n\nclass Unpackable(AST):\n    def len(self, scope:'Scope'=None) -\u003e int:\n        \"\"\"Return the length of the unpackable\"\"\"\n        raise NotImplementedError(f'{self.__class__.__name__}.len')\n    def get(self, key:int|EllipsisType|slice|tuple[int|EllipsisType|slice], scope:'Scope'=None) -\u003e AST:\n        \"\"\"Return the item at the given index\"\"\"\n        raise NotImplementedError(f'{self.__class__.__name__}.get')\n#TODO: make a type annotation for Unpackable[N] where N is the number of items in the unpackable?\n#        would maybe replace the len property?\n\nclass Iter(AST):\n    def next(self, scope:'Scope'=None) -\u003e Unpackable: #TODO: TBD on the return type. need dewy tuple type...\n        \"\"\"Get the next item from the iterator\"\"\"\n        raise NotImplementedError(f'{self.__class__.__name__}.next')\n\nclass Iterable(AST):\n    #TODO: maybe don't need scope for this method...\n    def iter(self, scope:'Scope'=None) -\u003e Iter:\n        \"\"\"Return an iterator over the iterable\"\"\"\n        raise NotImplementedError(f'{self.__class__.__name__}.iter')\n\n\n\n\nclass Arg:\n    def __init__(self, name:str, type:Type=None, val:AST|None=None):\n        self.name = name\n        self.val = val\n        self.type = type\n    # @insert_tabs\n    def __str__(self):\n        s = f'{self.name}'\n        if self.type is not None:\n            s += f':{self.type}'\n        if self.val is not None:\n            s += f' = {self.val}'\n        return s\n    def __repr__(self):\n        s = f'Arg({self.name}'\n        if self.type is not None:\n            s += f', {repr(self.type)}'\n        if self.val is not None:\n            s += f', {repr(self.val)}'\n        s += ')'\n        return s\n\n\nclass Function(Callable):\n    \n    type:Type = Type('function')\n\n    def __init__(self, args:list[Arg], body:AST, scope:Scope=None):\n        self.args = args\n        self.body = body\n        self.scope = scope #scope where the function was defined, which may be different from the scope where it is called\n    \n    def eval(self, scope:Scope=None):\n        #TODO: maybe this should do self.scope=scope since this is the scope where the function is defined\n        #        just probably problems when expressing the function without calling it, e.g. with handles\n        #        f = {() =\u003e {...}} @f // the @f would set the scope to be the outer scope...\n        return self\n    \n    def call(self, scope:Scope=None):\n        #collect args from calling scope, and merge into function scope\n        fscope = Scope(self.scope)\n\n        # grab the args being passed in\n        caller_args:list[AST] = []\n        caller_kwargs:dict[str,AST] = {}\n        if scope is not None and scope.args is not None:\n            for arg in scope.args.vals:\n                if not isinstance(arg, Bind):\n                    caller_args.append(arg)\n                else:\n                    caller_kwargs[arg.name] = arg.value\n        \n        # grab the args and any default args from the function definition\n        fn_args = [arg for arg in self.args if arg.val is None and arg.name not in caller_kwargs]\n        fn_kwargs = [arg for arg in self.args if arg.val is not None and arg.name not in caller_kwargs]\n        fn_arg_names = {arg.name for arg in self.args}\n\n        # bind the positional arguments to the function scope\n        assert len(fn_args) == len(caller_args), f'encountered different number of positional arguments than expected. Function is defined with {[a for a in self.args if a.val is None]}. Tried to call with {caller_args}'\n        for fn_arg, caller_arg in zip(fn_args, caller_args):\n            fscope.let(fn_arg.name, caller_arg)\n\n        # bind keyward arguments to the function scope, first from default args, then from caller\n        for fn_kwarg in fn_kwargs:\n            fscope.let(fn_kwarg.name, fn_kwarg.val)\n        for caller_kwarg_name, caller_kwarg_value in caller_kwargs.items():\n            assert caller_kwarg_name in fn_arg_names, f\"tried to bind unrecognized keyword argument '{caller_kwarg_name}' to function {self}\"\n            fscope.let(caller_kwarg_name, caller_kwarg_value)\n\n        return self.body.eval(fscope)\n\n    def treestr(self, indent=0):\n        s = tab * indent + f'Function()\\n'\n        for arg in self.args:\n            s += tab * (indent + 1) + f'Arg: {arg.name}\\n'\n            if arg.type is not None:\n                s += arg.type.treestr(indent + 2) + '\\n'\n            if arg.val is not None:\n                s += arg.val.treestr(indent + 2) + '\\n'\n        s += tab*(indent+1) + 'Body:\\n' + self.body.treestr(indent + 2)\n        return s\n\n    @insert_tabs\n    def __str__(self):\n        s = ''\n        if len(self.args) == 1:\n            s += f'{self.args[0]}'\n        else:\n            s += f'({\", \".join(map(str, self.args))})'\n        s += f' =\u003e {self.body}'\n        return s\n\n    def __repr__(self):\n        return f'Function(args:{self.args}, body:{self.body}, scope:{self.scope})'\n\nclass Builtin(Callable):\n    funcs = {\n        'print': partial(print, end=''),\n        'printl': print,\n        'readl': input\n    }\n\n    type:Type = Type('builtin')\n\n    def __init__(self, name:str, args:list[Arg], cls:PyCallable, type:Type):\n        self.name = name\n        self.args = args\n        self.cls = cls\n        self.type = type\n    \n    def eval(self, scope:Scope=None):\n        return self\n    \n    def call(self, scope:Scope=None):\n        if self.name in Builtin.funcs:\n            f = Builtin.funcs[self.name]\n            #TODO: this doesn't handle differences in named vs unnamed args between the function definition and the call\n\n            args = []\n            kwargs = {}\n\n            # insert positional and keyward args from the call\n            if scope.args is not None:\n                for ast in scope.args.vals:\n                    if not isinstance(ast, Bind):\n                        args.append(ast.eval(scope).topy(scope))\n                    else:\n                        kwargs[ast.name] = ast.value.eval(scope).topy(scope)\n\n            # insert any default/named args (not already inserted by the call)\n            for arg in self.args:\n                if arg.val is not None and arg.name not in kwargs:\n                    kwargs[arg.name] = arg.val.eval(scope).topy(scope)\n\n            result = f(*args, **kwargs)\n            if self.cls is not None:\n                return self.cls(result)\n        else:\n            raise NameError(self.name, 'is not a builtin')\n\n    def treestr(self, indent=0):\n        s = tab * indent + f'Builtin({self.name})\\n'\n        for arg in self.args:\n            s += tab * (indent + 1) + f'Arg: {arg.name}\\n'\n            if arg.type is not None:\n                s += arg.type.treestr(indent + 2) + '\\n'\n            if arg.val is not None:\n                s += arg.val.treestr(indent + 2) + '\\n'\n        return s\n\n    # @insert_tabs\n    def __str__(self):\n        return f'{self.name}({\", \".join(map(str, self.args))})'\n\n    def __repr__(self):\n        return f'Builtin({self.name}, {self.args})'\n\n\nclass Let(AST):\n    def __init__(self, name:str, type:Type, value:AST=undefined, const=False):\n        self.name = name\n        self.type = type\n        self.value = value\n        self.const = const\n\n    def eval(self, scope:Scope=None):\n        scope.let(self.name, self.type, self.value, self.const)\n\n    def treestr(self, indent=0):\n        return f'{tab * indent}{\"Const\" if self.const else \"Let\"}: {self.name}\\n{self.type.treestr(indent + 1)}'\n\n    @insert_tabs\n    def __str__(self):\n        return f'{\"const\" if self.const else \"let\"} {self.name}:{self.type} = {self.value}'\n\n    def __repr__(self):\n        return f'{\"Const\" if self.const else \"Let\"}({self.name}, {self.type}, {self.value})'\n\n\nclass Bind(AST):\n    #TODO: allow bind to take in an unpack structure\n    def __init__(self, name:str, value:AST):\n        self.name = name\n        self.value = value\n    def eval(self, scope:Scope=None):\n        scope.bind(self.name, self.value.eval(scope))\n\n    def treestr(self, indent=0):\n        return f'{tab * indent}Bind: {self.name}\\n{self.value.treestr(indent + 1)}'\n\n    @insert_tabs\n    def __str__(self):\n        return f'{self.name} = {self.value}'\n\n    def __repr__(self):\n        return f'Bind({self.name}, {repr(self.value)})'\n\n\nclass PackStruct(list[Union[str,'PackStruct']]):\n    \"\"\"\n    represents the type for left hand side of an unpack operation\n\n    unpacking operations in dewy look like this:\n    [a, b, c] = [1 2 3]                                         //a=1, b=2, c=3\n    [a, [b, c]] = [1 [2 3]]                                     //a=1, b=2, c=3\n    [a, [b, c], d] = [1 [2 3] 4]                                //a=1, b=2, c=3, d=4\n    [a, ...b] = [1 2 3 4]                                       //a=1, b=[2 3 4]\n    [a, ...b, c] = [1 2 3 4 5]                                  //a=1, b=[2 3 4], c=5\n    [a, ...b, [c, [...d, e, f]]] = [1 2 3 4 [5 [6 7 8 9 10]]]   //a=1, b=[2 3 4], c=5, d=[6 7 8], e=9, f=10\n\n    note that there may only be one ellipsis in a given level of the structure\n    \"\"\"\n    ...\n\n\n\nclass Unpack(AST):\n    def __init__(self, struct:PackStruct, value:Unpackable):\n        #check that there is only one ellipsis in the top level of the structure (lower levels are checked recursively)\n        #TODO: problem with checking lower levels recursively is that it is no longer a compile time check\n        assert sum(1 for s in struct if isinstance(s, str) and s.startswith('...')) \u003c= 1, 'only one ellipsis is allowed per level of the structure'\n        self.struct = struct\n        self.value = value\n\n    def eval(self, scope:Scope=None):\n        value = self.value.eval(scope)\n        assert isinstance(value, Unpackable), f'{value} is not unpackable'\n        value_len = value.len(scope)\n        \n        #check that the structure has a matching number of elements to the value\n        #TODO: actually maybe allow this, and any extra elements are just undefined. complicated to handle if the number of elements is wrong though\n        has_ellipsis = any(isinstance(s, str) and s.startswith('...') for s in self.struct)\n        if has_ellipsis:\n            assert value_len \u003e= len(self.struct) - 1, f'cannot unpack {value} into {Unpack.str_helper(self.struct)}, expected more values to unpack'\n        else:\n            assert value_len == len(self.struct), f'cannot unpack {value} into {Unpack.str_helper(self.struct)}, ' + ('expected more' if value_len \u003c len(self.struct) else 'expected less') + ' values to unpack'\n\n        offset = 0 #offset for handling if an ellipsis was encountered during the unpack\n        for i, s in enumerate(self.struct):\n            if isinstance(s, str):\n                if s.startswith('...'):\n                    name = s[3:]\n                    n = value_len - len(self.struct) + 1 #number of elements to fill the ellipsis with\n                    scope.bind(name, value.get(slice(i,i+n), scope))\n                    offset += n - 1\n                else:\n                    scope.bind(s, value.get(i+offset, scope))\n            elif isinstance(s, list) or isinstance(s, tuple):\n                Unpack(s, value.get(i+offset, scope)).eval(scope)\n            else:\n                raise TypeError(f'invalid type in unpack structure: `{s}` of type `{type(s)}`')\n\n    def treestr(self, indent=0):\n        return f'{tab * indent}Unpack: {self.struct}\\n{self.value.treestr(indent + 1)}'\n\n    @insert_tabs\n    def __str__(self):\n        return f'{Unpack.str_helper(self.struct)} = {self.value}'\n\n    @staticmethod\n    def str_helper(val):\n        if isinstance(val, str):\n            return val\n        else:\n            s = '['\n            for i, v in enumerate(val):\n                if isinstance(v, str):\n                    s += v\n                else:\n                    s += Unpack.str_helper(v)\n                if i != len(val) - 1:\n                    s += ', '\n            s += ']'\n            return s\n\n    def __repr__(self):\n        return f'Unpack({self.struct}, {self.value})'\n\nclass Tuple(PrototypeAST):\n    \"\"\"\n    A comma separated list of expressions (not wrapped in parentheses) e.g. 1, 2, 3\n    There is no special in-memory representation of a tuple, it is literally just a const list\n    \"\"\"\n    def __init__(self, exprs:list[AST]):\n        self.exprs = exprs\n    \n\nclass Block(AST):\n    def __init__(self, exprs:list[AST], newscope:bool=True):\n        self.exprs = exprs\n        self.newscope = newscope\n    def eval(self, scope:Scope=None):\n        #TODO: handle flow control from a block, e.g. return, break, continue, express, etc.\n        if self.newscope:\n            scope = Scope(scope)\n        ret = undefined\n        for expr in self.exprs:\n            ret = expr.eval(scope)\n        return ret\n\n    def treestr(self, indent=0):\n        \"\"\"print each expr on its own line, indented\"\"\"\n        s = tab * indent + 'Block\\n'\n        for expr in self.exprs:\n            s += expr.treestr(indent + 1)\n        return s\n\n    @insert_tabs\n    def __str__(self):\n        return f'{{{newline}{newline.join(map(str, self.exprs))}{newline}}}'\n\n    def __repr__(self):\n        return f'Block({repr(self.exprs)})'\n\n\nclass Call(AST):\n    def __init__(self, expr:str|Callable, args:Union['Array',None]=None):\n        assert isinstance(expr, str|Callable), f'invalid type for call expression: `{self.expr}` of type `{type(self.expr)}`'\n        self.expr = expr\n        self.args = args\n\n\n    def eval(self, scope:Scope):\n        scope.attach_args(self.args)\n\n        #check if we need to resolve the name, or if it was an anonymous expression\n        if isinstance(self.expr, AST):\n            expr = self.expr.eval(scope)\n        else:\n            expr = scope.get(self.expr)\n        \n        #functions get called with args, while everything else just gets evaluated/returned\n        if isinstance(expr, Callable):\n            return expr.call(scope)\n        else:\n            return expr\n\n    def treestr(self, indent=0):\n        s = tab * indent + 'Call: '\n        if isinstance(self.expr, AST):\n            s += self.expr.treestr(indent + 1)\n        else:\n            s += self.expr\n        if self.args is not None:\n            s += '\\n'\n            s += self.args.treestr(indent+1)\n        return s\n\n    @insert_tabs\n    def __str__(self):\n        #TODO: not sure if expr of type Function should get () even if they don't have args\n        argsstr = '' if self.args is None else f'({str(self.args)[1:-1]})' #strip off [] and replace with ()\n        return f'{self.expr}' + (f'{self.args}' if self.args else '')\n\n    def __repr__(self):\n        return f'Call({repr(self.expr)}, {repr(self.args)})'\n\nclass String(Rangeable):\n    type:Type=Type('string')\n    \n    def __init__(self, val:str):\n        self.val = val\n    def eval(self, scope:Scope=None):\n        return self\n    def typeof(self, scope:Scope=None):\n        return self.type\n    #TODO: implement rangable methods\n    def topy(self, scope:Scope=None) -\u003e str:\n        return self.val\n    def treestr(self, indent=0):\n        return f'{tab * indent}String: `{self.val}`'\n    # @insert_tabs\n    def __str__(self):\n        return f'\"{self.val}\"'\n    def __repr__(self):\n        return f'String({repr(self.val)})'\n\nclass IString(AST):\n    def __init__(self, parts:list[AST]):\n        self.parts = parts\n\n    def eval(self, scope:Scope=None):\n        #convert self into a String()\n        return String(self.topy(scope))\n\n    def topy(self, scope:Scope=None):\n        return ''.join(str(part.eval(scope).topy(scope)) for part in self.parts)\n\n    def treestr(self, indent=0):\n        s = tab * indent + 'IString\\n'\n        for part in self.parts:\n            s += part.treestr(indent + 1) + '\\n'\n        return s\n\n    @insert_tabs\n    def __str__(self):\n        s = ''\n        for part in self.parts:\n            if isinstance(part, String):\n                s += part.val\n            else:\n                s += f'{{{part}}}'\n        return f'\"{s}\"'\n\n    def __repr__(self):\n        return f'IString({repr(self.parts)})'\n\nclass BinOp(AST):\n    def __init__(self, left:AST, right:AST, op:PyCallable[[Any, Any],Any], outtype:PyType[AST]|None, opname:str, opsymbol:str):\n        self.left = left\n        self.right = right\n        self.op = op\n        self.outtype = outtype\n        self.opname = opname\n        self.opsymbol = opsymbol\n\n    def eval(self, scope:Scope=None):\n        left = self.left.eval(scope)\n        right = self.right.eval(scope)\n        outtype = self.outtype\n\n        if outtype is None:\n            #TODO: remove support for this later. type should be determined after parsing during type checking!\n            # determine the outtype from the input types\n            assert type(left) == type(right), f\"For unspecified output type, both left and right must have the same type. Found {type(left)=}, {type(right)=}\"\n            outtype = type(left)\n\n        return outtype(self.op(left.topy(), right.topy()))\n    \n\n    def treestr(self, indent=0):\n        return f'{tab * indent}{self.opname}\\n{self.left.treestr(indent + 1)}\\n{self.right.treestr(indent + 1)}'\n    @insert_tabs\n    def __str__(self):\n        return f'{self.left} {self.opsymbol} {self.right}'\n    def __repr__(self):\n        return f'{self.opname}({repr(self.left)}, {repr(self.right)})'\n\n##################### Binary operators #####################\nclass Equal(BinOp):\n    def __init__(self, left:AST, right:AST):\n        super().__init__(left, right, operator.eq, Bool, 'Equal', '=?')\n\nclass NotEqual(BinOp):\n    def __init__(self, left:AST, right:AST):\n        super().__init__(left, right, operator.ne, Bool, 'NotEqual', 'not=?')\n\nclass Less(BinOp):\n    def __init__(self, left:AST, right:AST):\n        super().__init__(left, right, operator.lt, Bool, 'Less', '\u003c?')\n\nclass LessEqual(BinOp):\n    def __init__(self, left:AST, right:AST):\n        super().__init__(left, right, operator.le, Bool, 'LessEqual', '\u003c=?')\n\nclass Greater(BinOp):\n    def __init__(self, left:AST, right:AST):\n        super().__init__(left, right, operator.gt, Bool, 'Greater', '\u003e?')\n\nclass GreaterEqual(BinOp):\n    def __init__(self, left:AST, right:AST):\n        super().__init__(left, right, operator.ge, Bool, 'GreaterEqual', '\u003e=?')\n\nclass Add(BinOp):\n    def __init__(self, left:AST, right:AST, outtype:PyType[AST]):\n        super().__init__(left, right, operator.add, outtype, 'Add', '+')\n\nclass Sub(BinOp):\n    def __init__(self, left:AST, right:AST, outtype:PyType[AST]):\n        super().__init__(left, right, operator.sub, outtype, 'Sub', '-')\n\nclass Mul(BinOp):\n    def __init__(self, left:AST, right:AST, outtype:PyType[AST]):\n        super().__init__(left, right, operator.mul, outtype, 'Mul', '*')\n\nclass Div(BinOp):\n    def __init__(self, left:AST, right:AST, outtype:PyType[AST]):\n        super().__init__(left, right, operator.truediv, outtype, 'Div', '/')\n\nclass IDiv(BinOp):\n    def __init__(self, left:AST, right:AST, outtype:PyType[AST]):\n        super().__init__(left, right, operator.floordiv, outtype, 'IDiv', '//')\n\nclass Mod(BinOp):\n    def __init__(self, left:AST, right:AST, outtype:PyType[AST]):\n        super().__init__(left, right, operator.mod, outtype, 'Mod', '%')\n\nclass Pow(BinOp):\n    def __init__(self, left:AST, right:AST, outtype:PyType[AST]):\n        super().__init__(left, right, operator.pow, outtype, 'Pow', '**')\n\nclass And(BinOp):\n    def __init__(self, left:AST, right:AST, outtype:PyType[AST]):\n        super().__init__(left, right, operator.and_, outtype, 'And', 'and')\n\nclass Or(BinOp):\n    def __init__(self, left:AST, right:AST, outtype:PyType[AST]):\n        super().__init__(left, right, operator.or_, outtype, 'Or', 'or')\n\nclass Xor(BinOp):\n    def __init__(self, left:AST, right:AST, outtype:PyType[AST]):\n        super().__init__(left, right, operator.xor, outtype, 'Xor', 'xor')\n\nclass Nand(BinOp):\n    def __init__(self, left:AST, right:AST, outtype:PyType[AST]):\n        super().__init__(left, right, lambda l, r: not (l and r), outtype, 'Nand', 'nand')\n\nclass Nor(BinOp):\n    def __init__(self, left:AST, right:AST, outtype:PyType[AST]):\n        super().__init__(left, right, lambda l, r: not (l or r), outtype, 'Nor', 'nor')\n\nclass Xnor(BinOp):\n    def __init__(self, left:AST, right:AST, outtype:PyType[AST]):\n        super().__init__(left, right, lambda l, r: l == r, outtype, 'Xnor', 'xnor')\n\n\n\n##################### Unary operators #####################\nclass UnaryOp(AST):\n    def __init__(self, child:AST, op:PyCallable[[Any, Any],Any], outtype:PyType[AST]|None, opname:str, opsymbol:str):\n        self.child = child\n        self.op = op\n        self.outtype = outtype\n        self.opname = opname\n        self.opsymbol = opsymbol\n\n    def eval(self, scope:Scope=None):\n        child = self.child.eval(scope)\n        outtype = self.outtype\n\n        if outtype is None:\n            #TODO: remove support for this later. type should be determined after parsing during type checking!\n            # determine the outtype from the input type\n            outtype = type(child)\n\n        return outtype(self.op(child.topy()))\n\n    def treestr(self, indent=0):\n        return f'{tab * indent}{self.opname}\\n{self.child.treestr(indent + 1)}'\n    @insert_tabs\n    def __str__(self):\n        return f'{self.opsymbol}{self.child}'\n    def __repr__(self):\n        return f'{self.opname}({repr(self.child)})'\n\nclass Neg(UnaryOp):\n    def __init__(self, child:AST, outtype:PyType[AST]):\n        super().__init__(child, operator.neg, outtype, 'Neg', '-')\n\n\nclass Inv(UnaryOp):\n    def __init__(self, child:AST, outtype:PyType[AST]):\n        super().__init__(child, lambda x: 1/x, outtype, 'Inv', '/')\n\n\nclass Bool(AST):\n    def __init__(self, val:bool):\n        self.val = val\n    def eval(self, scope:Scope=None):\n        return self\n    def topy(self, scope:Scope=None):\n        return self.val\n    def typeof(self, scope:Scope=None):\n        return Type('bool')\n    def treestr(self, indent=0):\n        return f'{tab * indent}Bool: {self.val}'\n    # @insert_tabs\n    def __str__(self):\n        return f'{self.val}'\n    def __repr__(self):\n        return f'Bool({repr(self.val)})'\n\nclass Flowable(AST):\n    def was_entered(self) -\u003e bool:\n        \"\"\"Determine if the flowable branch was entered. Should reset before performing calls to flow and checking this.\"\"\"\n        raise NotImplementedError(f'flowables must implement `was_entered()`. No implementation found for {self.__class__}')\n\n    def reset_was_entered(self) -\u003e None:\n        \"\"\"reset the state of was_entered, in preparation for executing branches in a flow\"\"\"\n        raise NotADirectoryError(f'flowables must implement `reset_was_entered()`. No implementation found for {self.__class__}')\n\nclass If(Flowable):\n    def __init__(self, cond:AST, body:AST):\n        self.cond = cond\n        self.body = body\n        self._was_entered: bool = False\n    \n    def was_entered(self) -\u003e bool:\n        return self._was_entered\n    \n    def reset_was_entered(self) -\u003e None:\n        self._was_entered = False\n    \n    def eval(self, scope:Scope=None):\n        child = Scope(scope) #if clause gets an anonymous scope\n        if self.cond.eval(child).topy(child):\n            self._was_entered = True\n            return self.body.eval(child)\n\n    def treestr(self, indent=0):\n        s = tab * indent + 'If\\n'\n        s += self.cond.treestr(indent + 1) + '\\n'\n        s += self.body.treestr(indent + 1) + '\\n'\n        return s\n\n    @insert_tabs\n    def __str__(self):\n        return f'if {self.cond} {self.body}'\n        \n    def __repr__(self):\n        return f'If({repr(self.cond)}, {repr(self.body)})'\n\n#TODO: maybe loop can work the say way as If, taking in a list of clauses?\nclass Loop(Flowable):\n    def __init__(self, cond:AST, body:AST):\n        self.cond = cond\n        self.body = body\n        self._was_entered: bool = False\n    \n    def was_entered(self) -\u003e bool:\n        return self._was_entered\n    \n    def reset_was_entered(self) -\u003e None:\n        self._was_entered = False\n\n    def eval(self, scope:Scope=None):\n        child = Scope(scope)\n        while self.cond.eval(child).topy(child):\n            self._was_entered = True\n            self.body.eval(child)\n        #TODO: handle capturing values from a loop\n        #TODO: handle break and continue\n        #TODO: also eventually handle return (problem for other ASTs as well)\n\n        #for now just don't let loops return anything\n        return undefined\n\n    def treestr(self, indent=0):\n        return f'{tab * indent}Loop\\n{self.cond.treestr(indent + 1)}\\n{self.body.treestr(indent + 1)}'\n\n    @insert_tabs\n    def __str__(self):\n        return f'loop {self.cond} {self.body}'\n\n    def __repr__(self):\n        return f'Loop({repr(self.cond)}, {repr(self.body)})'\n\nclass Flow(AST):\n    def __init__(self, branches:list[Flowable|AST]):\n        \n        #separate out the possible last branch which need not be a Flowable()\n        if not isinstance(branches[-1], Flowable):\n            branches, default = branches[:-1], branches[-1]\n        else:\n            branches, default = branches, None\n        \n        #verify all branches (not necessarily including last) are Flowable\n        assert all(isinstance(branch, Flowable) for branch in branches), f'All branches in a flow (excluding the last one) must inherit `Flowable()`. Got {branches=}'\n        \n        self.branches: list[Flowable] = branches\n        self.default: AST|None = default\n        \n    \n    def eval(self, scope:Scope=None):\n        shared = Scope(scope) #for now, all clauses share a common anonymous scope\n\n        #reset was entered for this execution of the flow\n        for expr in self.branches:\n            expr.reset_was_entered()\n\n        #execute branches in the flow until one is entered\n        for expr in self.branches:\n            res = expr.eval(shared)\n            if expr.was_entered():\n                return res\n            \n        #execute any default branch if it exists\n        if self.default is not None:\n            return self.default.eval(shared)\n        \n        return undefined\n\n    def treestr(self, indent=0):\n        s = tab * indent + 'Flow\\n'\n        for expr in self.branches:\n            s += expr.treestr(indent + 1) + '\\n'\n        if self.default is not None:\n            s += self.default.treestr(indent + 1) + '\\n'\n        return s\n\n    @insert_tabs\n    def __str__(self):\n        s = ''\n        for i, expr in enumerate(self.branches):\n            if i == 0:\n                s += f'{expr}'\n            else:\n                s += f' else {expr}'\n        if self.default is not None:\n            s += f' else {self.default}'\n        return s\n\n    def __repr__(self):\n        return f'Flow({repr(self.branches)})'\n\n\n#DEBUG example\n\"\"\"\nloop i in [0..10)\n    printl(i)\n\n//expanded version of above\niter = [0..10).iter()\nlet i\nloop {(cond, i) = iter.next(); cond} \n    printl(i)\n\n//but ideally the entire iterator could be contained in the condition expression of the loop\n{\n    loop\n    (\n        // idempotent initialization here\n        #ifnotexists(iter) iter = [0..10).iter()\n        (cond, i) = iter.next()\n        cond\n    )\n    (\n        // condition and body share the same scope\n        printl(i)\n    )\n}\n\"\"\"\n#TODO: convert to class In()\n#  in basically does this, but has the extra stuff with the var being set, and so forth\n#class iter is the manager for things that can iterate, e.g. Range.iter()-\u003eRangeIter, Array.iter()-\u003eArrayIter, etc.\nclass In(AST):\n    #TODO: allow name to be an unpack structure as well\n    def __init__(self, name:str|PackStruct, iterable:Iterable):#, init:AST, body:AST):\n        self._id = f'.it_{id(self)}'\n        self.name = name\n        self.iterable = iterable\n\n    def eval(self, scope:Scope=None) -\u003e Bool:\n        #idempotent initialization\n        try:\n            it = scope.get(self._id)\n        except NameError:\n            it = self.iterable.iter(scope)\n            scope.let(self._id, value=it, const=True)\n\n        # body gets the binds element and returns the resulting condition\n        Unpack(['_', self.name], Next(Call(self._id))).eval(scope)\n        cond = Call('_').eval(scope)\n        assert isinstance(cond, Bool), f'loop condition must be a Bool, not {cond} of type {type(cond)}'\n        return cond\n\n    def treestr(self, indent=0):\n        return f'{tab * indent}In: {self.name}\\n{self.iterable.treestr(indent + 1)}'\n\n    @insert_tabs\n    def __str__(self):\n        return f'{self.name} in {self.iterable}'\n\n    def __repr__(self):\n        return f'In({repr(self.name)}, {repr(self.iterable)})'\n\nclass Next(AST):\n    \"\"\"handle getting the next element in the iteration\"\"\"\n    def __init__(self, iterable:AST):\n        self.iterable = iterable\n\n    def eval(self, scope:Scope=None) -\u003e AST:\n        it = self.iterable.eval(scope)\n        assert isinstance(it, Iter), f'cannot call next on {it}, not an iterator'\n        return it.next(scope)\n\n    def __repr__(self):\n        return f'Next({repr(self.iterable)})'\n\n    @insert_tabs\n    def __str__(self):\n        return f'next({self.iterable})'\n\nclass Number(Rangeable):\n    type:Type = Type('number')\n\n    def __init__(self, val:int|float):\n        self.val = val\n    def eval(self, scope:Scope=None):\n        return self\n    def typeof(self):\n        return Type('number')\n    \n    #Rangeable methods\n    def compare(self, other:'Number', scope:Scope=None) -\u003e 'Number':\n        return Number(self.val - other.val)\n    def successor(self, step:'Number'=undefined, scope:'Scope'=None) -\u003e 'Number':\n        if step is undefined:\n            return Number(self.val + 1)\n        else:\n            return Number(self.val + step.val)\n    def predecessor(self, step:'Number'=undefined, scope:'Scope'=None) -\u003e 'Number':\n        if step is undefined:\n            return Number(self.val - 1)\n        else:\n            return Number(self.val - step.val)\n    @staticmethod\n    def max(self) -\u003e 'Number':\n        return Number(float('inf'))\n    @staticmethod\n    def min(self) -\u003e 'Number':\n        return Number(float('-inf'))\n    \n    def topy(self, scope:Scope=None):\n        return self.val\n    def treestr(self, indent=0):\n        return f'{tab * indent}Number: {self.val}'\n    # @insert_tabs\n    def __str__(self):\n        return f'{self.val}'\n    def __repr__(self):\n        return f'Number({repr(self.val)})'\n\n\n#TODO: handling of different types of ranges (e.g. character ranges, vs number ranges). \n#   how to handle +inf/-inf in non-numeric case? implies some sort of max/min element for the range value...\n#   i.e. class Rangeable(AST): where class Number(Rangable), Char(Rangeable), etc.\n#   Rangable types should implement successor(step=1) and predecessor(step=1) methods\nclass Range(Iterable,Unpackable):\n    \"\"\"\n    Inspired by Haskell syntax for ranges:\n    [first..]               // first to inf\n    [first,second..]        // step size is second-first\n    [first..last]           // first to last\n    [first,second..last]    // first to last, step size is second-first\n    //[first..2ndlast,last] // this is explicitly NOT ALLOWED, as it is covered by the previous case, and can have unintuitive behavior\n    [..2ndlast,last]        // -inf to last, step size is last-penultimate\n    [..last]                // -inf to last\n    [..]                    // -inf to inf\n\n    open/closed ranges:\n    [first..last]           // first to last including first and last\n    [first..last)           // first to last including first, excluding last\n    (first..last]           // first to last excluding first, including last\n    (first..last)           // first to last excluding first and last\n    first..last             // same as [first..last]. Note that parentheses are required if `second` is included in the expression\n    \"\"\"\n    def __init__(self, first:Rangeable=undefined, second:Rangeable=undefined, last:Rangeable=undefined, include_first:bool=True, include_last:bool=True):\n        range_type = type(first) if first is not undefined else type(second) if second is not undefined else type(last)\n        if range_type is undefined:\n            range_type = Number\n        assert issubclass(range_type, Rangeable), f'Range type must be of type Rangeable, not {range_type}'\n        #TODO: type checking to confirm that first, second, and last are all compatible types\n\n        self.range_type = range_type\n        self.first = first if first is not undefined else range_type.min()\n        self.second = second\n        self.last = last if last is not undefined else range_type.max()\n        self.include_first = include_first\n        self.include_last = include_last\n        \n\n    def eval(self, scope:Scope=None):\n        return self\n    \n    def iter(self, scope:'Scope'=None) -\u003e Iter:\n        return RangeIter(self)\n\n    # def typeof(self):\n    #     return Type('Range') #TODO: this should maybe care about the type of data in it?\n\n    def topy(self, scope:Scope=None):\n        step_size = self.second.topy() - self.first.topy() if self.second is not undefined else 1\n        return range(self.first.topy(scope), self.last.topy(scope), step_size)\n\n    def treestr(self, indent=0):\n        s = f'{tab * indent}Range\\n'\n        s += f'{tab * (indent + 1)}first:\\n{self.first.treestr(indent + 2)}\\n'\n        s += f'{tab * (indent + 1)}second:\\n{self.second.treestr(indent + 2)}\\n'\n        s += f'{tab * (indent + 1)}last:\\n{self.last.treestr(indent + 2)}\\n'\n        return s\n\n    @insert_tabs\n    def __str__(self):\n        s = ''\n        s += '[' if self.include_first else '('\n        if self.first is not undefined:\n            s += str(self.first)\n        if self.second is not undefined:\n            s += ','\n            s += str(self.second)\n        s += '..'\n        if self.last is not undefined:\n            s += str(self.last)\n        s += ']' if self.include_last else ')'\n        return s\n\n    def __repr__(self):\n        interval = f'{\"[\" if self.include_first else \"(\"}{\"]\" if self.include_last else \")\"}'\n        return f'Range({repr(self.first)},{repr(self.second)},{repr(self.last)},interval={interval})'\n\n\nclass RangeIter(Iter):\n    def __init__(self, ast:AST):#range:Range): #TODO: want AST[Range] typing which means it evals to a range...\n        # self._id = f'.iter_{id(self)}'\n        self.ast = ast\n    #     self.reset()\n\n    # def reset(self):\n        self.range = None\n        self.i = None\n        self.step = None\n\n    def eval(self, scope:Scope=None):\n        return self\n\n    def next(self, scope:Scope=None) -\u003e Unpackable:\n        if self.range is None:\n            self.range = self.ast.eval(scope)\n            assert isinstance(self.range, Range), f'RangeIter must be initialized with an AST that evaluates to a Range, not {type(self.range)}' \n            self.i = self.range.first\n            #set the stepsize (needed access to the scope)\n            if self.range.second is not undefined:\n                self.step = self.range.second.compare(self.range.first, scope)\n            else:\n                self.step = undefined\n            \n            #skip the first element if it's not included (closed interval)\n            if not self.range.include_first:\n                self.i = self.i.successor(self.step, scope)\n\n        #check the stop condition and return the next element\n        if (c:=self.i.compare(self.range.last).val) \u003c 0 or (c==0 and self.range.include_last):\n            ret = self.i\n            self.i = self.i.successor(self.step, scope)\n            return Array([Bool(True), ret])\n        else:\n            return Array([Bool(False), undefined])\n\n    def typeof(self):\n        return Type('RangeIter')\n\n    def topy(self, scope:Scope=None):\n        raise NotImplementedError\n\n    def treestr(self, indent=0):\n        return f'{tab * indent}RangeIter:\\n{self.ast.treestr(indent + 1)}'\n        \n    @insert_tabs\n    def __str__(self):\n        return f'RangeIter({self.ast})'\n\n    def __repr__(self):\n        return f'RangeIter({repr(self.ast)})'\n\n\nclass Array(Iterable, Unpackable):\n    def __init__(self, vals:list[AST]):\n        self.vals = vals\n    def eval(self, scope:Scope=None):\n        return self\n    def typeof(self, scope:Scope=None):\n        #TODO: this should include the type of the data inside the vector...\n        return Type('Array')\n    \n    #unpackable interface\n    def len(self, scope:Scope=None):\n        return len(self.vals)\n    def get(self, key:int|EllipsisType|slice|tuple[int|EllipsisType|slice], scope:Scope=None):\n        if isinstance(key, int):\n            return self.vals[key]\n        elif isinstance(key, EllipsisType):\n            return self\n        elif isinstance(key, slice):\n            return Array(self.vals[key])\n        elif isinstance(key, tuple):\n            #probably only valid for N-dimensional/non-jagged vectors\n            raise NotImplementedError('TODO: implement tuple indexing for Array')\n        else:\n            raise TypeError(f'invalid type for Array.get: `{key}` of type `{type(key)}`')\n\n\n    #iterable interface\n    #TODO...\n\n    def topy(self, scope:Scope=None):\n        return [v.eval(scope).topy(scope) for v in self.vals]\n    def treestr(self, indent=0):\n        s = tab * indent + 'Array\\n'\n        for v in self.vals:\n            s += v.treestr(indent + 1) + '\\n'\n        return s\n    @insert_tabs\n    def __str__(self):\n        return f'[{\" \".join(map(str, self.vals))}]'\n    def __repr__(self):\n        return f'Array({repr(self.vals)})'\n\n\n\nclass Void(AST):\n    \"\"\"void singleton\"\"\"\n\n    type:Type=Type('void')\n\n    def __new__(cls):\n        if not hasattr(cls, 'instance'):\n            cls.instance = super(Void, cls).__new__(cls)\n        return cls.instance\n    def eval(self, scope:Scope=None):\n        return self\n    def topy(self, scope:Scope=None):\n        return None\n    def typeof(self, scope:Scope=None):\n        return Type('void')\n    def treesr(self, indent=0):\n        return tab * indent + 'Void'\n    def __str__(self):\n        return 'void'\n    def __repr__(self):\n        return 'Void()'\n\n#void shorthand, for convenience\nvoid = Void()\n\n\n\n\n\n############################################## EXAMPLE PROGRAMS #############################################\n\ndef hello(root:Scope) -\u003e AST:\n    \"\"\"printl('Hello, World!')\"\"\"\n    return Call('printl', Array([String('Hello, World!')]))\n\n\ndef hello_func(root:Scope) -\u003e AST:\n    \"\"\"\n    {\n        main = () =\u003e {printl('Hello, World!')}\n        main\n    }\n    \"\"\"\n    return Block([\n        Bind(\n            'main',\n            Function(\n                [],\n                Call('printl', Array([String('Hello, World!')])),\n                root\n            )\n        ),\n        Call('main'),\n    ])\n   \n\ndef anonymous_func(root:Scope) -\u003e AST:\n    \"\"\"\n    {\n        (() =\u003e printl('Hello, World!'))()\n    }\n    \"\"\"\n    return Block([\n        Call(\n            Function(\n                [],\n                Call('printl', Array([String('Hello, World!')])),\n                root\n            )\n        ),\n    ])\n\ndef hello_name(root:Scope) -\u003e AST:\n    \"\"\"\n    {\n        print(\"What's your name? \")\n        name = readl()\n        printl('Hello {name}!')\n    }\n    \"\"\"\n    return Block([\n        Call('print', Array([String(\"What's your name? \")])),\n        Bind('name', Call('readl')),\n        Call('printl', Array([IString([String('Hello '), Call('name'), String('!')])])),\n    ])\n\n\ndef if_else(root:Scope) -\u003e AST:\n    \"\"\"\n    {\n        print(\"What's your name? \")\n        name = readl()\n        if name =? 'Alice' printl('Hello Alice!')\n        else printl('Hello stranger!')\n    }\n    \"\"\"\n    return Block([\n        Call('print', Array([String(\"What's your name? \")])),\n        Bind('name', Call('readl')),\n        Flow([\n            If(\n                Equal(Call('name'), String('Alice')),\n                Call('printl', Array([String('Hello Alice!')]))\n            ),\n            Call('printl', Array([String('Hello Stranger!')])),\n        ])\n    ])\n\n\ndef if_else_if(root:Scope) -\u003e AST:\n    \"\"\"\n    {\n        print(\"What's your name? \")\n        name = readl()\n        if name =? 'Alice' printl('Hello Alice!')\n        else if name =? 'Bob' printl('Hello Bob!')\n        else printl('Hello stranger!')\n    }\n    \"\"\"\n    return Block([\n        Call('print', Array([String(\"What's your name? \")])),\n        Bind('name', Call('readl')),\n        Flow([\n            If(\n                Equal(Call('name'), String('Alice')),\n                Call('printl', Array([String('Hello Alice!')]))\n            ),\n            If(\n                Equal(Call('name'), String('Bob')),\n                Call('printl', Array([String('Hello Bob!')]))\n            ),\n            Call('printl', Array([String('Hello Stranger!')])),\n        ])\n    ])\n\n\ndef hello_loop(root:Scope) -\u003e AST:\n    \"\"\"\n    {\n        print(\"What's your name? \")\n        name = readl()\n        i = 0\n        loop i \u003c? 10 {\n            printl('Hello {name}!')\n            i = i + 1\n        }\n    }\n    \"\"\"\n    return Block([\n        Call('print', Array([String(\"What's your name? \")])),\n        Bind('name', Call('readl')),\n        Bind('i', Number(0)),\n        Loop(\n            Less(Call('i'), Number(10)),\n            Block([\n                Call('printl', Array([IString([String('Hello '), Call('name'), String('!')])])),\n                Bind('i', Add(Call('i'), Number(1), Number)),\n            ])\n        )\n    ])\n\n\ndef unpack_test(root:Scope) -\u003e AST:\n    \"\"\"\n    {\n        s = ['Hello' ['World' '!'] 5 10]\n        printl('s={s}')\n        a, b, c, d = s\n        printl('a={a} b={b} c={c} d={d}')\n        a, ...b = s\n        printl('a={a} b={b}')\n        ...a, b = s\n        printl('a={a} b={b}')\n        a, [b, c], ...d = s\n        printl('a={a} b={b} c={c} d={d}')\n\n        //error tests\n        //a, b, c, d, e = s         //error: not enough values to unpack\n        //a, b = s                  //error: too many values to unpack\n        //a, ...b, c, d, e, f = s   //error: too many values to unpack\n\n        //TBD how unpack would handle `a, ...b, c, d, e = s`. Probably b would be empty?\n    }\n    \"\"\"\n\n    return Block([\n        Bind('s', Array([String('Hello'), Array([String('World'), String('!')]), Number(5), Number(10)])),\n        Call('printl', Array([IString([String('s='), Call('s')])])),\n        Unpack(['a', 'b', 'c', 'd'], Call('s')),\n        Call('printl', Array([IString([String('a='), Call('a'), String(' b='), Call('b'), String(' c='), Call('c'), String(' d='), Call('d')])])),\n        Unpack(['a', '...b'], Call('s')),\n        Call('printl', Array([IString([String('a='), Call('a'), String(' b='), Call('b')])])),\n        Unpack(['...a', 'b'], Call('s')),\n        Call('printl', Array([IString([String('a='), Call('a'), String(' b='), Call('b')])])),\n        Unpack(['a', ['b', 'c'], '...d'], Call('s')),\n        Call('printl', Array([IString([String('a='), Call('a'), String(' b='), Call('b'), String(' c='), Call('c'), String(' d='), Call('d')])])),\n\n        # Test unpacking too few/many values\n        # Unpack(['a', 'b', 'c', 'd', 'e'], Call('s')),         # error: not enough values to unpack\n        # Unpack(['a', 'b'], Call('s')),                        # error: too many values to unpack\n        # Unpack(['a', '...b', 'c', 'd', 'e', 'f'], Call('s')), # error: too many values to unpack\n    ])\n\n\ndef range_iter_test(root:Scope) -\u003e AST:\n    \"\"\"\n    {\n        r = [0,2..20]\n        it = iter(r)\n        printl(next(it))\n        printl(next(it))\n        printl(next(it))\n        printl(next(it))\n        printl(next(it))\n        printl(next(it))\n        printl(next(it))\n        printl(next(it))\n        printl(next(it))\n        printl(next(it))\n        printl(next(it)) //last iteration. should return [true, 20]\n        printl(next(it)) //should return [false, undefined]\n        printl(next(it))\n        printl(next(it))\n    }\n    \"\"\"\n    return Block([\n        Bind('r', Range(Number(0), Number(2), Number(20))),\n        Bind('it', RangeIter(Call('r'))),\n        Call('printl', Array([Next(Call('it'))])),\n        Call('printl', Array([Next(Call('it'))])),\n        Call('printl', Array([Next(Call('it'))])),\n        Call('printl', Array([Next(Call('it'))])),\n        Call('printl', Array([Next(Call('it'))])),\n        Call('printl', Array([Next(Call('it'))])),\n        Call('printl', Array([Next(Call('it'))])),\n        Call('printl', Array([Next(Call('it'))])),\n        Call('printl', Array([Next(Call('it'))])),\n        Call('printl', Array([Next(Call('it'))])),\n        Call('printl', Array([Next(Call('it'))])),\n        Call('printl', Array([Next(Call('it'))])), #should print [False, None] since the iterator is exhausted\n        Call('printl', Array([Next(Call('it'))])),\n        Call('printl', Array([Next(Call('it'))])),\n    ])\n\n\ndef loop_iter_manual(root:Scope) -\u003e AST:\n    \"\"\"\n    {\n        it = iter([0,2..10])\n        [cond, i] = next(it)\n        loop cond {\n            printl(i)\n            [cond, i] = next(it)\n        }\n    }\n    \"\"\"\n    return Block([\n        Bind('it', RangeIter(Range(Number(0), Number(2), Number(10)))),\n        Unpack(['cond', 'i'], Next(Call('it'))),\n\n        Loop(\n            Call('cond'),\n            Block([\n                Call('printl', Array([Call('i')])),\n                Unpack(['cond', 'i'], Next(Call('it'))),\n            ])\n        )\n    ])\n\n\n\ndef loop_in_iter(root:Scope) -\u003e AST:\n    \"\"\"\n    {\n        loop i in [0,2..10] printl(i)\n    }\n    \"\"\"\n    return Loop(\n        In('i', Range(Number(0), Number(2), Number(10))),\n        Call('printl', Array([Call('i')])),\n    )\n   \n\ndef nested_loop(root:Scope) -\u003e AST:\n    \"\"\"    \n    loop i in [0,2..10]\n        loop j in [0,2..10]\n            printl('{i},{j}')\n    \"\"\"\n    return Loop(\n        In('i', Range(Number(0), Number(2), Number(10))),\n        Loop(\n            In('j', Range(Number(0), Number(2), Number(10))),\n            Call('printl', Array([IString([Call('i'), String(','), Call('j')])])),\n        )\n    )\n\n\n\ndef block_printing(root:Scope) -\u003e AST:\n    \"\"\"\n    {\n        loop i in [0,2..5] {\n            loop j in [0,2..5] {\n                loop k in [0,2..5] {\n                    loop l in [0,2..5] {\n                        loop m in [0,2..5] {\n                            printl('{i},{j},{k},{l},{m}')\n                        }\n                    }\n                }\n            }\n        }\n    }\n    \"\"\"\n    return Block([\n        Loop(\n            In('i', Range(Number(0), Number(2), Number(5))),\n            Block([\n                Loop(\n                    In('j', Range(Number(0), Number(2), Number(5))),\n                    Block([\n                        Loop(\n                            In('k', Range(Number(0), Number(2), Number(5))),\n                            Block([\n                                Loop(\n                                    In('l', Range(Number(0), Number(2), Number(5))),\n                                    Block([\n                                        Loop(\n                                            In('m', Range(Number(0), Number(2), Number(5))),\n                                            Block([\n                                                Call('printl', Array([IString([Call('i'), String(','), Call('j'), String(','), Call('k'), String(','), Call('l'), String(','), Call('m')])])),\n                                            ])\n                                        )\n                                    ])\n                                )\n                            ])\n                        )\n                    ])\n                )\n            ])\n        )\n    ])\n\ndef rule110(root:Scope) -\u003e AST:\n    \"\"\"\n    progress = world:vector\u003cbit\u003e =\u003e {\n        update:bit = 0\n        loop i in 0..world.length\n        {\n            if i \u003e? 0 world[i-1] = update //TODO: #notfirst handled by compiler unrolling the loop into prelude, interludes, and postlude\n            update = 0b01110110 \u003c\u003c (world[i-1..i+1] .?? 0 .\u003c\u003c [2 1 0])\n        }\n        world.push(update)\n    }\n\n    world: vector\u003cbit\u003e = [1]\n    loop true\n    {\n        printl(world)\n        progress(world)\n    }\n    \"\"\"\n\n    #rule 110\n    #TODO: handle type annotations in AST\n    return Block([\n        Bind(\n            'progress', \n            Function(\n                [Arg('world', Type('vector', [Type('bit')]))], \n                Block([\n                    Bind('cell_update', Number(0)),\n                    # loop i in 0..world.length\n                    #     if i \u003e? 0 world[i-1] = cell_update\n                    #     update = (0b01110110 \u003c\u003c (((world[i-1] ?? 0) \u003c\u003c 2) or ((world[i] ?? 0) \u003c\u003c 1) or (world[i+1] ?? 0)))\n                    # world.push(update)\n                    #etc....\n                ]), \n                root\n            ),\n            # Type('function', [Type('vector', [Type('bit')]), Type('vector', [Type('bit')])]),\n        ),\n        Let('world', Type('vector', [Type('bit')])),\n        Bind(\n            'world',\n            Array([Number(1)]),\n        ),\n        # loop true\n        #     printl(world)\n        #     update(world)\n    ])\n\n\n\n\nif __name__ == '__main__':\n    show = True\n    show_verbose = True\n    run = True\n\n    progs = [\n        hello,\n        hello_func,\n        anonymous_func,\n        hello_name,\n        if_else,\n        if_else_if,\n        hello_loop,\n        unpack_test,\n        range_iter_test,\n        loop_iter_manual,\n        loop_in_iter,\n        nested_loop,\n        block_printing,\n        # rule110,\n    ]\n\n    for prog in progs:\n        #set up root scope with some functions\n        root = Scope.default()\n\n        # get the program AST\n        ast = prog(root)\n\n        # display and or run the program\n        if show:\n            print(ast)\n        if show_verbose:\n            print(repr(ast))\n        if run:\n            ast.eval(root)\n\n        print('----------------------------------------')"])</script><script>self.__next_f.push([1,"1e:T69d,"])</script><script>self.__next_f.push([1,"# llvm backend or interpreter\n# all backends either compile+run the code or just run it directly\n\nfrom argparse import ArgumentParser, REMAINDER\nfrom backend import backends, get_backend, python_interpreter, llvm_compiler, get_version\n\nimport pdb\n\ndef main():\n    arg_parser = ArgumentParser(description='Dewy Compiler')\n\n    # positional argument for the file to compile\n    arg_parser.add_argument('file', help='.dewy file to run')\n\n    # mutually exclusive flags for specifying the backend to use\n    group = arg_parser.add_mutually_exclusive_group()\n    group.add_argument('-i', action='store_true', help='(DEFAULT) Run in interpreter mode with the python backend')\n    group.add_argument('-c', action='store_true', help='Run in compiler mode with the llvm backend (not implemented yet)')\n    group.add_argument('--backend', type=str, help=f'Specify a backend compiler/interpreter by name to use. Backends will include: {backends} (however currently only python is available).')\n\n    arg_parser.add_argument('-v', '--version', action='version', version=f'Dewy {get_version()}', help='Print version information and exit')\n    arg_parser.add_argument('args', nargs=REMAINDER, help='Arguments after the file are passed directly to program')\n\n    args = arg_parser.parse_args()\n\n    # default interpreter is python. default compiler is llvm. default with no args is python.\n    if args.backend: backend = get_backend(args.backend)\n    elif args.c:     backend = llvm_compiler\n    elif args.i:     backend = python_interpreter\n    else:            backend = python_interpreter\n    \n    # run with the selected backend\n    backend(args.file, args.args)\n\n\n\n\n\nif __name__ == '__main__':\n    main()"])</script><script>self.__next_f.push([1,"1f:T8a5a,"])</script><script>self.__next_f.push([1,"# from __future__ import annotations\n\nfrom dewy import (\n    AST, PrototypeAST,\n    Undefined, undefined,\n    Void, void,\n    Identifier,\n    Callable,\n    Orderable,\n    Rangeable,\n    Unpackable,\n    Iter,\n    Iterable,\n    Type,\n    Arg,\n    Tuple,\n    Function,\n    Builtin,\n    Let,\n    Bind,\n    PackStruct,\n    Unpack,\n    Block,\n    Call,\n    String, IString,\n    BinOp,\n    Equal, NotEqual, Less, LessEqual, Greater, GreaterEqual,\n    Add, Sub, Mul, Div, IDiv, Mod, Pow,\n    UnaryOp,\n    Neg, Inv,\n    Bool,\n    Flow,\n    If,\n    Loop,\n    In,\n    Next,\n    Number,\n    Range,\n    RangeIter,\n    Array,\n    Scope,\n)\nfrom tokenizer import ( tokenize, tprint, traverse_tokens,                       \n    unary_prefix_operators,\n    unary_postfix_operators,\n    binary_operators,\n    \n    Token,\n\n    WhiteSpace_t,\n\n    Escape_t,\n\n    Identifier_t,\n    Block_t,\n    TypeParam_t,\n    RawString_t,\n    String_t,\n    Integer_t,\n    BasedNumber_t,\n    Boolean_t,\n    Hashtag_t,\n    DotDot_t,\n\n    Keyword_t,\n\n    Juxtapose_t,\n    Operator_t,\n    ShiftOperator_t,\n    Comma_t,\n)\n\nfrom postok import post_process, get_next_chain, is_op, Chain, Flow_t\n\nfrom utils import based_number_to_int, bool_to_bool\nfrom dataclasses import dataclass\nfrom typing import Generator\nfrom itertools import groupby, chain as iterchain\nfrom enum import Enum, auto\n\ntry:\n    from rich import print, traceback; traceback.install(show_locals=True)\nexcept:\n    print('rich unavailable for import. using built-in printing')\n\nimport pdb\n\n\n\n\n#compiler pipeline steps:\n# 1. tokenize\n# 2. post tokenization\n#    -\u003e invert whitespace to juxtapose\n#    -\u003e bundle conditional chains into a single token\n#    -\u003e chain operator sequences into a single compount operator\n#    -\u003e desugar things, e.g. empty range `..` to `()..()`\n# 3. parse tokens to AST\n# 4. post parse\n#    -\u003e convert PrototypeASTs to concrete AST\n#    -\u003e (maybe) set correct scope for exprs that use (e.g. Function)\n# 5. type checking, other validation, etc.\n# 6. high level optimizations/transformations\n# 7. generate code via a backend (e.g. llvm, c, python)\n#    -\u003e llvm: convert ast to ssa form, then generate llvm ir from ssa form\n\n\n\n@dataclass\nclass qint:\n    \"\"\"\n    quantum int for dealing with precedences that are multiple values at the same time\n    qint's can only be strictly greater or strictly less than other values. Otherwise it's ambiguous\n    \"\"\"\n    values:set[int]\n    def __gt__(self, other:'int|qint') -\u003e bool:\n        if isinstance(other, int):\n            return all(v \u003e other for v in self.values)\n        return all(v \u003e other for v in self.values)\n    def __lt__(self, other:'int|qint') -\u003e bool:\n        if isinstance(other, int):\n            return all(v \u003c other for v in self.values)\n        return all(v \u003c other for v in self.values)\n    def __ge__(self, other:'int|qint') -\u003e bool: return self.__gt__(other)\n    def __le__(self, other:'int|qint') -\u003e bool: return self.__lt__(other)\n    def __eq__(self, other:'int|qint') -\u003e bool: return False\n        \n\n\n######### Operator Precedence Table #########\n#TODO: class for compund operators, e.g. += -= .+= .-= not=? not\u003e? etc.\n#TODO: how to handle unary operators in the table? perhaps make PrefixOperator_t/PostfixOperator_t classes?\n#TODO: add specification of associativity for each row\nclass Associativity(Enum):\n    left = auto()    #left-to-right\n    right = auto()   #right-to-left\n    prefix = auto()\n    postfix = auto()\n    none = auto()\n    fail = auto()\n\noperator_groups: list[tuple[Associativity, list[Operator_t|ShiftOperator_t|Juxtapose_t|Comma_t]]] = list(reversed([\n    (Associativity.prefix, [Operator_t('@')]),\n    (Associativity.left, [Operator_t('.'), Juxtapose_t(None)]), #jux-call, jux-index\n    (Associativity.right,  [Operator_t('^')]),\n    (Associativity.left, [Juxtapose_t(None)]), #jux-multiply\n    (Associativity.left, [Operator_t('*'), Operator_t('/'), Operator_t('%')]),\n    (Associativity.left, [Operator_t('+'), Operator_t('-')]),\n    (Associativity.left, [ShiftOperator_t('\u003c\u003c'), ShiftOperator_t('\u003e\u003e'), ShiftOperator_t('\u003c\u003c\u003c'), ShiftOperator_t('\u003e\u003e\u003e'), ShiftOperator_t('\u003c\u003c!'), ShiftOperator_t('!\u003e\u003e')]),\n    (Associativity.left, [Operator_t('=?'), Operator_t('\u003e?'), Operator_t('\u003c?'), Operator_t('\u003e=?'), Operator_t('\u003c=?')]),\n    (Associativity.left, [Operator_t('and'), Operator_t('nand'), Operator_t('\u0026')]),\n    (Associativity.left, [Operator_t('xor'), Operator_t('xnor')]),\n    (Associativity.left, [Operator_t('or'), Operator_t('nor'), Operator_t('|')]),\n    (Associativity.none,  [Comma_t(None)]),\n    # (Associativity.none/fail?, [RangeJuxtapose_t(None)]), #jux-range\n    (Associativity.right,  [Operator_t('=\u003e')]), # () =\u003e () =\u003e () =\u003e 42\n    (Associativity.fail,  [Operator_t('=')]),\n    (Associativity.none,  [Operator_t('else')]),\n]))\nprecedence_table: dict[Operator_t|ShiftOperator_t|Juxtapose_t|Comma_t, int|qint] = {}\nassociativity_table: dict[int, Associativity] = {}\nfor i, (assoc, group) in enumerate(operator_groups):\n\n    #mark precedence level i as the specified associativity\n    associativity_table[i] = assoc\n\n    #insert all ops in the row into the precedence table at precedence level i\n    for op in group:\n        if op not in precedence_table:\n            precedence_table[op] = i\n            continue\n        \n        val = precedence_table[op]\n        if isinstance(val, int):\n            precedence_table[op] = qint({val, i})\n        else:\n            precedence_table[op] = qint(val.values|{i})\n\n\ndef operator_precedence(op:Operator_t|ShiftOperator_t|Juxtapose_t|Comma_t) -\u003e int | qint:\n    \"\"\"\n    precedence:\n    [HIGHEST]\n    (prefix) @\n    . \u003cjux call\u003e \u003cjux index access\u003e\n    (prefix) not ...\n    (postfix) ? `\n    ^                                   //right-associative\n    \u003cjux mul\u003e\n    / * %\n    + -\n    \u003c\u003c \u003e\u003e \u003c\u003c\u003c \u003e\u003e\u003e \u003c\u003c! !\u003e\u003e\n    \u003cjux range\u003e                         //TBD, e.g. [(first,second)..last]\n    in\n    =? \u003e? \u003c? \u003e=? \u003c=? not=? \u003c=\u003e is? isnt? @?\n    and nand \u0026\n    xor xnor                            //following C's precedence: and \u003e xor \u003e or\n    or nor |\n    ,                                   //tuple maker\n    =\u003e\n    = .= \u003cop\u003e= .\u003cop\u003e=  (e.g. += .+=)    //right-associative (but technically causes a type error since assignments can't be chained)\n    else\n    (postfix) ;\n    \u003cseq\u003e (i.e. space)\n    [LOWEST]\n\n    TODO:\n    - add operators: as transmute |\u003e \u003c| -\u003e \u003c-\u003e \u003c- :\n\n    [Notes]\n    .. for ranges is not an operator, it is an expression. it uses juxtapose to bind to left/right arguments (or empty), and type-checks left and right\n    if-else-loop chain expr is more like a single unit, so it doesn't really have a precedence. but they act like they have the lowest precedence since the expressions they capture will be full chains only broken by space/seq\n    the unary versions of + - * / % have the same precedence as their binary versions\n    \"\"\"\n\n    #TODO: handling compound operators like +=, .+=, etc.\n    # if isinstance(op, CompoundOperator_t):\n    #     op = op.base\n\n    try:\n        return precedence_table[op]\n    except:\n        raise ValueError(f\"ERROR: expected operator, got {op=}\") from None\n\ndef operator_associativity(op:Operator_t|ShiftOperator_t|Juxtapose_t|Comma_t|int) -\u003e Associativity:\n    if not isinstance(op, int):\n        i = operator_precedence(op)\n        assert isinstance(i, int), f'Cannot determine associativity of operator ({op}) with multiple precedence levels ({i})'\n    else:\n        i = op\n    try:\n        return associativity_table[i]\n    except:\n        raise ValueError(f\"Error: failed to determine associativity for operator {op}\") from None\n\nopname_map = {\n    '@': 'reference',\n    '.': 'access',\n    '^': 'power',\n    '*': 'multiply',\n    '/': 'divide',\n    '%': 'modulus',\n    '+': 'add',\n    '-': 'subtract',\n    '\u003c\u003c': 'left shift',\n    '\u003e\u003e': 'right shift',\n    '\u003e\u003e\u003e': 'rotate left no carry',\n    '\u003c\u003c\u003c': 'rotate right no carry',\n    '\u003c\u003c!': 'rotate left with carry',\n    '!\u003e\u003e': 'rotate right with carry',\n    '\u003e?': 'greater than',\n    '\u003c?': 'less than',\n    '\u003e=?': 'greater than or equal',\n    '\u003c=?': 'less than or equal',\n    '=?': 'equal',\n    'and': 'and',\n    'nand': 'nand',\n    '\u0026': 'and',\n    'xor': 'xor',\n    'xnor': 'xnor',\n    'or': 'or',\n    'nor': 'nor',\n    '|': 'or',\n    '=\u003e': 'function arrow',\n    '=': 'bind',\n    'else': 'flow alternate',\n    ';': 'semicolon',\n    'in': 'in',\n    'as': 'as',\n    'transmute': 'transmute',\n    '|\u003e': 'pipe',\n    '\u003c|': 'reverse pipe',\n    '-\u003e': 'right pointer',\n    '\u003c-\u003e': 'bidir pointer',\n    '\u003c-': 'left pointer',\n    ':': 'type annotation',\n\n    Comma_t(None): 'comma',\n    Juxtapose_t(None): 'unknown juxtapose',\n}\ndef get_precedence_table_markdown() -\u003e str:\n    \"\"\"return a string that is the markdown table for the docs containing all the operators\"\"\"\n    header = '| Precedence | Operator | Name | Associativity |\\n| --- | --- | --- | --- |'\n    \n    def get_ops_str(ops:list[Operator_t|ShiftOperator_t|Juxtapose_t|Comma_t]) -\u003e str:\n        return '\u003cbr\u003e'.join(f'`{op.op if isinstance(op, (Operator_t, ShiftOperator_t)) else op.__class__.__name__[:-2].lower()}`' for op in ops)\n    def get_opnames_str(ops:list[Operator_t|ShiftOperator_t|Juxtapose_t|Comma_t]) -\u003e str:\n        return '\u003cbr\u003e'.join(f'{opname_map.get(op.op, None) if isinstance(op, (Operator_t, ShiftOperator_t)) else op.__class__.__name__[:-2].lower()}' for op in ops)\n    def get_row_str(row:tuple[Associativity, list[Operator_t|ShiftOperator_t|Juxtapose_t|Comma_t]]) -\u003e str:\n        assoc, group = row\n        return f'{get_ops_str(group)} | {get_opnames_str(group)} | {assoc.name}'\n\n    rows = [\n        f'| {i} | {get_row_str(row)} |'\n        for i, row in reversed([*enumerate(operator_groups)])\n    ]\n\n    return header + '\\n' + '\\n'.join(rows)\n\n\n#TODO: this isn't very well integrated into the type system...\n# operator_result_type_table = {\n#     (Number.type, Add, Number.type): Number,\n#     (Number.type, Sub, Number.type): Number,\n#     (Number.type, Mul, Number.type): Number,\n#     (Number.type, Div, Number.type): Number,\n#     (Inv, Number.type): Number,\n#     (Neg, Number.type): Number,\n#     #TODO: add anything else to the matrix\n# }\n\n\n# @cache\ndef split_by_lowest_precedence(tokens: Chain[Token], scope:Scope) -\u003e tuple[Chain[Token], Token, Chain[Token]]:\n    \"\"\"\n    return the integer index/indices of the lowest precedence operator(s) in the given list of tokens\n    \"\"\"\n    assert isinstance(tokens, Chain), f\"ERROR: `split_by_lowset_precedence()` may only be called on explicitly known Chain[Token], got {type(tokens)}\"\n\n    #collect all operators and their indices in the list of tokens\n    idxs, ops = zip(*[(i,token) for i,token in enumerate(tokens) if is_op(token)])\n\n    if len(ops) == 0:\n        pdb.set_trace()\n        #TODO: how to handle this case?\n        return Chain(), None, Chain()\n        raise ValueError()\n    if len(ops) == 1:\n        i, = idxs\n        op, = ops\n        return Chain(tokens[:i]), op, Chain(tokens[i+1:])\n    \n    # when more than one op present, find the lowest precedence one\n    ranks = [operator_precedence(op) for op in ops]\n    min_rank = min(ranks)\n\n    # verify that the min is strictly less than or equal to all other ranks\n    if not all(min_rank \u003c= r for r in ranks):\n        #TODO: probably enumerate out all permutations of the ambiguous operators and return all of them as a list of lists of indices\n        #make use of scope/chain typeof to disambiguate if need be\n        raise NotImplementedError(f\"TODO: ambiguous precedence for {ops=} with {ranks=}, in token stream {tokens=}\")\n\n\n    # find operators with precedence equal to the current minimum\n    op_idxs = [i for i,r in zip(idxs, ranks) if r == min_rank]\n\n    if len(op_idxs) == 1:\n        i, = op_idxs\n        return Chain(tokens[:i]), tokens[i], Chain(tokens[i+1:])\n\n    # handling when multiple ops have the same precedence, select based on associativity rules\n    if isinstance(min_rank, qint):\n        assocs = {operator_associativity(i) for i in min_rank.values}\n        if len(assocs) \u003e 1:\n            raise NotImplementedError(f'TODO: need to type check to deal with multiple/ambiguous operator associativities: {assocs}')\n        assoc, = assocs\n    else:\n        assoc = operator_associativity(min_rank)\n    \n    match assoc:\n        case Associativity.left: i = op_idxs[-1]\n        case Associativity.right: i = op_idxs[0]\n        case Associativity.prefix: i = op_idxs[0]\n        case Associativity.postfix: i = op_idxs[-1]\n        case Associativity.none: i = op_idxs[-1] #default to left. handled later in parsing\n        case Associativity.fail: raise ValueError(f'Cannot handle multiple given operators in chain {tokens}, as lowest precedence operator is marked as un-associable.')\n    \n    return Chain(tokens[:i]), tokens[i], Chain(tokens[i+1:])\n\n# @cache\ndef typeof(chain: list[Token], scope:Scope) -\u003e Type|None: #this should be the same type system`` used in the interpreter!\n    # recursively determine the type of the sequence of tokens\n    # return none if the sequence does not form a valid type\n    # follow a similar process to parsing, breaking down the expressions, etc.\n\n    pdb.set_trace()\n    chain, remainder = get_next_chain(chain)\n    assert len(remainder) == 0, 'typeof may only be called on single chains of tokens'\n\n    if len(chain) == 1:\n        token, = chain\n        return typeof_single(token, scope)\n        \n    # TODO: handle type check for more complicated chains...\n    pdb.set_trace()\n    left, op, right = split_by_lowest_precedence(chain, scope)\n    left_t, right_t = typeof(left, scope), typeof(right, scope)\n\n    pdb.set_trace()\n\n\n\ndef typeof_single(token:Token, scope:Scope) -\u003e Type|None:\n\n    pdb.set_trace()\n    ...\n\ndef to_callable(ast:AST) -\u003e str|Callable:\n    \"\"\"Convert the ast to either a string (identifier name) or Callable\"\"\"\n\n    if isinstance(ast, Identifier):\n        return ast.name\n    if isinstance(ast, Callable):\n        return ast\n    \n    # hacky way of dealing with blocks\n    if isinstance(ast, Block):\n        if len(ast.exprs) == 1:\n            return to_callable(ast.exprs[0])\n        else:\n            pdb.set_trace()\n            ...\n\n    raise ValueError(f'Tried to prepare callable expression with unrecognized type {type(ast)}')\n\n\ndef to_call_args(ast:AST) -\u003e Array:\n    if isinstance(ast, Void):\n        return Array([])\n    \n    if isinstance(ast, Tuple):\n        return Array(ast.exprs)\n\n    #TODO: some sort of check that ast is a valid single type...?\n    return Array([ast])\n    \n    \n\ndef is_callable(ast:AST, scope:Scope) -\u003e bool:\n    #TODO: make calling typeof on an AST more robust/handle this better\n\n    if isinstance(ast, Identifier):\n        #check the type of the identifier in the scope\n        if (val:=scope.get(ast.name, undefined)) is not undefined:\n            return Type.is_instance(val.type, Callable.type)\n        raise ValueError(f'Could not check is_callable. Identifier `{ast}` was undefined in scope.')\n\n    # check if directly callable\n    if isinstance(ast, Callable):\n        return True\n    \n    # Non-callable types\n    if isinstance(ast, (Number, String, IString)):\n        return False\n\n    # TODO: hacky way of dealing with blocks...\n    if isinstance(ast, Block):\n        if len(ast.exprs) == 1:\n            return is_callable(ast.exprs[0], scope)\n        else:\n            pdb.set_trace()\n            ...\n    \n    if isinstance(ast, PrototypeAST):\n        raise NotImplementedError(f\"Currently haven't handled is_callable for case of {type(ast)}\")\n        \n    \n\n    #other cases, e.g. function literals. should be able to use the AST type checking method at this point\n    pdb.set_trace()\n    ...\n\n# don't need is_multipliable, because that is just the default case.\n# also don't have to worry about the user making custom callable types not being parsed correctly,\n#    since they should inherit from Callable, making is_callable return true for them!\n\ndef parse(tokens:list[Token], scope:Scope) -\u003e AST:\n\n    asts = []\n    while len(tokens) \u003e 0:\n        chain, tokens = get_next_chain(tokens)\n\n        if len(chain) == 1:\n            asts.append(parse_single(chain[0], scope))\n        else:\n            asts.append(parse_chain(chain, scope))\n    \n    if len(asts) == 0:\n        #literally nothing was parsed\n        return void\n    \n    if len(asts) == 1:\n        ast, = asts\n        return ast\n    \n    block = Block(asts)\n    block.newscope = True\n    return block\n\n\ndef parse_single(token:Token, scope:Scope) -\u003e AST:\n    \"\"\"Parse a single token into an AST\"\"\"\n    match token:\n        case Identifier_t():    return Identifier(token.src)\n        case Integer_t():       return Number(int(token.src))\n        case Boolean_t():       return Bool(bool_to_bool(token.src))\n        case BasedNumber_t():   return Number(based_number_to_int(token.src))\n        case RawString_t():     return String(token.to_str())\n        case String_t():        return parse_string(token, scope)\n        case Block_t():         return parse_block(token, scope)\n        case Flow_t():          return parse_flow(token, scope)\n        \n        case _:\n            #TODO handle other types...\n            pdb.set_trace()\n            ...\n    \n    pdb.set_trace()\n    raise NotImplementedError()\n    ...\n\n\ndef parse_chain(chain:Chain[Token], scope:Scope) -\u003e AST:\n    assert isinstance(chain, Chain), f\"ERROR: parse chain may only be called on explicitly known Chain[Token], got {type(chain)}\"\n    \n    if len(chain) == 0: return void\n    if len(chain) == 1: return parse_single(chain[0], scope)\n    \n    left, op, right = split_by_lowest_precedence(chain, scope)\n    left, right = parse(left, scope), parse(right, scope)\n\n    assert not isinstance(left, Void) or not isinstance(right, Void), f\"Internal Error: both left and right returned Void during parse chain, implying chain was invalid: {chain}\"\n\n    # 3 cases are prefix expr, postfix expr, or binary expr\n    if isinstance(left, Void): return build_unary_prefix_expr(op, right, scope)\n    if isinstance(right, Void): return build_unary_postfix_expr(left, op, scope)\n    return build_bin_expr(left, op, right, scope)\n\n\ndef build_bin_expr(left:AST, op:Token, right:AST, scope:Scope) -\u003e AST:\n    \"\"\"create a unary prefix expression AST from the op and right AST\"\"\"\n\n    match op:\n        case Juxtapose_t():\n            if is_callable(left, scope):\n                fn = to_callable(left)\n                args = to_call_args(right)\n                return Call(fn, args)\n            else:\n                # assume left/right are multipliable\n                return Mul(left, right, None)\n\n        case Operator_t(op='='):\n            if isinstance(left, Identifier):\n                return Bind(left.name, right)\n            else:\n                #TODO: handle other cases, e.g. a.b, a[b], etc.\n                #      probably make bind take str|AST as the left-hand-side target\n                #      return Bind(left, right)\n                pdb.set_trace()\n                ...\n\n        case Operator_t(op='=\u003e'):\n            if isinstance(left, Void):\n                return Function([], right, scope) #TODO: scope needs to be set. not sure if should set here or on a post processing pass...\n            elif isinstance(left, Identifier):\n                pdb.set_trace()\n                ...\n            elif isinstance(left, Block):\n                pdb.set_trace()\n                ...\n            else:\n                raise ValueError(f'Unrecognized left-hand side for function literal: {left=}, {right=}')\n\n        # a bunch of simple cases:\n        # case ShiftOperator_t(op='\u003c\u003c'):  return LeftShift(left, right)\n        # case ShiftOperator_t(op='\u003e\u003e'):  return RightShift(left, right)\n        # case ShiftOperator_t(op='\u003c\u003c\u003c'): return LeftRotate(left, right)\n        # case ShiftOperator_t(op='\u003e\u003e\u003e'): return RightRotate(left, right)\n        # case ShiftOperator_t(op='\u003c\u003c!'): return LeftRotateCarry(left, right)\n        # case ShiftOperator_t(op='!\u003e\u003e'): return RightRotateCarry(left, right)\n        case Operator_t(op='+'): return Add(left, right, None)\n        case Operator_t(op='-'): return Sub(left, right, None)\n        case Operator_t(op='*'): return Mul(left, right, None)\n        case Operator_t(op='/'): return Div(left, right, None)\n        case Operator_t(op='%'): return Mod(left, right, None)\n        case Operator_t(op='^'): return Pow(left, right, None)\n\n        #comparison operators\n        case Operator_t(op='=?'): return Equal(left, right)\n        case Operator_t(op='\u003e?'): return Greater(left, right)\n        case Operator_t(op='\u003c?'): return Less(left, right)\n        case Operator_t(op='\u003e=?'): return GreaterEqual(left, right)\n        case Operator_t(op='\u003c=?'): return LessEqual(left, right)\n        # case Operator_t(op='in?'): return MemberIn(left, right)\n        # case Operator_t(op='is?'): return Is(left, right)\n        # case Operator_t(op='isnt?'): return Isnt(left, right)\n        # case Operator_t(op='\u003c=\u003e'): return ThreewayCompare(left, right)\n\n        # Boolean Operators\n\n        # Misc Operators\n        case Comma_t(): \n            #TODO: combine left or right tuples into a single tuple\n            if isinstance(left, Tuple) and isinstance(right, Tuple):\n                return Tuple([*left.exprs, *right.exprs])\n            elif isinstance(left, Tuple):\n                return Tuple([*left.exprs, right])\n            elif isinstance(right, Tuple):\n                return Tuple([left, *right.exprs])\n            else:\n                return Tuple([left, right])\n        \n        case Operator_t(op='else'):\n            if isinstance(left, Flow) and isinstance(right, Flow):\n                #merge left+right as single flow\n                assert left.default is None, f'cannot merge left flow with default case. Got {left=}, {right=}'\n                default = [right.default] if right.default else []\n                return Flow([*left.branches, *right.branches, *default])\n            elif isinstance(left, Flow):\n                #append right to left\n                assert left.default is None, f'cannot merge left flow with default case. Got {left=}, {right=}'\n                return Flow([*left.branches, right])\n            elif isinstance(right, Flow):\n                #prepend left to right\n                default = [right.default] if right.default else []\n                return Flow([left, *right.branches, *default])\n            else:\n                #create a new flow out of the left and right\n                return Flow([left, right])\n        \n\n        case _:\n            pdb.set_trace()\n            raise NotImplementedError(f'Parsing of operator {op} has not been implemented yet')\n\n\ndef build_unary_prefix_expr(op:Token, right:AST, scope:Scope) -\u003e AST:\n    \"\"\"create a unary prefix expression AST from the op and right AST\"\"\"\n    match op:\n        # normal prefix operators\n        case Operator_t(op='+'): return right\n        case Operator_t(op='-'): return Neg(right, None)\n        case Operator_t(op='*'): return right\n        case Operator_t(op='/'): return Inv(right, None)\n        case Operator_t(op='not'): raise NotImplementedError(f\"TODO: prefix op: {op=}\")\n        case Operator_t(op='@'):   raise NotImplementedError(f\"TODO: prefix op: {op=}\")\n        case Operator_t(op='...'): raise NotImplementedError(f\"TODO: prefix op: {op=}\")\n\n        # binary operators that appear to be unary because the left can be void\n        case Operator_t(op='=\u003e'): return Function([], right, scope) # =\u003e called as unary prefix op means left was ()/void\n\n        case _:\n            raise ValueError(f\"INTERNAL ERROR: {op=} is not a known unary prefix operator\")\n\n\ndef build_unary_postfix_expr(left:AST, op:Token, scope:Scope) -\u003e AST:\n    \"\"\"create a unary postfix expression AST from the left AST and op token\"\"\"\n    match op:\n        # normal postfix operators\n        case Operator_t(op='!'): raise NotImplementedError(f\"TODO: postfix op: {op=}\") #return Fact(left)\n\n        # binary operators that appear to be unary because the right can be void\n        case Juxtapose_t(): return Call(to_callable(left), Array([])) # anything juxtaposed with void is treated as a zero-arg call()\n\n        case _:\n            raise NotImplementedError(f\"TODO: {op=}\")\n\ndef parse_string(token:String_t, scope:Scope) -\u003e String | IString:\n    \"\"\"Convert a string token to an AST\"\"\"\n\n    if len(token.body) == 1 and isinstance(token.body[0], str):\n        return String(token.body[0])\n\n    # else handle interpolation strings\n    parts = []\n    for chunk in token.body:\n        if isinstance(chunk, str):\n            parts.append(chunk)\n        elif isinstance(chunk, Escape_t):\n            parts.append(chunk.to_str())\n        else:\n            #put any interpolation expressions in a new scope\n            ast = parse(chunk.body, scope)\n            if isinstance(ast, Block):\n                ast.newscope = True\n            else:\n                ast = Block([ast], newscope=True)\n            parts.append(ast)\n\n    # combine any adjacent Strings into a single string (e.g. if there were escapes)\n    parts = iterchain(*((''.join(g),) if issubclass(t, str) else (*g,) for t, g in groupby(parts, type)))\n    # convert any free strings to ASTs\n    parts = [p if not isinstance(p, str) else String(p) for p in parts]\n\n    return IString(parts)\n\n\ndef parse_block(block:Block_t, scope:Scope) -\u003e AST:\n    \"\"\"Convert a block token to an AST\"\"\"\n\n    # if new scope block, nest the current scope\n    newscope =  block.left == '{' and block.right == '}'\n    if newscope:\n        scope = Scope(scope)\n    \n    #parse the inside of the block\n    inner = parse(block.body, scope)\n\n    delims = block.left + block.right\n    match delims, inner:\n        #types returned as is\n        case '()'|'{}', String() | IString() | Call() | Function() | Identifier() | Number() | BinOp() | UnaryOp(): #TODO: more types\n            return Block([inner], newscope=delims=='{}')\n        case '()'|'{}', Void():\n            return inner\n        case '()'|'{}', Block():\n            inner.newscope = delims == '{}'\n            return inner\n        \n        # create class RawRange(PrototypeAST) for representing the inner part of a range without the block delimiters\n        # case '()'|'(]'|'[)'|'[]', RawRange(): ...\n\n        # array\n        # case '[]', Block() | Tuple(): return Array(inner.exprs)\n\n        case _:\n            pdb.set_trace()\n            raise NotImplementedError(f'block parse not implemented for {block.left+block.right}, {type(inner)}')\n\n\ndef parse_flow(flow:Flow_t, scope:Scope) -\u003e If|Loop:\n    cond = parse_chain(flow.condition, scope)\n    clause = parse_chain(flow.clause, scope)\n    \n    match flow.keyword:\n        case Keyword_t(src='if'): return If(cond, clause)\n        case Keyword_t(src='loop'): return Loop(cond, clause)\n        case _:\n            pdb.set_trace()\n            ...\n            raise NotImplementedError('TODO: other flow keywords, namely lazy')\n    pdb.set_trace()\n    ...\n\n\n\ndef top_level_parse(tokens:list[Token], scope:Scope=None) -\u003e AST:\n    \"\"\"\n    Parse the sequence of tokens into an AST\n\n    Args:\n        tokens (list[Token]): tokens to be parsed\n        scope (Scope, optional): The scope to use when determining the type of identified values. Defaults to Scope.default()\n    \"\"\"\n\n    #ensure there is a valid scope to do the parse with\n    if scope is None:\n        scope = Scope.default()\n    \n    # kick off the parser\n    ast = parse(tokens, scope.copy())\n\n    # post processing on the parsed AST \n    express_identifiers(ast)\n    tuples_to_arrays(ast)\n    ensure_no_prototypes(ast)\n    set_ast_scopes(ast, scope)\n\n    return ast\n    \n\n\ndef express_identifiers(root:AST) -\u003e None:\n    \"\"\"\n    Convert (in-place) any free floating Identifier AST nodes (PrototypeAST) to Call nodes\n    \"\"\"\n    for ast in full_traverse_ast(root):\n        if isinstance(ast, Identifier):\n            #in place convert Identifier to Call\n            call = Call(ast.name)\n            ast.__dict__ = call.__dict__\n            ast.__class__ = Call\n\ndef tuples_to_arrays(root:AST)  -\u003e None:\n    \"\"\"Convert (in-place) any Tuple nodes (PrototypeAST) to Array nodes\"\"\"\n    #TODO: should be able to specify that the array is const...\n    for ast in full_traverse_ast(root):\n        if isinstance(ast, Tuple):\n            #in place convert Tuple to Array\n            arr = Array(ast.exprs)\n            ast.__dict__ = arr.__dict__\n            ast.__class__ = Array\n\n#TODO: if we make a third conversion function, make a meta conversion function that takes a lambda \n# for how to make the new instance from the old one, and then does the in-place conversion\n# def in_place_type_conversion(root:AST, target:PyType[AST], converter: Function[[AST], AST]) -\u003e None\n#     for ast in full_traverse_ast(root):\n#         if isinstance(ast, target):\n#             new = converter(ast)\n#             ast.__dict__ = new.__dict__\n#             ast.__class__ = target\n\ndef ensure_no_prototypes(root:AST) -\u003e None:\n    \"\"\"\n    Raises an exception if there are any PrototypeAST nodes in the AST\n    \"\"\"\n    for ast in full_traverse_ast(root):\n        if isinstance(ast, PrototypeAST):\n            raise ValueError(f'May not have any PrototypeASTs in a final AST. Found {ast} of type ({type(ast)})')\n            \ndef set_ast_scopes(root:AST, scope:Scope) -\u003e None:\n    #TODO: hacky, just setting function scopes to root scope!\n    #      need to handle setting scope to where fn defined.\n    #      probably have traverse keep track of scope for given node!\n    for ast in full_traverse_ast(root):\n        if isinstance(ast, Function):\n            ast.scope = scope\n\ndef full_traverse_ast(root:AST) -\u003e Generator[AST, None, None]:\n    \"\"\"\n    Generator to recursively walk all nodes in the given AST.\n    \n    While traversing, the user can skip visiting the current node's children by calling `.send(True)`.\n    Children nodes are visited after the current node (preorder traversal), so you may modify the children\n      during iteration, and the iterator ought to handle it fine.\n\n    e.g.\n    ```python\n    \n    for ast in (gen := full_traverse_ast(root)):\n        #do something with current ast node\n        #...\n\n        #maybe skip any children of this node\n        if should_skip:\n            gen.send(True)\n    ```\n\n    Do not call `.send()` twice in a row without calling `next()` in between. This will cause unexpected behavior.\n\n    Args:\n        root: the ast node to start traversing from\n\n    Yields:\n        ast: the current ast node being looked at (and recursively all children nodes)\n    \"\"\"\n    \n    skip = yield root\n    if skip is not None: assert (yield) is None, \".send() may only be called once per iteration\"\n    if skip is not None: return\n    \n    match root:\n        case Block(exprs=list(exprs)) | Tuple(exprs=list(exprs)):\n            for expr in exprs:\n                yield from full_traverse_ast(expr)\n\n        case Array(vals=list(vals)):\n            for val in vals:\n                yield from full_traverse_ast(val)\n\n        case Call():\n            #handle expr being called\n            if isinstance(root.expr, AST):\n                yield from full_traverse_ast(root.expr)\n            # else str identifier, which doesn't need to be visited\n\n            #handle any arguments\n            if root.args is not None:\n                for arg in root.args.vals:\n                    yield from full_traverse_ast(arg)\n        \n        case IString(parts=list(parts)):\n            for ast in parts:\n                yield from full_traverse_ast(ast)\n\n        case Bind():\n            yield from full_traverse_ast(root.value)\n        \n        case Function():\n            for arg in root.args:\n                yield from full_traverse_ast(arg.type)\n                if arg.val is not None:\n                    yield from full_traverse_ast(arg.val)\n            yield from full_traverse_ast(root.body)\n\n        case BinOp():\n            yield from full_traverse_ast(root.left)\n            yield from full_traverse_ast(root.right)\n\n        case UnaryOp():\n            yield from full_traverse_ast(root.child)\n\n\n        case Flow():\n            for expr in root.branches:\n                yield from full_traverse_ast(expr)\n            if root.default is not None:\n                yield from full_traverse_ast(root.default)\n\n        case If():\n            yield from full_traverse_ast(root.cond)\n            yield from full_traverse_ast(root.body)\n\n        case Loop():\n            yield from full_traverse_ast(root.cond)\n            yield from full_traverse_ast(root.body)\n\n\n        # do nothing cases\n        case String(): ...\n        case Identifier(): ...\n        case Number(): ...\n        case Bool(): ...\n        case Void(): ...\n        \n        case _:\n            #TODO: unhandled ast type\n            pdb.set_trace()\n            raise NotImplementedError(f'traversal not implemented for ast type {type(root)}')\n\n\n\n\n\n\ndef test_file(path:str):\n    \"\"\"Run a given file\"\"\"\n\n    with open(path) as f:\n        src = f.read()\n    \n    tokens = tokenize(src)\n    post_process(tokens)\n\n    root = Scope.default()\n    ast = top_level_parse(tokens, root)\n    res = ast.eval(root)\n    if res: print(res)\n\n\n\n\n#TODO: broken. probably set up scope with some default values\ndef test_many_lines():\n    \"\"\"\n    Parse each line of syntax3.dewy one at a time for testing\n    \"\"\"\n    #load the syntax3 file and split the lines\n    with open('../../examples/syntax3.dewyl') as f:\n        lines = f.read().splitlines()\n\n\n    #set up a scope with declarations for all of the variables used in the example file    \n    root = Scope.default()\n    root.let('x', Number.type)\n    root.let('y', Number.type)\n    root.let('z', Number.type)\n\n    for line in lines:\n        tokens = tokenize(line)\n        post_process(tokens)\n\n        # skip empty lines\n        if len(tokens) == 0:\n            continue\n\n        #print the line, and run it\n        print('-'*80)\n        print(tokens)\n\n        ast = top_level_parse(tokens)\n        print(ast)\n\n        #TODO: maybe later we can run the file. potentially declare all the values used at the top?\n        # res = ast.eval(root)\n        # if res: print(res)\n\n\ndef test_hello():\n    # line = \"'Hello, World!'\"\n    line = r\"\"\"\nprint'What is your name? '\nname = readl\nprintl'Hello {name}'\na = 4(5)\nb = -5\nc = /4\nd = 1,2,3,4,5\nprintl'a={a}, b={b}, c={c} d={d}'\n\"\"\"\n\n    tokens = tokenize(line)\n    post_process(tokens)\n\n    #DEBUG\n    # tokens = [Identifier_t('printl'), Juxtapose_t(''), Identifier_t('readl')]\n\n    ast = top_level_parse(tokens)\n    root = Scope.default()\n    ast.eval(root)\n\n\ndef test_example_progs():\n    from dewy import hello, hello_func, anonymous_func, hello_name, if_else, if_else_if, hello_loop, unpack_test, range_iter_test, loop_iter_manual, loop_in_iter, nested_loop, block_printing\n\n    funcs = [hello, hello_func, anonymous_func, hello_name, if_else, if_else_if, hello_loop, unpack_test, range_iter_test, loop_iter_manual, loop_in_iter, nested_loop, block_printing]\n\n    for func in funcs:\n        src = func.__doc__\n        print(f'Parsing source:\\n{src}\\n')\n        tokens = tokenize(src)\n        post_process(tokens)\n\n        ast = top_level_parse(tokens)\n        root = Scope.default()\n        ast.eval(root)\n\n\nif __name__ == \"__main__\":\n    import sys\n    if len(sys.argv) \u003e 1:\n        test_file(sys.argv[1])\n    else:\n        # test_hello()\n        # test_example_progs()\n        test_many_lines()\n\n    # print(\"Usage: `python parser.py [path/to/file.dewy\u003e]`\")\n\n\n\n\n\n\n"])</script><script>self.__next_f.push([1,"20:T36e3,"])</script><script>self.__next_f.push([1,"from tokenizer import ( tokenize, tprint, full_traverse_tokens,\n    unary_prefix_operators,\n    unary_postfix_operators,\n    binary_operators,\n    opchain_starters,\n\n    Token,\n\n    WhiteSpace_t,\n\n    Escape_t,\n\n    Identifier_t,\n    Block_t,\n    TypeParam_t,\n    RawString_t,\n    String_t,\n    Integer_t,\n    Boolean_t,\n    BasedNumber_t,\n    Hashtag_t,\n    DotDot_t,\n\n    Keyword_t,\n\n    Juxtapose_t,\n    Operator_t,\n    ShiftOperator_t,\n    Comma_t,\n)\n\nfrom enum import Enum, auto\n\n\nimport pdb\n\n\n\"\"\"\nTODO:\n- full pipeline for hello world:\n  [x] tokenize\n  [ ] chain (still no typing, just group single expressions together). Actually probably just leave as list[Token], and generate chains again at parse time!\n  [ ] parse (building up types based on expressions and types of lowest levels/outside in)\n\"\"\"\n\n\n# There is no chain class\n# A chain is just a list of tokens that is directly parsable as an expression without any other syntax\n# all other syntax is wrapped up into compound tokens\n# it should literally just be a sequence of atoms and operators\n    \n\n#TODO: replace with 3.12 syntax when released: class Chain[T](list[T]): ...\nfrom typing import TypeVar\nT = TypeVar('T')\nclass Chain(list[T]):\n    \"\"\"class for explicitly annotating that a token list is a single chain\"\"\"\n\n\n# Later Token classes\n\nclass Flow_t(Token):\n    def __init__(self, keyword:Keyword_t, condition:Chain[Token], clause:Chain[Token]):\n        self.keyword = keyword\n        self.condition = condition\n        self.clause = clause\n    def __repr__(self) -\u003e str:\n        return f\"\u003cFlow_t: {self.keyword}: {self.condition} {self.clause}\"\n\nclass Do_t(Token):...\nclass Return_t(Token):...\nclass Express_t(Token):...\nclass Declare_t(Token):...\n\n\natom_tokens = (\n    Identifier_t,\n    Integer_t,\n    Boolean_t,\n    BasedNumber_t,\n    RawString_t,\n    String_t,\n    Block_t,\n    TypeParam_t,\n    Hashtag_t,\n    DotDot_t,\n    Flow_t,\n)\n\n\n\n\n\ndef invert_whitespace(tokens: list[Token]) -\u003e None:\n    \"\"\"\n    removes all whitespace tokens, and insert juxtapose tokens between adjacent pairs (i.e. not separated by whitespace)\n\n    Args:\n        tokens (list[Token]): list of tokens to modify. This is modified in place.\n    \"\"\"\n    \n    #juxtapose singleton token so we aren't wasting memory\n    jux = Juxtapose_t(None)\n    \n    i = 0\n    while i \u003c len(tokens):\n        # delete whitespace if it comes up\n        if isinstance(tokens[i], WhiteSpace_t):\n            tokens.pop(i)\n            continue\n\n        # recursively handle inverting whitespace for blocks\n        if isinstance(tokens[i], (Block_t, TypeParam_t)):\n            invert_whitespace(tokens[i].body)\n        elif isinstance(tokens[i], String_t):\n            for child in tokens[i].body:\n                if isinstance(child, Block_t):\n                    invert_whitespace(child.body)\n\n        # insert juxtapose if no whitespace between tokens\n        if i + 1 \u003c len(tokens) and not isinstance(tokens[i + 1], WhiteSpace_t):\n            tokens.insert(i + 1, jux)\n            i += 1\n        i += 1\n\n    #finally, remove juxtapose tokens next to operators that are not whitespace sensitive\n    i = 1\n    while i \u003c len(tokens) - 1:\n        left,middle,right = tokens[i-1:i+2]\n        if isinstance(middle, Juxtapose_t) and (isinstance(left, (Operator_t, ShiftOperator_t, Comma_t)) or isinstance(right, (Operator_t, ShiftOperator_t, Comma_t))):\n            tokens.pop(i)\n            continue\n        i += 1\n\n\n\n\ndef _get_next_prefixes(tokens:list[Token]) -\u003e tuple[list[Token], list[Token]]:\n    prefixes = []\n    while len(tokens) \u003e 0 and is_unary_prefix_op(tokens[0]): #isinstance(tokens[0], Operator_t) and tokens[0].op in unary_prefix_operators:\n        prefixes.append(tokens.pop(0))\n    return prefixes, tokens\ndef _get_next_postfixes(tokens:list[Token]) -\u003e tuple[list[Token], list[Token]]:\n    postfixes = []\n    while len(tokens) \u003e 0 and is_unary_postfix_op(tokens[0], exclude_semicolon=True):#isinstance(tokens[0], Operator_t) and tokens[0].op in unary_postfix_operators - {';'}:\n        postfixes.append(tokens.pop(0))\n    return postfixes, tokens\ndef _get_next_atom(tokens:list[Token]) -\u003e tuple[Token, list[Token]]:\n    if len(tokens) == 0:\n        raise ValueError(f\"ERROR: expected atom, got {tokens=}\")\n\n    #TODO: this is going to be unnecessary as expressions will have been bundled up into single tokens\n    if isinstance(tokens[0], Keyword_t):\n        return _get_next_keyword_expr(tokens)\n\n    if isinstance(tokens[0], atom_tokens):#(Integer_t, BasedNumber_t, String_t, RawString_t, Identifier_t, Hashtag_t, Block_t, TypeParam_t, DotDot_t)):\n        return tokens[0], tokens[1:]\n\n    raise ValueError(f\"ERROR: expected atom, got {tokens[0]=}\")\n\ndef _get_next_chunk(tokens:list[Token]) -\u003e tuple[list[Token], list[Token]]:\n    chunk = []\n    t, tokens = _get_next_prefixes(tokens)\n    chunk.extend(t)\n\n    t, tokens = _get_next_atom(tokens)\n    if t is None:\n        raise ValueError(f\"ERROR: expected atom, got {tokens[0]=}\")\n    chunk.append(t)\n\n    t, tokens = _get_next_postfixes(tokens)\n    chunk.extend(t)\n\n    return chunk, tokens\n\ndef is_unary_prefix_op(token:Token) -\u003e bool:\n    \"\"\"\n    Determines if a token could be a unary prefix operator.\n    Note that this is not mutually exclusive with being a postfix operator or a binary operator.\n    \"\"\"\n    return isinstance(token, Operator_t) and token.op in unary_prefix_operators\n\ndef is_unary_postfix_op(token:Token, exclude_semicolon:bool=False) -\u003e bool:\n    \"\"\"\n    Determines if a token could be a unary postfix operator. \n    Optionally can exclude semicolon from the set of operators.\n    Note that this is not mutually exclusive with being a prefix operator or a binary operator.\n    \"\"\"\n    if exclude_semicolon:\n        return isinstance(token, Operator_t) and token.op in unary_postfix_operators - {';'}\n    return isinstance(token, Operator_t) and token.op in unary_postfix_operators\n\ndef is_binop(token:Token) -\u003e bool:\n    \"\"\"\n    Determines if a token could be a binary operator.\n    Note that this is not mutually exclusive with being a prefix operator or a postfix operator.\n    \"\"\"\n    return isinstance(token, Operator_t) and token.op in binary_operators or isinstance(token, (ShiftOperator_t, Comma_t, Juxtapose_t))\n\ndef is_op(token:Token) -\u003e bool:\n    return is_binop(token) or is_unary_prefix_op(token) or is_unary_postfix_op(token)\n\ndef is_opchain_starter(token:Token) -\u003e bool:\n    return isinstance(token, Operator_t) and token.op in opchain_starters\n\ndef _get_next_keyword_expr(tokens:list[Token]) -\u003e tuple[Token, list[Token]]:\n    \"\"\"package up the next keyword expression into a single token\"\"\"\n    if len(tokens) == 0:\n        raise ValueError(f\"ERROR: expected keyword expression, got {tokens=}\")\n    t, tokens = tokens[0], tokens[1:]\n\n    if not isinstance(t, Keyword_t):\n        raise ValueError(f\"ERROR: expected keyword expression, got {t=}\")\n\n    match t:\n        case Keyword_t(src='if'|'loop'|'lazy'):\n            cond, tokens = get_next_chain(tokens, binop_blacklist={Operator_t('else')})\n            clause, tokens = get_next_chain(tokens, binop_blacklist={Operator_t('else')})\n            return Flow_t(t, cond, clause), tokens\n        case Keyword_t(src='do'):\n            clause, tokens = get_next_chain(tokens)\n            #assert next token is a do_keyward\n            #depending on the keyward, get a condition, or condition+clause\n            pdb.set_trace()\n            ...\n        case Keyword_t(src='return'):\n            #TBD how to do this one...\n            pdb.set_trace()\n            ...\n        case Keyword_t(src='express'):\n            pdb.set_trace()\n            ...\n        case Keyword_t(src='let'|'const'):\n            expr, tokens = get_next_chain(tokens)\n            pdb.set_trace()\n            ...\n    \n    raise NotImplementedError(\"TODO: handle keyword based expressions\")\n    # (if | loop) #chain #chain (else (if | loop) #chain #chain)* (else #chain)?\n    # return #chain?\n    # express #chain\n    # (break | continue) #hashtag? //note the hashtag should be an entire chain if present\n    # (let | const) #chain\n\n\ndef get_next_chain(tokens:list[Token], binop_blacklist:set[Token]=None) -\u003e tuple[Chain[Token], list[Token]]:\n    \"\"\"\n    grab the next single expression chain of tokens from the given list of tokens\n\n    Also wraps up keyword-based expressions (if loop etc.) into a single token\n\n    A chain is represented by the following grammar:\n        #chunk = #prefix_op* #atom_expr (#postfix_op - ';')*\n        #chain = #chunk (#binary_op #chunk)* ';'?\n\n    Args:\n        tokens (list[Token]): list of tokens to grab the next chain from\n\n    Returns:\n        next, rest (list[Token], list[Token]): the next chain of tokens, and the remaining tokens\n    \"\"\"\n    if binop_blacklist is None: binop_blacklist = set()\n\n    chain = []\n\n    chunk, tokens = _get_next_chunk(tokens)\n    chain.extend(chunk)\n\n    while len(tokens) \u003e 0 and is_binop(tokens[0]) and tokens[0] not in binop_blacklist:\n        chain.append(tokens.pop(0))\n        chunk, tokens = _get_next_chunk(tokens)\n        chain.extend(chunk)\n\n    if len(tokens) \u003e 0 and isinstance(tokens[0], Operator_t) and tokens[0].op == ';':\n        chain.append(tokens.pop(0))\n\n    return Chain(chain), tokens\n\n\n\n\n# def combine_keywords(tokens: list[Token]) -\u003e None:\n#     \"\"\"\n#     combine known keyword pairs into a single keyword\n\n#     TBD on some of these\n#     do loop -\u003e do_loop\n#     do lazy -\u003e do_lazy\n#     else if -\u003e else_if\n#     else loop -\u003e else_loop\n#     else lazy -\u003e else_lazy\n#     \"\"\"\n\n#     for i, token, stream in (gen := full_traverse_tokens(tokens)):\n#         if isinstance(token, Keyword_t):\n#             raise NotImplementedError\n\ndef desugar_ranges(tokens: list[Token]) -\u003e None:\n    \"\"\"fill in empty expressions on the left/right of any range `..` that lacks left or right operands\"\"\"\n    #TODO: also maybe put range in a group with []\n    for i, token, stream in (gen := full_traverse_tokens(tokens)):\n        if isinstance(token, DotDot_t):\n            raise NotImplementedError\n\n\n\ndef bundle_conditionals(tokens: list[Token]) -\u003e None:\n    \"\"\"Convert sequences of tokens that represent conditionals (if, loop, etc.) into a single expression token\"\"\"\n    \n    #TODO: should scan through, and if it finds a conditional, raise the not implemented error\n    #TODO: need to check that nested conditionals as well as chained conditionals are handled properly\n    #      e.g. `if a b`, `if a b else if c d else f`, `if a if b c else d`\n    \n    for i, token, stream in (gen := full_traverse_tokens(tokens)):\n        if isinstance(token, Keyword_t):\n            #TODO: handle bundling up the keyword into an expression\n            raise NotImplementedError\n\n\ndef chain_operators(tokens: list[Token]) -\u003e None:\n    \"\"\"Convert consecutive operator tokens into a single opchain token\"\"\"\n    \"\"\"\n    A chain is represented by the following grammar:\n        #chunk = #prefix_op* #atom_expr (#postfix_op - ';')*\n        #chain = #chunk (#binary_op #chunk)* ';'?\n\n        #prefix_op = '+' | '-' | '*' | '/' | 'not' | '@' | '...'\n        #postfix_op = '?' | '`' | ';'\n        #binary_op = '+' | '-' | '*' | '/' | '%' | '^'\n          | '=?' | '\u003e?' | '\u003c?' | '\u003e=?' | '\u003c=?' | 'in?' | 'is?' | 'isnt?' | '\u003c=\u003e'\n          | '|' | '\u0026'\n          | 'and' | 'or' | 'nand' | 'nor' | 'xor' | 'xnor' | '??'\n          | '=' | ':=' | 'as' | 'in' | 'transmute'\n          | '@?'\n          | '|\u003e' | '\u003c|' | '=\u003e'\n          | '-\u003e' | '\u003c-\u003e' | '\u003c-'\n          | '.' | ':'\n    \"\"\"\n\n    # TODO: skip for now. not needed by hello world\n    # also may not be necessary if we use a pratt parser. was necessary for split by lowest precedence parser\n\n    for i, token, stream in (gen := full_traverse_tokens(tokens)):\n\n        #TODO: this is not a correct way to detect these. need to verify that the operators are in between two #chunks\n        #   this will be conservative, but for now it will let us do a hello world happy path\n        if is_opchain_starter(token):\n            j = 1\n            while i+j \u003c len(stream) and is_unary_prefix_op(stream[i+j]):\n                j+=1\n            if j \u003e 1:\n                pdb.set_trace()\n                raise NotImplementedError('opchaining has not been implemented yet')\n\n\ndef post_process(tokens: list[Token]) -\u003e None:\n    \"\"\"post process the tokens to make them ready for parsing\"\"\"\n\n    # remove whitespace, and insert juxtapose tokens\n    invert_whitespace(tokens)\n\n    if len(tokens) == 0: return\n\n    # combine known keyword pairs into a single keyword\n    # combine_keywords(tokens) # possibly handled by bundling conditionals...\n\n    # bundle up conditionals into single token expressions\n    #TODO: can put this in after get_next_chain can bundle as it goes. Basically this would just make any work it does finding flow permenant\n    # bundle_conditionals(tokens)\n\n    # combine operator chains into a single operator token\n    chain_operators(tokens)\n\n    # desugar ranges\n    desugar_ranges(tokens)\n\n\n    # make the actual list of chains\n\n    # based on types, replace jux with jux_mul or jux_call\n    # TODO: actually this probably would need to be done during parsing, since we can't get a type for a complex/compound expression...\n\n    # print(tokens)\n\n\n\ndef test():\n    with open('../../../examples/hello.dewy') as f:\n        src = f.read()\n\n    tokens = tokenize(src)\n\n    #chainer process\n    post_process(tokens)\n\n    pdb.set_trace()\n    ...\n    \n\ndef test2():\n    \"\"\"gauntlet of multiple tests from example file\"\"\"\n    with open('../../../examples/syntax3.dewyl') as f:\n        lines = f.readlines()\n\n    # filter out empty lines\n    lines = [l for line in lines if (l := line.strip())]\n\n    for line in lines:\n        tokens = tokenize(line)\n\n        #chainer process\n        post_process(tokens)\n\n        #other stuff? pass to the parser? etc.\n\n    pdb.set_trace()\n    ...\n\n\ndef test_hello():\n    line = \"printl'Hello, World!'\"\n\n    tokens = tokenize(line)\n    post_process(tokens)\n\n    pdb.set_trace()\n    ...\n\n\nif __name__ == '__main__':\n    # test()\n    # test2()\n    test_hello()"])</script><script>self.__next_f.push([1,"21:T8f9f,"])</script><script>self.__next_f.push([1,"from abc import ABC\nimport inspect\nfrom typing import Callable, Type, Generator\nfrom types import UnionType\nfrom functools import lru_cache\nfrom utils import CoordString\n\nimport pdb\n\n#### DEBUG rich traceback printing ####\ntry:\n    from rich import traceback, print\n    traceback.install(show_locals=True)\nexcept:\n    print('rich unavailable for import. using built-in printing')\n\n\n\n\"\"\"\n[tasks]\n- clean up eat_block\n    - general cleanup\n    - break out eat_ matching into smaller functions?\n    - figure out tie breaking process:\n        1. prefer @full_eat over @peek_eat ---\u003e TODO: implement\n        2. prefer longest matches\n        3. prefer higher precedence\n        4. error\n- make all tokens keep the source they come from (for error reporting/keeping track of row/col of the token)\n\"\"\"\n\n\n\n\nclass Token(ABC):\n    def __repr__(self) -\u003e str:\n        \"\"\"default repr for tokens is just the class name\"\"\"\n        return f\"\u003c{self.__class__.__name__}\u003e\"\n    def __hash__(self) -\u003e int:\n        raise NotImplementedError(f'hash is not implemented for token type {type(self)}')\n    def __eq__(self, __value: object) -\u003e bool:\n        raise NotImplementedError(f'equals is not implemented for token type {type(self)}')\n\nclass WhiteSpace_t(Token):\n    def __init__(self, _): ...\n\nclass Juxtapose_t(Token):\n    def __init__(self, _): ...\n    def __hash__(self) -\u003e int:\n        return hash(Juxtapose_t)\n    def __eq__(self, other) -\u003e bool:\n        return isinstance(other, Juxtapose_t)\n\nclass Keyword_t(Token):\n    def __init__(self, src:str):\n        self.src = src.lower()\n    def __repr__(self) -\u003e str:\n        return f\"\u003cKeyword_t: {self.src}\u003e\"\n\nclass Identifier_t(Token):\n    def __init__(self, src:str):\n        self.src = src\n    def __repr__(self) -\u003e str:\n        return f\"\u003cIdentifier_t: {self.src}\u003e\"\n    \nclass Hashtag_t(Token):\n    def __init__(self, src:str):\n        self.src = src\n    def __repr__(self) -\u003e str:\n        return f\"\u003cHashtag_t: {self.src}\u003e\"\n\nclass Block_t(Token):\n    def __init__(self, body:list[Token], left:str, right:str):\n        self.body = body\n        self.left = left\n        self.right = right\n    def __repr__(self) -\u003e str:\n        body_str = ', '.join(repr(token) for token in self.body)\n        return f\"\u003cBlock_t: {self.left}{body_str}{self.right}\u003e\"\n    \nclass TypeParam_t(Token):\n    def __init__(self, body:list[Token]):\n        self.body = body\n    def __repr__(self) -\u003e str:\n        body_str = ', '.join(repr(token) for token in self.body)\n        return f\"\u003cTypeParam_t: `\u003c{body_str}\u003e`\u003e\"\n\nclass Escape_t(Token):\n    escape_map = {\n        '\\\\n': '\\n', '\\\\r': '\\r', '\\\\t': '\\t', '\\\\b': '\\b', '\\\\f': '\\f', '\\\\v': '\\v', '\\\\a': '\\a', '\\\\0': '\\0', '\\\\\\\\': '\\\\'\n    }\n    def __init__(self, src:str):\n        self.src = src\n    def __repr__(self) -\u003e str:\n        return f\"\u003cEscape_t: {self.src}\u003e\"\n    def to_str(self) -\u003e str:\n        \"\"\"Convert the escape sequence to the character it represents\"\"\"\n\n        #unicode escape (may be several characters long)\n        if self.src.startswith('\\\\U') or self.src.startswith('\\\\u'):\n            return chr(int(self.src[2:], 16))\n        assert len(self.src) == 2 and self.src[0] == '\\\\', \"internal error. Ill-posed escape sequence\"\n\n        #known escape sequence\n        if self.src in self.escape_map:\n            esc = self.escape_map[self.src]\n            #construct a CoordString at the position of the original escape\n            return CoordString.from_existing(esc, self.src[:len(esc)].row_col_map)\n\n        #unknown escape sequence (i.e. just replicate the character)\n        return self.src[1]\n\n\n\nclass RawString_t(Token):\n    def __init__(self, body:str):\n        self.body = body\n    def __repr__(self) -\u003e str:\n        return f\"\u003cRawString_t: {self.body}\u003e\"\n    def to_str(self) -\u003e str:\n        body = self.body\n        if body.startswith('r\"\"\"') or body.startswith(\"r'''\"):\n            body = body[4:-3]\n        elif body.startswith('r\"') or body.startswith(\"r'\"):\n            body = body[2:-1]\n        else:\n            raise ValueError(f\"Internal Error: unrecognized delimiters on raw string: {repr(self)}\")\n        return body\n\nclass String_t(Token):\n    def __init__(self, body:list[str|Escape_t|Block_t]):\n        self.body = body\n    def __repr__(self) -\u003e str:\n        return f\"\u003cString_t: {self.body}\u003e\"\n    \n# class Number_t(Token, ABC):...\n    \nclass Integer_t(Token):\n    def __init__(self, src:str):\n        self.src = src\n    def __repr__(self) -\u003e str:\n        return f\"\u003cInteger_t: {self.src}\u003e\"\n    \nclass BasedNumber_t(Token):\n    def __init__(self, src:str):\n        self.src = src\n    def __repr__(self) -\u003e str:\n        return f\"\u003cBasedNumber_t: {self.src}\u003e\"\n\nclass Boolean_t(Token):\n    def __init__(self, src:str):\n        self.src = src\n    def __repr__(self) -\u003e str:\n        return f\"\u003cBoolean_t: {self.src}\u003e\"\n\nclass Operator_t(Token):\n    def __init__(self, op:str):\n        self.op = op\n    def __repr__(self) -\u003e str:\n        return f\"\u003cOperator_t: `{self.op}`\u003e\"\n    def __hash__(self) -\u003e int:\n        return hash((Operator_t, self.op))\n    def __eq__(self, other) -\u003e bool:\n        return isinstance(other, Operator_t) and self.op == other.op\n    \nclass ShiftOperator_t(Token):\n    def __init__(self, op:str):\n        self.op = op\n    def __repr__(self) -\u003e str:\n        return f\"\u003cShiftOperator_t: `{self.op}`\u003e\"\n    def __hash__(self) -\u003e int:\n        return hash((ShiftOperator_t, self.op))\n    def __eq__(self, other) -\u003e bool:\n        return isinstance(other, ShiftOperator_t) and self.op == other.op\n    \n\nclass Comma_t(Token):\n    def __init__(self, src:str):\n        self.src = src\n    def __hash__(self) -\u003e int:\n        return hash(Comma_t)\n    def __eq__(self, other) -\u003e bool:\n        return isinstance(other, Comma_t)\n\nclass DotDot_t(Token):\n    def __init__(self, src:str):\n        self.src = src\n\n\n# #TODO: these should probably each be their own class/token, or a single class..\n# these should all be case insensitive\n# reserved_values = ['true', 'false', 'void', 'undefined', 'end'] \n\n\n    \n\n\n# identify token classes that should take precedence over others when tokenizing\n# each row is a list of token types that are confusable in their precedence order. e.g. [Keyword, Unit, Identifier] means Keyword \u003e Unit \u003e Identifier\n# only confusable token classes need to be included in the table\nprecedence_table = [\n    [Keyword_t, Boolean_t, Operator_t, DotDot_t, Identifier_t],\n]\nprecedence = {cls: len(row)-i for row in precedence_table for i, cls in enumerate(row)}\n\n# mark which tokens cannot be repeated in a list of tokens. E.g. whitespace should always be merged into a single token\nidempotent_tokens = {\n    WhiteSpace_t\n}\n\n# paired delimiters for blocks, ranges, groups, etc.\npair_opening_delims = '{(['\npair_closing_delims = '})]'\n\n# which closing delimiters are allowed for each opening delimiter\nvalid_delim_closers = {\n    '{': '}',\n    '(': ')]',\n    '[': '])',\n    # '\u003c': '\u003e'\n}\n\n#list of all operators sorted from longest to shortest\nunary_prefix_operators = {'+', '-', '*', '/', 'not', '@', '...'}\nunary_postfix_operators = {'?', '`', ';'}\nbinary_operators = {\n        '+', '-', '*', '/', '%', '^',\n        '=?', '\u003e?', '\u003c?', '\u003e=?', '\u003c=?', 'in?', 'is?', 'isnt?', '\u003c=\u003e',\n        '|', '\u0026',\n        'and', 'or', 'nand', 'nor', 'xor', 'xnor', '??',\n        'else',\n        '=', ':=', 'as', 'in', 'transmute',\n        '@?',\n        '|\u003e', '\u003c|', '=\u003e',\n        '-\u003e', '\u003c-\u003e', '\u003c-',\n        '.', ':'\n}\nopchain_starters = {'+', '-', '*', '/', '%', '^'}\noperators = sorted(\n    [*(unary_prefix_operators | unary_postfix_operators | binary_operators)],\n    key=len,\n    reverse=True\n)\n#TODO: may need to separate |\u003e from regular operators since it may confuse type param\nshift_operators = sorted(['\u003c\u003c', '\u003e\u003e', '\u003c\u003c\u003c', '\u003e\u003e\u003e', '\u003c\u003c!', '!\u003e\u003e'], key=len, reverse=True)\nkeywords = ['loop', 'lazy', 'do', 'if', 'return', 'express', 'let', 'const']\n#TODO: what about language values, e.g. void, undefined, end, units, etc.? probably define at compile time, rather than in the compiler\n\n# note that the prefix is case insensitive, so call .lower() when matching the prefix\n# numbers may have _ as a separator (if _ is not in the set of digits)\nnumber_bases = {\n    '0b': {*'01'},                      #binary\n    '0t': {*'012'},                     #ternary\n    '0q': {*'0123'},                    #quaternary\n    '0s': {*'012345'},                  #seximal\n    '0o': {*'01234567'},                #octal\n    '0d': {*'0123456789'},              #decimal\n    '0z': {*'0123456789xeXE'},          #dozenal\n    '0x': {*'0123456789abcdefABCDEF'},  #hexadecimal \n    '0u': {*'0123456789abcdefghijklmnopqrstuvABCDEFGHIJKLMNOPQRSTUV'},              #base 32 (duotrigesimal)\n    '0r': {*'0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'},      #base 36 (hexatrigesimal)\n    '0y': {*'0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!$'},    #base 64 (tetrasexagesimal)\n}\n\n\n# units = #actually units should probably not be specific tokens, but recognized identifiers since the user can make their own units\n\n\n\ndef peek_eat(cls:Type[Token], whitelist:list[Type[Token]]|None=None, blacklist:list[Type[Token]]|None=None):\n    \"\"\"\n    Decorator for functions that eat tokens, but only return how many characters would make up the token. \n    Makes function return include constructor for token class that it tries to eat, in tupled with return.\n\n    whitelist and blacklist can be used to specify parent token contexts that may or may not consume this type as a child\n    \"\"\"\n    assert issubclass(cls, Token), f\"cls must be a subclass of Token, but got {cls}\"\n    if whitelist is not None and blacklist is not None:\n        raise ValueError(\"cannot specify both whitelist and blacklist\")\n    def decorator(eat_func:Callable[[str], int|None]):\n        def wrapper(src:str) -\u003e tuple[int|None, Type[Token]]:\n            return eat_func(src), cls\n        wrapper._is_peek_eat_decorator = True  # make it easy to check if a function has this decorator\n        wrapper._eat_func = eat_func\n        wrapper._token_cls = cls\n        wrapper._whitelist = whitelist\n        wrapper._blacklist = blacklist\n        return wrapper\n    return decorator\n\n#TODO: full eat probably won't need to take the class as an argument, since the function will know how to construct the token itself\ndef full_eat(whitelist:list[Type[Token]]|None=None, blacklist:list[Type[Token]]|None=None):\n    def decorator(eat_func:Callable[[str], tuple[int, Token] | None]):\n        \"\"\"\n        Decorator for functions that eat tokens, and return the token itself if successful.\n        TBD what this actually does...for now, largely keep unmodified, but attach the metadata to the wrapped function\n        \"\"\"\n        # pull cls it from the return type of eat_func (which should be a Union[tuple[int, Token], None])\n        cls = inspect.signature(eat_func).return_annotation.__args__[0].__args__[1]\n        assert issubclass(cls, Token), f\"cls must be a subclass of Token, but got {cls}\"\n        if whitelist is not None and blacklist is not None:\n            raise ValueError(\"cannot specify both whitelist and blacklist\")\n        def wrapper(*args, **kwargs):\n            return eat_func(*args, **kwargs), cls\n        wrapper._is_full_eat_decorator = True  # make it easy to check if a function has this decorator\n        wrapper._eat_func = eat_func\n        wrapper._token_cls = cls\n        wrapper._whitelist = whitelist\n        wrapper._blacklist = blacklist\n\n        return wrapper\n    return decorator\n\n\ndef get_peek_eat_funcs_with_name() -\u003e tuple[tuple[str, Callable]]:\n    return tuple((name, func) for name, func in globals().items() if callable(func) and getattr(func, '_is_peek_eat_decorator', False))\ndef get_full_eat_funcs_with_name() -\u003e tuple[tuple[str, Callable]]:\n    return tuple((name, func) for name, func in globals().items() if callable(func) and getattr(func, '_is_full_eat_decorator', False))\n\ndef get_eat_funcs() -\u003e tuple[Callable]:\n    return tuple(func for name, func in get_peek_eat_funcs_with_name() + get_full_eat_funcs_with_name())\n\n@lru_cache()\ndef get_contextual_eat_funcs(context:Type[Token]) -\u003e tuple[Callable]:\n    \"\"\"Get all the eat functions that are valid in the given context\"\"\"\n    return tuple(func for func in get_eat_funcs() if (func._whitelist is None or context in func._whitelist) and (func._blacklist is None or context not in func._blacklist))\n\n@lru_cache()\ndef get_func_precedences(funcs:tuple[Callable]) -\u003e tuple[int]:\n    assert isinstance(funcs, tuple)\n    return tuple(precedence.get(func._token_cls, 0) for func in funcs)\n\n\n@peek_eat(WhiteSpace_t)\ndef eat_line_comment(src:str) -\u003e int|None:\n    \"\"\"eat a line comment, return the number of characters eaten\"\"\"\n    if src.startswith('//'):\n        try:\n            return src.index('\\n') + 1\n        except ValueError:\n            return len(src)\n    return None\n\n@peek_eat(WhiteSpace_t)\ndef eat_block_comment(src:str) -\u003e int|None:\n    \"\"\"\n    Eat a block comment, return the number of characters eaten\n    Block comments are of the form /{ ... }/ and can be nested.\n    \"\"\"\n    if not src.startswith(\"/{\"):\n        return None\n\n    nesting_level = 0\n    i = 0\n\n    while i \u003c len(src):\n        if src[i:].startswith('/{'):\n            nesting_level += 1\n            i += 2\n        elif src[i:].startswith('}/'):\n            nesting_level -= 1\n            i += 2\n\n            if nesting_level == 0:\n                return i\n        else:\n            i += 1\n\n    raise ValueError(\"unterminated block comment\")\n    # return None\n\n@peek_eat(WhiteSpace_t)\ndef eat_whitespace(src:str) -\u003e int|None:\n    \"\"\"Eat whitespace, return the number of characters eaten\"\"\"\n    i = 0\n    while i \u003c len(src) and src[i].isspace():\n        i += 1\n    return i if i \u003e 0 else None\n\n@peek_eat(Keyword_t)\ndef eat_keyword(src: str) -\u003e int | None:\n    \"\"\"\n    Eat a reserved keyword, return the number of characters eaten\n\n    #keyword = {in} | {as} | {loop} | {lazy} | {if} | {and} | {or} | {xor} | {nand} | {nor} | {xnor} | {not};# | {true} | {false}; \n    \n    noting that keywords are case insensitive\n    \"\"\"\n\n    max_len = max(len(keyword) for keyword in keywords)\n    \n    lower_src = src[:max_len].lower()\n    for keyword in keywords:\n        if lower_src.startswith(keyword):\n            #TBD if we need to check that the next character is not an identifier character\n            return len(keyword)\n\n    return None\n\n\n\n#TODO: expand the list of valid identifier characters\ndigits = set('0123456789')\nalpha = set('ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz')\ngreek = set('ΑΒΓΔΕΖΗΘΙΚΛΜΝΞΟΠΡΣΤΥΦΧΨΩαβγδεζηθικλμνξοπρςστυφχψω')\nmisc = set('_?!$\u0026°')\n\nstart_characters = (alpha | greek | misc) - {'?'}\ncontinue_characters = (alpha | digits | greek | misc)\n\n\n@peek_eat(Identifier_t)\ndef eat_identifier(src:str) -\u003e int|None:\n    \"\"\"\n    Eat an identifier, return the number of characters eaten\n\n    Identifiers:\n    - may not start with a number or a question mark\n    - may not end with a question mark\n    - may use (TODO enumerate the full chars list somewhere. for now copying from python)\n    \n    \"\"\"\n    if not src[0] in start_characters:\n        return None\n\n    i = 1\n    while i \u003c len(src) and src[i] in continue_characters:\n        i += 1\n\n    # while last character is ?, remove it\n    while i \u003e 1 and src[i-1] == '?':\n        i -= 1\n\n    return i\n\n\n\n@peek_eat(Hashtag_t)\ndef eat_hashtag(src:str) -\u003e int|None:\n    \"\"\"\n    Eat a hashtag, return the number of characters eaten\n    \n    hashtags are special identifiers that start with #\n    \"\"\"\n\n    if src.startswith('#'):\n        i,_ = eat_identifier(src[1:])\n        if i is not None:\n            return i + 1\n        \n    return None\n\n\n@peek_eat(Escape_t, whitelist=[String_t])\ndef eat_escape(src:str) -\u003e int|None:\n    r\"\"\"\n    Eat an escape sequence, return the number of characters eaten\n    Escape sequences must be either a known escape sequence:\n    - \\n newline \n    - \\r carriage return\n    - \\t tab\n    - \\b backspace\n    - \\f form feed\n    - \\v vertical tab\n    - \\a alert\n    - \\0 null\n    - \\u##..# or \\U##..# for an arbitrary unicode character. May have any number of hex digits\n    \n    or a \\ followed by an unknown character. In this case, the escape converts to just the unknown character\n    This is how to insert characters that are otherwise illegal inside a string, e.g. \n    - \\' converts to just a single quote '\n    - \\{ converts to just a single open brace {\n    - \\\\ converts to just a single backslash \\\n    - \\m converts to just a single character m\n    - etc.\n    \"\"\"\n    if not src.startswith('\\\\'):\n        return None\n\n    if len(src) == 1:\n        raise ValueError(\"unterminated escape sequence\")\n\n    if src[1] in 'uU':\n        i = 2\n        while i \u003c len(src) and src[i].isxdigit():\n            i += 1\n        if i == 2:\n            raise ValueError(\"invalid unicode escape sequence\")\n        return i\n\n    # if src[1] in 'nrtbfva0':\n    #     return 2\n\n    #all other escape sequences (known or unknown) are just a single character\n    return 2\n\n\n@full_eat()\ndef eat_string(src:str) -\u003e tuple[int, String_t] | None:\n    \"\"\"\n    strings are delimited with either single (') or double quotes (\")\n    the character portion of a string may contain any character except the delimiter, \\, or {.\n    strings may be multiline\n    strings may contain escape sequences of the form \\s where s is either a known escape sequence or a single character\n    strings may interpolation blocks which open with { and close with }\n\n    Tokenizing of escape sequences and interpolation blocks is handled as sub-tokenization task via eat_block and eat_escape\n\n    returns the number of characters eaten and an instance of the String token, containing the list of tokens/string chunks/escape sequences\n    \"\"\"\n    \n    #determine the starting delimiter, or exit if there is none\n    if src.startswith('\"\"\"') or src.startswith(\"'''\"):\n        delim = src[:3]\n        i = 3\n    elif src.startswith('\"') or src.startswith(\"'\"):\n        delim = src[0]\n        i = 1\n    else:\n        return None\n    \n    #keep track of chunks, and the start index of the current chunk\n    chunk_start = i\n    body = []\n\n    # add character sequences, escapes, and block sections until the end of the string\n    while i \u003c len(src) and not src[i:].startswith(delim):\n        \n        #regular characters\n        if src[i] not in '\\\\{':\n            i += 1\n            continue\n\n        #add the previous chunk before handling the escape/interpolation block\n        if i \u003e chunk_start:\n            body.append(src[chunk_start:i])\n\n        if src[i] == '\\\\':\n            res, _ = eat_escape(src[i:])\n            if res is None:\n                raise ValueError(\"invalid escape sequence\")\n            body.append(Escape_t(src[i:i+res]))\n            i += res\n\n        else: # src[i] == '{':\n            assert src[i] == '{', \"internal error\"\n            res, _ = eat_block(src[i:])\n            if res is None:\n                raise ValueError(\"invalid block\")\n            n_eaten, block = res\n            body.append(block)\n            i += n_eaten\n        \n        #update the chunk start\n        chunk_start = i\n            \n\n    if i == len(src):\n        raise ValueError(\"unterminated string\")\n    \n    #add the final chunk\n    if i \u003e chunk_start:\n        body.append(src[chunk_start:i])\n    \n    return i + len(delim), String_t(body)\n\n\n\n@peek_eat(RawString_t)\ndef eat_raw_string(src:str) -\u003e int|None:\n    \"\"\"\n    raw strings start with `r`, followed by a delimiter, one of ' \" ''' or \\\"\"\"\n    raw strings may contain any character except the delimiter.\n    Escapes and interpolations are ignored.\n    The string ends at the first instance of the delimiter\n    \"\"\"\n    if not src.startswith('r'):\n        return None\n    i = 1\n\n    if src[i:].startswith('\"\"\"') or src[i:].startswith(\"'''\"):\n        delim = src[i:i+3]\n        i += 3\n    elif src[i:].startswith('\"') or src[i:].startswith(\"'\"):\n        delim = src[i]\n        i += 1\n    else:\n        return None\n\n    while i \u003c len(src) and not src[i:].startswith(delim):\n        i += 1\n\n    if i == len(src):\n        raise ValueError(\"unterminated raw string\")\n\n    return i + len(delim)\n\n\n@peek_eat(Integer_t)\ndef eat_integer(src:str) -\u003e int|None:\n    \"\"\"\n    eat an integer, return the number of characters eaten\n    integers are of the form [0-9]+\n    \"\"\"\n    i = 0\n    while i \u003c len(src) and src[i].isdigit():\n        i += 1\n    return i if i \u003e 0 else None\n\n\n@peek_eat(BasedNumber_t)\ndef eat_based_number(src:str) -\u003e int|None:\n    \"\"\"\n    eat a based number, return the number of characters eaten\n\n    based numbers have a (case-insensitive) prefix (0p) identifying the base, and (case-sensitive) allowed digits\n    \"\"\"\n    try:\n        digits = number_bases[src[:2].lower()]\n    except KeyError:\n        return None\n    \n    i = 2\n    while i \u003c len(src) and src[i] in digits or src[i] == '_':\n        i += 1\n\n    return i if i \u003e 2 else None\n\n\n@peek_eat(Boolean_t)\ndef eat_boolean(src:str) -\u003e int|None:\n    \"\"\"\n    eat a boolean, return the number of characters eaten\n\n    booleans are either true or false (case-insensitive)\n    \"\"\"\n    sample = src[:5].lower()\n    if sample.startswith('true'):\n        return 4\n    elif sample.startswith('false'):\n        return 5\n\n    return None\n\n\n@peek_eat(Operator_t)\ndef eat_operator(src:str) -\u003e int|None:\n    \"\"\"\n    eat a unary or binary operator, return the number of characters eaten\n\n    picks the longest matching operator\n\n    see `operators` for full list of operators\n    \"\"\"\n    for op in operators:\n        if src.startswith(op):\n            return len(op)\n    return None\n\n@peek_eat(ShiftOperator_t, blacklist=[TypeParam_t])\ndef eat_shift_operator(src:str) -\u003e int|None:\n    \"\"\"\n    eat a shift operator, return the number of characters eaten\n\n    picks the longest matching operator. \n    Shift operators are not allowed in type parameters, e.g. `\u003e\u003e` is not recognized in `Foo\u003cBar\u003cBaz\u003cT\u003e\u003e, U\u003e`\n\n    see `shift_operators` for full list of operators\n    \"\"\"\n    for op in shift_operators:\n        if src.startswith(op):\n            return len(op)\n    return None\n\n@peek_eat(Comma_t)\ndef eat_comma(src:str) -\u003e int|None:\n    \"\"\"\n    eat a comma, return the number of characters eaten\n    \"\"\"\n    return 1 if src.startswith(',') else None\n\n\n@peek_eat(DotDot_t)\ndef eat_dotdot(src:str) -\u003e int|None:\n    \"\"\"\n    eat a dotdot, return the number of characters eaten\n    \"\"\"\n    return 2 if src.startswith('..') else None\n\n\n\nclass EatTracker:\n    i: int\n    tokens: list[Token]\n\n\n@full_eat()\ndef eat_type_param(src:str) -\u003e tuple[int, TypeParam_t] | None:\n    \"\"\"\n    eat a type parameter, return the number of characters eaten and an instance of the TypeParam token\n\n    type parameters are of the form \u003c...\u003e where ... is a sequence of tokens. \n    Type parameters may not start with `\u003c\u003c` or contain any shift operators (`\u003c\u003c`, `\u003c\u003c\u003c`, `\u003e\u003e`, `\u003e\u003e\u003e`)\n    Internally encountered shift operators are considered to be delimiters for the type parameter\n    \"\"\"\n    if not src.startswith('\u003c') or src.startswith('\u003c\u003c'):\n        return None\n    \n    i = 1\n    body: list[Token] = []\n\n    while i \u003c len(src) and src[i] != '\u003e':\n        \n        funcs = get_contextual_eat_funcs(TypeParam_t)\n        precedences = get_func_precedences(funcs)\n        res = get_best_match(src[i:], funcs, precedences)\n\n        if res is None:\n            return None        \n        n_eaten, token = res\n\n        if isinstance(token, Token):\n            #add the already-eaten token to the list of tokens\n            body.append(token)\n        else:\n            #add a new instance of the token to the list of tokens (handling idempotent token cases)\n            token_cls = token\n            if not body or token_cls not in idempotent_tokens or not isinstance(body[-1], token_cls):\n                body.append(token_cls(src[i:i+n_eaten]))\n\n        #increment the index\n        i += n_eaten\n\n\n    if i == len(src):\n        return None\n    \n    return i + 1, TypeParam_t(body)\n    \n\n\n\n@full_eat()\ndef eat_block(src:str, tracker:EatTracker|None=None) -\u003e tuple[int, Block_t] | None:\n    \"\"\"\n    Eat a block, return the number of characters eaten and an instance of the Block token\n\n    blocks are { ... } or ( ... ) and may contain sequences of any other tokens including other blocks\n\n    if return_partial is True, then returns (i, body) in the case where the eat process fails, instead of None\n    \"\"\"\n    \n    if not src or src[0] not in pair_opening_delims:\n        return None\n    \n    # save the opening delimiter\n    left = src[0]\n    \n    i = 1\n    body: list[Token] = []\n\n    if tracker:\n        tracker.i = i\n        tracker.tokens = body\n\n    while i \u003c len(src) and src[i] not in pair_closing_delims:\n        #run all root eat functions\n        #if multiple, resolve for best match (TBD... current is longest match + precedence)\n        #if no match, return None\n\n\n        ########### TODO: probably break this inner part into a function that eats the next token, given a list of eat functions\n        ###########       could also think about ways to specify other multi-match resolutions, other than longest match + precedence...\n        #run all the eat functions on the current src\n        funcs = get_contextual_eat_funcs(Block_t)\n        precedences = get_func_precedences(funcs)\n        res = get_best_match(src[i:], funcs, precedences)\n\n        #if we didn't match anything, return None\n        if res is None:\n            return None\n        \n        n_eaten, token = res\n        \n        if isinstance(token, Token):\n            #add the already-eaten token to the list of tokens\n            body.append(token)\n        else:\n            #add a new instance of the token to the list of tokens (handling idempotent token cases)\n            token_cls = token\n            if not body or token_cls not in idempotent_tokens or not isinstance(body[-1], token_cls):\n                body.append(token_cls(src[i:i+n_eaten]))\n\n        #increment the index\n        i += n_eaten\n        if tracker:\n            tracker.i = i\n\n    if i == len(src):\n        if tracker: #only return an exception for the top level block. nested blocks can return None\n            raise ValueError(\"unterminated block\") \n        return None\n    \n    # closing delim (doesn't need to match opening delim)\n    right = src[i]\n    assert left in pair_opening_delims and right in pair_closing_delims, f\"invalid block delimiters: {left} {right}\"\n\n    #include closing delimiter in character count\n    i += 1\n    if tracker:\n        tracker.i = i\n\n    return i, Block_t(body, left=left, right=right)\n\n\n\ndef get_best_match(src:str, eat_funcs:list, precedences:list[int]) -\u003e tuple[int, Type[Token]|Token]|None:\n    #TODO: handle selecting between full_eat and peek_eat functions that were successful...\n    #      general, just need to clarify the selection order precedence\n\n    #may return none if no match\n    #may return (i, token_cls) if peek match\n    #may return (i, token) if full match\n\n    matches = [eat_func(src) for eat_func in eat_funcs]\n\n    #find the longest token that matched. if multiple tied for longest, use the one with the highest precedence.\n    #raise an error if multiple tokens tied, and they have the same precedence\n    def key(x):\n        (res, _cls), precedence = x\n        if res is None:\n            return 0, precedence\n        if isinstance(res, tuple):\n            res, _token = res #full_eat functions return a tuple of (num_chars_eaten, token)\n        return res, precedence\n\n    matches = [*zip(matches, precedences)]\n    best = max(matches, key=key)\n    ties = [match for match in matches if key(match) == key(best)]\n    if len(ties) \u003e 1:\n        raise ValueError(f\"multiple tokens matches tied {[match[0][1].__name__ for match in ties]}: {repr(src)}\\nPlease disambiguate by providing precedence levels for these tokens.\")\n\n    (res, token_cls), _ = best\n    \n    # force the type annotations\n    res: tuple[int, Token]|int|None \n    token_cls: type[Token]\n\n    if res is None:\n        return None\n    \n    if isinstance(res, int):\n        return res, token_cls\n    \n    if isinstance(res, tuple):\n        return res\n    \n    raise ValueError(f\"Internal Error: invalid return type from eat function: {res}\")\n\n\n\ndef tokenize(src:str) -\u003e list[Token]:\n\n    # insert src into a block\n    src = f'{{\\n{src}\\n}}'\n\n    #convert string to a coordinate string (for keeping track of row/col numbers)\n    src = CoordString(src, anchor=(-1, 0))\n\n    # eat tokens for a block\n    tracker = EatTracker()\n    try:\n        res, _cls = eat_block(src, tracker=tracker)\n    except Exception as e:\n        raise ValueError(f\"failed to tokenize: ```{escape_whitespace(src[tracker.i:])}```.\\nCurrent tokens: {tracker.tokens}\") from e\n\n    # check if the process failed\n    if res is None:\n        raise ValueError(f\"failed to tokenize: ```{escape_whitespace(src[tracker.i:])}```.\\nCurrent tokens: {tracker.tokens}\")\n\n    (i, block) = res\n    tokens = block.body\n\n    # ensure that all blocks have valid open/close pairs\n    validate_block_braces(tokens)\n\n    return tokens\n\ndef full_traverse_tokens(tokens:list[Token]) -\u003e Generator[tuple[int, Token, list[Token]], None, None]:\n    \"\"\"\n    Walk all tokens recursively, allowing for modification of the tokens list as it is traversed.\n    \n    So long as modifications do not occur before the current token, this will safely iterate over all tokens.\n    This will not yield string or escape chunks in strings, but will yield interpolated blocks.\n\n    While traversing, the user can overwrite the current index by calling .send(new_index).\n\n    e.g.\n    ```python\n    gen = full_traverse_tokens(tokens)\n    for i, token, stream in gen:\n        #do something with current token\n        #...\n\n        #maybe overwrite the current index\n        if should_overwrite:\n            gen.send(new_index)\n    ```\n\n    Do not call .send() twice in a row without calling next() in between. This will cause unexpected behavior.\n\n    Args:\n        tokens: the list of tokens to traverse\n\n    Yields:\n        i: the index of the current token in the current token list\n        token: the current token\n        stream: the current token list\n    \"\"\"\n\n    i = 0\n\n    while i \u003c len(tokens):\n        \"\"\"\n        1. get next token\n        2. send current to user\n        3. increment index (or overwrite it)\n        4. recurse into blocks\n        \"\"\"\n\n        # get the current token\n        token = tokens[i]\n\n        # send the current index to the user. possibly receive a new index to continue from\n        overwrite_i = yield i, token, tokens\n\n        # only calls to next() will continue execution. calls to .send do nothing wait\n        if overwrite_i is not None:\n            assert (yield) is None, \".send() may only be called once per iteration.\"\n            i = overwrite_i\n        else:\n            i += 1\n\n        # recursively handle traversing into blocks\n        if isinstance(token, Block_t) or isinstance(token, TypeParam_t):\n            yield from full_traverse_tokens(token.body)\n        \n        # recursively handle traversing into strings (only interpolation blocks are yielded)\n        if isinstance(token, String_t):\n            for child in token.body:\n                if isinstance(child, Block_t):\n                    yield from full_traverse_tokens(child.body)\n\n\ndef traverse_tokens(tokens:list[Token]) -\u003e Generator[Token, None, None]:\n    \"\"\"\n    Convenience function over full_traverse_tokens. Walk all tokens recursively\n    \n    Does not allow for modification of the tokens list as it is traversed.\n    To modify during traversal, use `full_traverse_tokens` instead.\n\n    Args:\n        tokens: the list of tokens to traverse\n\n    Yields:\n        token: the current token\n    \"\"\"\n    for _, token, _ in full_traverse_tokens(tokens):\n        yield token\n\n\n\ndef validate_block_braces(tokens:list[Token]) -\u003e None:\n    \"\"\"\n    Checks that all blocks have valid open/close pairs.\n\n    For example, ranges may have differing open/close pairs, e.g. [0..10), (0..10], etc.\n    But regular blocks must have matching open/close pairs, e.g. { ... }, ( ... ), [ ... ]\n    Performs some validation, without knowing if the block is a range or a block. \n    So more validation is needed when the actual block type is known.\n\n    Raises:\n        AssertionError: if a block is found with an invalid open/close pair\n    \"\"\"\n    for token in traverse_tokens(tokens):\n        if isinstance(token, Block_t):\n            assert token.left in valid_delim_closers, f'INTERNAL ERROR: left block opening token is not a valid token. Expected one of {[*valid_delim_closers.keys()]}. Got \\'{token.left}\\''\n            assert token.right in valid_delim_closers[token.left], f'ERROR: mismatched opening and closing braces. For opening brace \\'{token.left}\\', expected one of \\'{valid_delim_closers[token.left]}\\''\n        \n\ndef validate_functions():\n\n    # Validate the @peek_eat function signatures\n    peek_eat_functions = get_peek_eat_funcs_with_name()\n    for name, wrapper_func in peek_eat_functions:\n        func = wrapper_func._eat_func\n        signature = inspect.signature(func)\n        param_types = [param.annotation for param in signature.parameters.values() if param.default is inspect.Parameter.empty]\n        return_type = signature.return_annotation\n\n        # Check if the function has the correct signature\n        if len(param_types) != 1 or param_types[0] != str or return_type != int|None:\n            pdb.set_trace()\n            raise ValueError(f\"{func.__name__} has an invalid signature: `{signature}`. Expected `(src: str) -\u003e int | None`\")\n\n    # Validate the @full_eat function signatures\n    full_eat_functions = get_full_eat_funcs_with_name()\n    for name, wrapper_func in full_eat_functions:\n        func = wrapper_func._eat_func\n        signature = inspect.signature(func)\n        param_types = [param.annotation for param in signature.parameters.values() if param.default is inspect.Parameter.empty]\n        return_type = signature.return_annotation\n\n        # Check if the function has the correct signature\n        error_message = f\"{func.__name__} has an invalid signature: `{signature}`. Expected `(src: str) -\u003e tuple[int, Token] | None`\"\n        if not (isinstance(return_type, UnionType) and len(return_type.__args__) == 2 and type(None) in return_type.__args__):\n            raise ValueError(error_message)\n        A, B = return_type.__args__\n        if B is not type(None):\n            B, A = A, B\n        if not (isinstance(A, type(tuple)) and len(A.__args__) == 2 and A.__args__[0] is int and issubclass(A.__args__[1], Token)):\n            raise ValueError(error_message)        \n        if len(param_types) != 1 or param_types[0] != str:\n            pdb.set_trace()\n            raise ValueError(error_message)\n\n    # check for any functions that start with eat_ but are not decorated with @eat\n    peek_eat_func_names = {name for name, _ in peek_eat_functions}\n    full_eat_func_names = {name for name, _ in full_eat_functions}\n    for name, func in globals().items():\n        if name.startswith(\"eat_\") and callable(func) and name not in peek_eat_func_names and name not in full_eat_func_names:\n            raise ValueError(f\"`{name}()` function is not decorated with @peek_eat or @full_eat\")\n\n\ndef escape_whitespace(s:str):\n    \"\"\"convert a string to one where all non-space whitespace is escaped\"\"\"\n    escape_map = {\n        '\\t': '\\\\t',\n        '\\r': '\\\\r',\n        '\\f': '\\\\f',\n        '\\v': '\\\\v',\n        '\\n': '\\\\n',\n    }\n    return ''.join(escape_map.get(c, c) for c in s)\n\n\ndef tprint(token:Token, level=0):\n    \"\"\"\n    print a token with a certain indentation level.\n    \n    If tokens contain nested tokens, they will be printed recursively with an increased indentation level\n    \"\"\"\n    print(f'{\"    \"*level}', end='')\n    if isinstance(token, Block_t):\n        print(f'\u003cBlock {token.left}{token.right}\u003e')\n        for t in token.body:\n            tprint(t, level=level+1)\n    elif isinstance(token, String_t):\n        print(f'\u003cString\u003e')\n        for t in token.body:\n            tprint(t, level=level+1)\n    elif isinstance(token, TypeParam_t):\n        print(f'\u003cTypeParam\u003e')\n        for t in token.body:\n            tprint(t, level=level+1)\n    else:\n        print(token)\n        \n\n\ndef test():\n    import sys\n    \"\"\"simple test dewy program\"\"\"\n\n    try:\n        path = sys.argv[1]\n    except IndexError:\n        raise ValueError(\"Usage: `python tokenizer.py path/to/file.dewy\u003e`\")\n\n\n    with open(path) as f:\n        src = f.read()\n\n    tokens = tokenize(src)\n    print(f'matched tokens:')\n    tprint(Block_t(left='{', right='}', body=tokens))\n    # for t in tokens:\n    #     tprint(t, level=1)\n\n\n\n\nif __name__ == \"__main__\":\n    validate_functions()\n    test()"])</script><script>self.__next_f.push([1,"22:T14ae,"])</script><script>self.__next_f.push([1,"from typing import Callable\n\n\n\ndef wrap_coords(method:Callable):\n    def wrapped_method(self, *args, **kwargs):\n        result = method(self, *args, **kwargs)\n        if isinstance(result, str) and len(result) == len(self):\n            custom_str = CoordString(result)\n            custom_str.row_col_map = self.row_col_map\n            return custom_str\n        else:\n            raise ValueError(\"coord_string_method must return a string of the same length as the original string\")\n        return result\n\n    return wrapped_method\n\ndef fail_coords(method:Callable):\n    def wrapped_method(self, *args, **kwargs):\n        raise ValueError(f\"coord_string_method {method} cannot be called on a CoordString, as it will not return a CoordString\")\n    return wrapped_method\n\n\nclass CoordString(str):\n    \"\"\"\n    Drop-in replacement for str that keeps track of the coordinates of each character in the string\n\n    Identical to normal strings, but attaches the `row_col(i:int) -\u003e tuple[int, int]` method\n    which returns the (row, column) of the character at index i\n\n    Args:\n        anchor (tuple[int,int], optional): The row and column of the top left of the string. Defaults to (0, 0).\n    \"\"\"\n    def __new__(cls, *args, anchor:tuple[int,int]=(0, 0), **kwargs):\n        self = super().__new__(cls, *args, **kwargs)\n        row, col = anchor\n        self.row_col_map = self._generate_row_col_map(row, col)\n\n        return self\n\n    #TODO: make init so that class recognized .row_col_map as property on instances\n    # def __init__(self, s:str, row_col_map:list[tuple[int,int]]):\n\n\n    def _generate_row_col_map(self, row=0, col=0) -\u003e list[tuple[int, int]]:\n        row_col_map = []\n        for c in self:\n            if c == '\\n':\n                row_col_map.append((row, col))\n                row += 1\n                col = 0\n            else:\n                row_col_map.append((row, col))\n                col += 1\n        return row_col_map\n\n    def __getitem__(self, key):\n        if isinstance(key, slice):\n            sliced_str = super().__getitem__(key)\n            sliced_row_col_map = self.row_col_map[key]\n            custom_str = CoordString(sliced_str)\n            custom_str.row_col_map = sliced_row_col_map\n            return custom_str\n        return super().__getitem__(key)\n\n    def loc(self, index):\n        return self.row_col_map[index]\n\n    @staticmethod\n    def from_existing(new_str:str, old_coords:list[tuple[int,int]]) -\u003e 'CoordString':\n        new_coord_str = CoordString(new_str)\n        new_coord_str.row_col_map = old_coords\n        return new_coord_str\n\n    #wrappers for string methods that should return CoordStrings\n    def lstrip(self, *args, **kwargs):\n        result = super().lstrip(*args, **kwargs)\n        custom_str = CoordString(result)\n        custom_str.row_col_map = self.row_col_map[len(self)-len(result):]\n        return custom_str\n\n    def rstrip(self, *args, **kwargs):\n        result = super().rstrip(*args, **kwargs)\n        custom_str = CoordString(result)\n        custom_str.row_col_map = self.row_col_map[:len(result)]\n        return custom_str\n    \n    def strip(self, *args, **kwargs):\n        return self.lstrip(*args, **kwargs).rstrip(*args, **kwargs)\n\n\n    @wrap_coords\n    def capitalize(self): return super().capitalize()\n\n    @wrap_coords\n    def casefold(self): return super().casefold()\n\n    @wrap_coords\n    def lower(self): return super().lower()\n\n    @wrap_coords\n    def upper(self): return super().upper()\n\n    @wrap_coords\n    def swapcase(self): return super().swapcase()\n\n    @wrap_coords\n    def title(self): return super().title()\n\n    @wrap_coords\n    def translate(self, table): return super().translate(table)\n\n    @wrap_coords\n    def replace(self, old, new, count=-1): return super().replace(old, new, count)\n\n    @fail_coords\n    def center(self, *args, **kwargs): ...\n\n    @fail_coords\n    def expandtabs(self, *args, **kwargs): ...\n\n    @fail_coords\n    def ljust(self, *args, **kwargs): ...\n\n    @fail_coords\n    def zfill(self, *args, **kwargs): ...\n\n\n#TODO: maybe make adding this string with other regular str illegal\n\n\n\n\n\nint_parsable_base_prefixes = {\n    '0b':2,  '0B':2,\n    '0t':3,  '0T':3,\n    '0q':4,  '0Q':4,\n    '0s':6,  '0S':6,\n    '0o':8,  '0O':8,\n    '0d':10, '0D':10,\n    # '0z':12, #uses different digits Z/z and X/x (instead of A/a and B/b expected by int())\n    '0x':16, '0X':16,\n    '0u':32, '0U':32,\n    '0r':36, '0R':36,\n    # '0y':64, #more than int's max parsable base (36)\n}\n\n\ndef based_number_to_int(src:str) -\u003e int:\n    \"\"\"\n    convert a number in a given base to an int\n    \"\"\"\n    prefix, digits = src[:2], src[2:]\n    if prefix in int_parsable_base_prefixes:\n        return int(digits, int_parsable_base_prefixes[prefix])\n    elif prefix == '0z':\n        raise NotImplementedError(f\"base {prefix} is not supported\")\n    elif prefix == '0y':\n        raise NotImplementedError(f\"base {prefix} is not supported\")\n    else:\n        raise ValueError(f\"INTERNAL ERROR: base {prefix} is not a valid base\")\n\n\ndef bool_to_bool(src:str) -\u003e bool:\n    \"\"\"\n    convert a (case-insensitive) bool literal to a bool\n    \"\"\"\n    try:\n        return bool(['false', 'true'].index(src.lower()))\n    except ValueError:\n        raise ValueError(f\"INTERNAL ERROR: bool {src} is not a valid bool\") from None"])</script><script>self.__next_f.push([1,"23:T8cb,"])</script><script>self.__next_f.push([1,"//TODO: uncomment when types are supported\n/{\n// simple xorshift+ generator\nstate:uint64 = 123456789\nrand = ():uint64 =\u003e {\n    state xor= state \u003e\u003e 21\n    state xor= state \u003c\u003c 35\n    state xor= state \u003e\u003e 4\n    \n    return state * 2_685821_657736_338717 //TODO: divide by uint64.MAX (18_446744_073709_551615)\n}\nhalf = 9_223372_036854_775807\na = rand \u003c half\nb = rand \u003c half\nc = rand \u003c half\nd = rand \u003c half\ne = rand \u003c half\nf = rand \u003c half\ng = rand \u003c half\nh = rand \u003c half\ni = rand \u003c half\nj = rand \u003c half\nk = rand \u003c half\nl = rand \u003c half\nm = rand \u003c half\nn = rand \u003c half\no = rand \u003c half\np = rand \u003c half\nq = rand \u003c half\nr = rand \u003c half\ns = rand \u003c half\nt = rand \u003c half\nu = rand \u003c half\nv = rand \u003c half\nw = rand \u003c half\nx = rand \u003c half\ny = rand \u003c half\nz = rand \u003c half\n}/\n\n//manually specify bools\na = false\nb = true\nc = true\nd = false\ne = true\nf = false\ng = true\nh = false\ni = true\nj = false\nk = true\nl = false\nm = true\nn = false\no = true\np = false\nq = true\nr = false\ns = true\nt = false\nu = true\nv = false\nw = true\nx = false\ny = true\nz = false\n\n\n\nif a\n    printl'a'\nelse if b\n    if c\n        if d\n            if e\n                printl'bcde'\n            else if f\n                if g\n                    if h\n                        printl'bcdfgh'\n                    else if i\n                        printl'bcdfgi'\n                    else if j\n                        printl'bcdfgj'\n                    else\n                        printl'bcdfg[]'\n                else if k\n                    printl'bcdfk'\n                else if l\n                    if m\n                        printl'bcdflm'\n                    else\n                        printl'bcdfl[]'\n                else\n                    printl'bcdf[]'\n            else if n\n                printl'bcdn'\n            else\n                printl'bcd[]'\n        else if o\n            printl'bco'\n        else if p\n            if q\n                printl'bcpq'\n            else\n                printl'bcp[]'\n        else\n            printl'bc[]'\n    else\n        printl'b[]'\nelse if r\n    printl'r'\nelse if s\n    if t\n        printl'st'\n    else if u\n        printl'su'\nif v\n    if w\n        printl'vw'\n    else if x\n        printl'x'\nif y\n    printl'y'\nelse if z\n    printl'z'\nelse\n    printl'[]'\n"])</script><script>self.__next_f.push([1,"24:Tc2b,"])</script><script>self.__next_f.push([1,"// examples of syntax used in dewy\n// line comments\n/{ block/multiline comments }/\n\n// typed declaration\napple: uint64\nbanana: map\u003cint, string\u003e\npeach: array\u003cint, length=N\u003e  //array of ints with length N...\nlet pear: set\u003crange\u003e  // let indicates that this is definitely a new declaration, even if the identifier already exists\n\n\n\n// unpack assignment examples\nA = 1..10\nB = [loop a in A -a]\nloop [a, b] in [A B] {}\n\n// object with nested objects to unpack\nmy_obj = [\n    apple = [1 2 3 4 [\n        ultimate_answer = 42\n    ]]\n    banana = 10\n    peach = [\n        purple = 23\n        blue = 12\n        orange = 'orange'\n    ]\n]\n\n// nested unpack assignment. tbd if the top level is `[unpack, params, etc] = obj`, or `obj as [unpack, params, etc]`\n[\n    apple as [\n        a1, \n        a2, \n        a3, \n        a4, \n        a5 as [ultimate_answer as answer]\n    ], \n    banana as renamed_banana, \n    peach as [purple, blue, orange]\n] = my_obj\n// unpacked variables are:\n//   a1 = 1, a2 = 2, a3 = 3, a4 = 4\n//   answer = 42\n//   renamed_banana = 10\n//   purple = 23, blue = 12, orange = 'orange'\n\n// unpacking dictionaries probably treats them as just the list of key -\u003e value pairs\n// unpacking sets, probably just treats the elements like a normal array\n// unpacking ranges treats them as a normal array\n\n// `...` can be used in unpack to coalesce extra elements for list-like containers\n// there may only be 1 `...` in an unpack (otherwise it would be ambiguous which elements to collect)\n// the variable receiving the `...` will be of the same type as the original object being unpacked\nmy_arr = [1 2 3 4 5 6 7 8 9]\n[a1, a2, a3, ...my_arr, a8, a9] = my_arr  //a1 = 1, a2 = 2, a3 = 3, my_arr = [4, 5, 6, 7], a8 = 8, a9 = 9\n\nmy_dict = ['apple' -\u003e 1 'banana' -\u003e 2 'peach' -\u003e 3 'pie' -\u003e 4]\n[d1, ...dict_left] = my_dict //d1 = ('apple' -\u003e 1), dict_left = ['banana' -\u003e 2 'peach' -\u003e 3 'pie' -\u003e 4]\n\n// random range note: for step sizes other than +1, use range_iter constructor e.g. range_iter(start to stop, step=5)\nmy_range = 1..inf\nloop my_range.length \u003e? 0 ( [i, ...my_range] = my_range )\n// first iteration: i = 1, my_range = 2..inf\n// second iteration: i = 2, my_range = 3..inf\n// third iteration: i = 3, my_range = 4..inf\n// ...\n// for forever\n\n//[...my_range, i] = my_range //will probably set my_range = 1 to inf, i = inf\n\n// unpacking too many values, or named values that don't exist just sets them to undefined\n\n\n\n// assignment expressions (i.e. python's walrus operator from https://www.python.org/dev/peps/pep-0572/)\n// Handle a matched regex\nif (match = pattern.search(data); match) not =? undefined\n{\n    // Do something with match\n}\n\n// A loop that can't be trivially rewritten using 2-arg iter()\nloop (chunk = file.read(8192); chunk.length \u003e? 0)\n{\n   process(chunk)\n}\n\n// Reuse a value that's expensive to compute\n[(y = f(x); y) y**2 y**3]\n\n// Share a subexpression between a comprehension filter clause and its output\nfiltered_data = [for x in data if (y = f(x); y) not =? undefined y]\n//though you could also just write this like so\nfiltered_data = [for x in data {y = f(x) if y not =? undefined y}]\n"])</script><script>self.__next_f.push([1,"25:T12f2,"])</script><script>self.__next_f.push([1,"//simple, fast, high quality, dependency-free RNG generation\n//uniform distribution via XORSHIFT*\n//normal distribution via PPND16\n\n\nRNG = (s:uint64) =\u003e [\n    let s = s\n    next_u64 = () =\u003e {\n        s ^= s \u003e\u003e 21\n        s ^= s \u003c\u003c 35\n        s ^= s \u003e\u003e 4\n        s * 2685821657736338717\n    }\n    next_uniform = () =\u003e fast_to_uniform(next_u64())\n    next_normal = () =\u003e ppnd16(fast_to_uniform(next_u64()))\n    \n    /{\n        Use bit hacks to quickly convert a 64-bit number to a double in the range [0, 1)\n\n        @param x the number to convert. Only the lowest 23 bits are used.\n        @return the number in the range [0, 1)\n    }/\n    fast_to_uniform = (x:uint64):float64 =\u003e {\n        const mask1 = 0x3FF0_0000_0000_0000\n        const mask2 = 0x3FFF_FFFF_FFFF_FFFF\n        out: uint64 = (x | mask1) \u0026 mask2\n        (out as float64) - 1\n    }\n\n    full_to_uniform = (x:uint64):float64 =\u003e truediv(x, uint64.max, float64)\n\n\n    /{\n        Convert a uniformly distributed double in the range (0, 1) to a normally distributed double\n        Uses the PPND16 algorithm from Algorithm AS241: The Percentage Points of the Normal Distribution\n\n        @param P the uniformly distributed double in the range (0, 1)\n        @return the normally distributed double\n    }/\n    ppnd16 = (P:float64) =\u003e {\n        const SPLIT1:float64 = 0.425\n        const SPLIT2:float64 = 5.0\n        const CONST1:float64 = 0.180625\n        const CONST2:float64 = 1.6\n\n        // Cofficients for P close to 0.5\n        const A0:float64 = 3.3871328727963665\n        const A1:float64 = 133.14166789178438\n        const A2:float64 = 1971.5909503065514\n        const A3:float64 = 13731.693765509461\n        const A4:float64 = 45921.95393154987\n        const A5:float64 = 67265.7709270087\n        const A6:float64 = 33430.575583588128\n        const A7:float64 = 2509.0809287301227\n        const B1:float64 = 42.313330701600911\n        const B2:float64 = 687.18700749205789\n        const B3:float64 = 5394.1960214247511\n        const B4:float64 = 21213.794301586597\n        const B5:float64 = 39307.895800092709\n        const B6:float64 = 28729.085735721943\n        const B7:float64 = 5226.4952788528544\n        \n        // Coefficients for P not close to 0, 0.5 or 1\n        const C0:float64 = 1.4234371107496835\n        const C1:float64 = 4.6303378461565456\n        const C2:float64 = 5.769497221460691\n        const C3:float64 = 3.6478483247632045\n        const C4:float64 = 1.2704582524523684\n        const C5:float64 = 0.24178072517745061\n        const C6:float64 = 0.022723844989269184\n        const C7:float64 = 0.00077454501427834139\n        const D1:float64 = 2.053191626637759\n        const D2:float64 = 1.6763848301838038\n        const D3:float64 = 0.6897673349851\n        const D4:float64 = 0.14810397642748008\n        const D5:float64 = 0.015198666563616457\n        const D6:float64 = 0.00054759380849953455\n        const D7:float64 = 0.0000000010507500716444169\n\n        // Coefficients for P near 0 or 1\n        const E0:float64 = 6.6579046435011033\n        const E1:float64 = 5.4637849111641144\n        const E2:float64 = 1.7848265399172913\n        const E3:float64 = 0.29656057182850487\n        const E4:float64 = 0.026532189526576124\n        const E5:float64 = 0.0012426609473880784\n        const E6:float64 = 0.000027115555687434876\n        const E7:float64 = 0.00000020103343992922882\n        const F1:float64 = 0.599832206555888\n        const F2:float64 = 0.13692988092273581\n        const F3:float64 = 0.014875361290850615\n        const F4:float64 = 0.00078686913114561329\n        const F5:float64 = 0.000018463183175100548\n        const F6:float64 = 0.0000001421511758316446\n        const F7:float64 = 0.0000000000000020442631033899397\n\n        let R:float64, Q:float64, PPND16:float64\n        Q = P - 0.5\n\n        if (abs(Q) \u003c=? SPLIT1)\n        {\n            R = CONST1 - Q * Q\n            return Q * (((((((A7 * R + A6) * R + A5) * R + A4) * R + A3) * R + A2) * R + A1) * R + A0) / (((((((B7 * R + B6) * R + B5) * R + B4) * R + B3) * R + B2) * R + B1) * R + 1)\n        }\n        \n        R = if Q \u003c? 0 P else 1 - P\n        \n        if (R \u003c=? 0)\n            return 0\n        \n        R = sqrt(-log(R))\n        \n        if (R \u003c=? SPLIT2)\n        {\n            R = R - CONST2\n            PPND16 = (((((((C7 * R + C6) * R + C5) * R + C4) * R + C3) * R + C2) * R + C1) * R + C0) / (((((((D7 * R + D6) * R + D5) * R + D4) * R + D3) * R + D2) * R + D1) * R + 1)\n        }\n        else\n        {\n            R = R - SPLIT2\n            PPND16 = (((((((E7 * R + E6) * R + E5) * R + E4) * R + E3) * R + E2) * R + E1) * R + E0) / (((((((F7 * R + F6) * R + F5) * R + F4) * R + F3) * R + F2) * R + F1) * R + 1)\n        }\n        \n        if (Q \u003c? 0)\n            PPND16 = -PPND16\n        \n        return PPND16\n    }\n]\n\n\n\nr = RNG(42)\nloop i in 0..100 printl(r.next_normal())"])</script><script>self.__next_f.push([1,"26:T1536,"])</script><script>self.__next_f.push([1,"///////////////////// STRING INTERPOLATION /////////////////////\n\n/{Todo: probably break each section for different syntaxes into different files?}/\n\n//silly example with keyword vs identifier\nloop i i\n\nr'this is a raw string \\'  expr  'a separate string later'\n\n// simple blocks\n{   }\n( /{comment inside}/ )\n{ 2+2 }\n( 2+2 )\n\n\n//string interpolation\nmy_string = '2 + 2 = {2+2}'\n\n//complex interpolation\ns = \"first 10 primes are: {\n    primes = [2]\n    loop i in [3, 5..) and primes.length \u003c? 10\n        if i .% primes |\u003e product not =? 0 \n            primes.push(i)\n    primes\n}\"\n\n\n//alternative prime generator + getting first 10 primes\n#ctx\nprimes = [\n    2\n    lazy i in [3, 5..)\n        if i .% #ctx.primes .=? 0 |\u003e @reduce(, (prev, v) =\u003e prev and v)\n            i\n][..10)\n\n//TBD if there is a parallel way to do this where the i .% primes dispatches each operation, and fails immediately on any returning false\n#label\nprimes = [\n    2\n    lazy i in [3, 5..)\n        if not parallel_or(p =\u003e i % p =? 0, #label.primes)\n            i\n][..10)\n//parallel or is like goroutines with cancel once any is true...should have it be more flexible, e.g. able to use any of the boolean keywords that can short circuit\n//actually probably don't want to need to specify that it's parallel. Instead if there's an operation over a vector, it gets parallelized if possible.\n\n//nested interpolation\ns2 = 'this is an outer string, and {'this is an interior string with \"{my_string}\" in it'}'\n\n\n\n\n\nconst add: (int, int) =\u003e int = (a:int, b:int) =\u003e { /{return sum of a and b}/ }\nlet div: (real, real) =\u003e real? = (a:real, b:real) =\u003e { /{return a / b}/ }\n\n// function type with named default argument\nmy_func: (string, kwarg:bool) =\u003e () = (s:string, kwarg:bool=false) =\u003e {}\n\n//you probably can do the verbose version as well (probably useful for when you're just defining the interface without the implementation)\nmy_func: (s:string, kwarg:bool=false) =\u003e void\n\n\n\n// example annotations for function types\n() =\u003e ()\n() =\u003e void\n() =\u003e bool\nint =\u003e bool\na: int =\u003e bool\n(int, int) =\u003e int\n\u003cT\u003e(T, T) =\u003e T\n\u003cT\u003e(a:T, b:T) =\u003e T\n\n// object type\n[a:int? b:string]\n\n//? (optional) is sugar for |void\n[a:int|void b:string]\n\n// operators juxtaposed to identifiers\naorb\na or b\na+b\n\n\n//based number literals\n0b1010_0011_0101_0110_1001_1010_1100_1111\n0B0101_1111_1010_1110_0011_0101_1001_1100\n\n0t012_221_012_221_012_221_012_221\n0t211_001_211_001_211_001_211_001\n\n0q331_231_223_131_331_231_223_131\n0Q123_321_123_321_123_321_123_321\n\n0s123_450_123_450_123_450_123_450\n0S543_210_543_210_543_210_543_210\n\n0o123_456_701_234_567_012_345_670\n0O012_345_670_123_456_701_234_567\n\n0d123_456_789_012_345_678_901_234\n0D987_654_321_098_765_432_109_876\n\n0z123_456_789_xe0_123_456_789_xe0\n0ZEX9_876_543_210_987_654_321_09E\n\n0x1234_5678_9abc_def0_1234_5678_9abc_def0\n0XFEDC_BA98_7654_3210_fedc_ba98_7654_3210\n\n0u0123456789abcdefghijklmnopqrstuv0123456\n0UVUTSRQPONMLKJIHGFEDCBA9876543210vutsrq\n\n0r0123456789abcdefghijklmnopqrstuvwxyz012345\n0RZYXWVUTSRQPONMLKJIHGFEDCBA9876543210zyxwv\n\n0y0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!$\n0Y$!ZYXWVUTSRQPONMLKJIHGFEDCBA9876543210zyxwvutsrqponmlkjihgfedcba\n\n//Units TODO\n\n\n\n\n[a, b, c] = [1 2 3]                                         //a=1, b=2, c=3\n[a, [b, c]] = [1 [2 3]]                                     //a=1, b=2, c=3\n[a, [b, c], d] = [1 [2 3] 4]                                //a=1, b=2, c=3, d=4\n[a, ...b] = [1 2 3 4]                                       //a=1, b=[2 3 4]\n[a, ...b, c] = [1 2 3 4 5]                                  //a=1, b=[2 3 4], c=5\n[a, ...b, [c, [...d, e, f]]] = [1 2 3 4 [5 [6 7 8 9 10]]]   //a=1, b=[2 3 4], c=5, d=[6 7 8], e=9, f=10\n\n\n\n// silly things that are technically valid\nx = loop i in [0..10] i //x=10\n\ny = [\n    if something \n        x\n    else loop i in something_else\n        y\n    else if z\n        z\n    else loop i in last_thing\n        w\n    else\n        ()\n]\n\n\napple \u0026 banana\napple\u0026banana\napple | banana\napple|banana\n\n\n\n\n\n///////////// String prefixes ////////////////\np = s:string =\u003e [\n    //process s based on / and \\ separators\n    //store result in this object\n    route:array\u003cstring\u003e = ...\n    filename:string? = ...\n    extension:string? = ...\n]\n\np\"this/is/a/file/path.ext\"\n\n//other prefixes\nre\"[^i*\u00262@]\"                            // regex literal\nt'my_token'                             //token literal. probably my version of enums\nr'this is a raw string'                 //raw string. technically handled during tokenizing, there is no r function\n(dewy)r'''printl(\"Hello, World!\")'''    //dewy source code literal. uses raw string so that we don't have to worry about {}.\n\nipa\"ɛt vɔkavit dɛus aɾidam tɛɾam kɔngɾɛgatsiɔnɛskwɛ akwaɾum apɛlavit maɾia ɛt vidit dɛus kwɔd ɛsɛt bɔnum\" //international phonetic alphabet literal\n(apl)r\"life ← {⊃1 ⍵ ∨.∧ 3 4 = +/ +⌿ ¯1 0 1 ∘.⊖ ¯1 0 1 ⌽¨ ⊂⍵}\"  //apl expression literal\napl\u003c|r\"life ← {⊃1 ⍵ ∨.∧ 3 4 = +/ +⌿ ¯1 0 1 ∘.⊖ ¯1 0 1 ⌽¨ ⊂⍵}\"  //same as above\n\n'''this is a regular string with triple quotes'''\n\"\"\"this is a regular string with triple quotes\"\"\"\n\n///////////// object prefixes ////////////////\n//doubly linked list\ndll[1 2 3 4 6 5 3 6 3 2]\n\n//set literal syntax\nset[4 3 6 4 6 4 2 2 4 5]\n\n\n\n// silly example for generating a list of ones\nones = n =\u003e {l = [...[1..n]] l.=1 l}\nones(10) // [1 1 1 1 1 1 1 1 1 1]\n//alternate\nones = n =\u003e [loop i in 1..n 1]"])</script><script>self.__next_f.push([1,"17:[\"$\",\"$L1b\",null,{\"dewy_interpreter_source\":[{\"name\":\"backend\",\"code\":\"$1c\"},{\"name\":\"dewy\",\"code\":\"$1d\"},{\"name\":\"frontend\",\"code\":\"$1e\"},{\"name\":\"parser\",\"code\":\"$1f\"},{\"name\":\"postok\",\"code\":\"$20\"},{\"name\":\"tokenizer\",\"code\":\"$21\"},{\"name\":\"utils\",\"code\":\"$22\"}],\"dewy_examples\":{\"good_examples\":[{\"name\":\"hello.dewy\",\"code\":\"printl'Hello, World!'\"},{\"name\":\"hello_func.dewy\",\"code\":\"main = () =\u003e printl'Hello, World!'\\nmain\"},{\"name\":\"hello_loop.dewy\",\"code\":\"print\\\"What's your name? \\\"\\nname = readl\\ni = 0\\nloop i \u003c? 10 {\\n    printl'Hello {name}!'\\n    i = i + 1\\n}\"},{\"name\":\"hello_name.dewy\",\"code\":\"print\\\"What's your name? \\\"\\nname = readl\\nprintl'Hello {name}!'\"},{\"name\":\"anonymous_func.dewy\",\"code\":\"(() =\u003e printl'Hello, World!')()\"},{\"name\":\"if_else.dewy\",\"code\":\"print\\\"What's your name? \\\"\\nname = readl\\nif name =? 'Alice' printl'Hello Alice!'\\nelse printl'Hello stranger!'\"},{\"name\":\"if_else_if.dewy\",\"code\":\"print\\\"What's your name? \\\"\\nname = readl\\nif name =? 'Alice' printl'Hello Alice!'\\nelse if name =? 'Bob' printl'Hello Bob!'\\nelse printl'Hello stranger!'\"}],\"bad_examples\":[{\"name\":\"dangling_else.dewy\",\"code\":\"// if a then if b then s else s2\\n// See: https://en.wikipedia.org/wiki/Dangling_else\\n\\na = false\\nb = true\\n\\n//TODO: this should print nothing, but prints 's2'\\n//The problem has to do with how flow control chains are parsed with the blacklist\\nif a\\n    if b\\n        printl's'\\n    else\\n        printl's2'\\n//else\\n//    printl's3'\"},{\"name\":\"if_tree.dewy\",\"code\":\"$23\"},{\"name\":\"loop_in_iter.dewy\",\"code\":\"loop i in [0,2..10] printl(i)\"},{\"name\":\"loop_iter_manual.dewy\",\"code\":\"it = iter[0,2..10]\\n[cond, i] = next(it)\\nloop cond {\\n    printl(i)\\n    [cond, i] = next(it)\\n}\"},{\"name\":\"nested_loop.dewy\",\"code\":\"loop i in [0,2..10]\\n    loop j in [0,2..10]\\n        printl'{i},{j}'\"},{\"name\":\"range_iter_test.dewy\",\"code\":\"r = [0,2..20]\\nit = iter(r)\\nprintl(next(it))\\nprintl(next(it))\\nprintl(next(it))\\nprintl(next(it))\\nprintl(next(it))\\nprintl(next(it))\\nprintl(next(it))\\nprintl(next(it))\\nprintl(next(it))\\nprintl(next(it))\\nprintl(next(it)) //last iteration. should return [true, 20]\\nprintl(next(it)) //should return [false, undefined]\\nprintl(next(it))\\nprintl(next(it))\"},{\"name\":\"block_printing.dewy\",\"code\":\"loop i in [0,2..5] {\\n    loop j in [0,2..5] {\\n        loop k in [0,2..5] {\\n            loop l in [0,2..5] {\\n                loop m in [0,2..5] {\\n                    printl'{i},{j},{k},{l},{m}'\\n                }\\n            }\\n        }\\n    }\\n}\"},{\"name\":\"unpack_test.dewy\",\"code\":\" s = ['Hello' ['World' '!'] 5 10]\\nprintl's={s}'\\na, b, c, d = s\\nprintl'a={a} b={b} c={c} d={d}'\\na, ...b = s\\nprintl'a={a} b={b}'\\n...a, b = s\\nprintl'a={a} b={b}'\\na, [b, c], ...d = s\\nprintl'a={a} b={b} c={c} d={d}'\\n\\n//error tests\\n//a, b, c, d, e = s         //error: not enough values to unpack\\n//a, b = s                  //error: too many values to unpack\\n//a, ...b, c, d, e, f = s   //error: too many values to unpack\\n\\n//TBD how unpack would handle `a, ...b, c, d, e = s`. Probably b would be empty?\\n\"},{\"name\":\"rule110.dewy\",\"code\":\"// proof that dewy is turing complete\\n// rule 110 would grow the vector from the front, so instead we reverse everything for efficiency\\n// for now use parenthesis where precedence filter needed. eventually should be able to remove with precedence filter\\n\\nprogress = world:vector\u003cbit\u003e =\u003e {\\n    update:bit = 0\\n    loop i in 0..world.length\\n    {\\n        if i \u003e? 0 world[i-1] = update //TODO: #notfirst handled by compiler unrolling the loop into prelude, interludes, and postlude\\n        update = 0b01110110 \u003c\u003c (world[i-1..i+1] .?? 0 .\u003c\u003c [2 1 0])\\n    }\\n    world.push(update)\\n}\\n\\nworld: vector\u003cbit\u003e = [1]\\nloop true\\n{\\n    printl(world)\\n    progress(world)\\n}\"},{\"name\":\"dewy_syntax_examples.dewy\",\"code\":\"$24\"},{\"name\":\"fast_inverse_sqrt.dewy\",\"code\":\"\\n\\n// fast inverse square-root. see: https://en.wikipedia.org/wiki/Fast_inverse_square_root#Overview_of_the_code\\nfast_isqrt = (x:f32) =\u003e {\\n    let y:f32, i:u32\\n    \\n    i = 0.5x transmute u32      // evil floating point bit level hacking\\n    i = 0x5f3759df - (i \u003e\u003e 1)   // what the fuck?\\n    y = i transmute f32\\n    y *= 1.5 - (0.5x)y^2        // 1st iteration of newton's method\\n    //y *= 1.5 - (0.5x)y^2      // 2nd iteration (optional)\\n\\n    return y\\n}\\n\\n\\n//TODO: use autodiff to calculate the derivative automatically?\\n//isqrt = (x:number) =\u003e 1/x^0.5\\n//diff(isqrt)\"},{\"name\":\"fizzbuzz0.dewy\",\"code\":\"taps = [3 -\u003e 'Fizz' 5 -\u003e 'Buzz' /{7 -\u003e 'Bazz' 11 -\u003e 'Bar'}/]\\nloop i in [0..100)\\n{\\n    printed_words = false\\n    loop [tap string] in taps \\n    {\\n        if i % tap =? 0 \\n        { \\n            print(tap)\\n            printed_words = true\\n        }\\n    }\\n    if not? printed_words print(i)\\n    printl()\\n}\"},{\"name\":\"fizzbuzz1.dewy\",\"code\":\"taps = [3 -\u003e 'Fizz' 5 -\u003e 'Buzz' /{7 -\u003e 'Bazz' 11 -\u003e 'Bar'}/]\\nrange = [0..100)\\n\\n//indexing at [, ..] and [..,] adds singleton dimensions\\nword_bools = range[, ..] .% taps.keys[..,] .=? 0\\n\\n// ` means transpose, which behaves like python's zip()\\nwords_grid = [taps.values word_bools]`.map(\\n    [word bools] =\u003e bools.map(b =\u003e if b word else '')\\n)\\n\\nraw_lines = word_grid`.map(line_words =\u003e line_words.join(''))\\n\\nlines = [raw_lines range]`.map(\\n    (raw_line, i) =\u003e if raw_line.length =? 0 '{i}' else raw_line\\n)\\n\\nlines.join('\\\\n') |\u003e printl\"},{\"name\":\"random.dewy\",\"code\":\"$25\"},{\"name\":\"syntax.dewy\",\"code\":\"$26\"},{\"name\":\"tokenizer.dewy\",\"code\":\"//demo of manual dewy tokenizer written in dewy\\n\\n// (template) instance of the token class\\nTokenBase = [\\n    name = 'Token'\\n    __repr__ = () =\u003e '\u003c{name}\u003e'\\n]\\nToken = type(TokenBase)\\n\\n\\n// class constructor for Keyword token type\\nKeyword = src:string =\u003e [\\n    ...TokenBase\\n    name = 'Keyword'\\n    __repr__ = () =\u003e '\u003c{name}: {value}\u003e'\\n]\\n\\n\\neat_fn_type = func\u003csrc:string\u003e =\u003e int? \\n\\n\\n/{\\n    Eat a reserved keyword, return the number of characters eaten\\n\\n    #keyword = {in} | {as} | {loop} | {lazy} | {if} | {and} | {or} | {xor} | {nand} | {nor} | {xnor} | {not}; \\n\\n    noting that keywords are case insensitive\\n}/\\neat_keyword: func\u003csrc:string\u003e =\u003e int? = src:string =\u003e {\\n    keywords = ['in' 'as' 'loop' 'lazy' 'if' 'and' 'or' 'xor' 'nand' 'nor' 'xnor' 'not']\\n    max_len = [loop k in keywords k.length].max\\n    lower_src = src[..max_len].lowercase()\\n    loop k in keywords\\n        if lower_src.startswith(k)\\n            return k.length\\n    return undefined // tbd if this is optional\\n}\\n\"}]}}]\n"])</script></body></html>